<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>linear regression in python, outliers / leverage detect &mdash; pydata: Huiming's learning notes</title>
  <meta name="author" content="shm">






  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="/favicon.png" rel="icon">

  <link href="/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><header>
  <h1><a href="/">pydata: Huiming's learning notes</a></h1>
    <h2>Keep Looking, Don't Settle</h2>
</header>

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],  // 允许 $...$ 和 \( ... \) 作为行内公式
    displayMath: [['$$', '$$'], ['\\[', '\\]']],  // 允许 $$...$$ 和 \[ ... \] 作为块级公式
    processEscapes: true,  // 允许在公式中使用转义符，如 \$ 表示美元符号
    processEnvironments: true  // 允许解析 \begin{equation} ... \end{equation} 等数学环境
  },
  options: {
    skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],  // 跳过某些 HTML 标签，防止错误解析
    renderActions: {
      addMenu: []  // 移除右键菜单
    }
  }
};

window.addEventListener('load', () => {
  document.querySelectorAll("mjx-container").forEach(x => {
    x.parentElement.classList.add('has-jax');  // 使用 classList.add() 避免字符串拼接错误
  });
});
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script></header>
  <nav role="navigation">

<form action="https://www.google.com/search" method="get">
    <fieldset role="search">
       <input type="hidden" name="q" value="site:songhuiming.github.io" />
       <input class="search" type="text" name="q" results="0" placeholder="Search"/>
    </fieldset>
</form>


<ul class="main-navigation">
    <li><a href="/functions/archives.html">Archives</a></li>
      <li >
        <a href="/category/career-growth.html">Career growth</a>
      </li>
      <li >
        <a href="/category/linux.html">Linux</a>
      </li>
      <li class="active">
        <a href="/category/python.html">Python</a>
      </li>
      <li >
        <a href="/category/rthers.html">Rthers</a>
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">linear regression in python, outliers / leverage detect</h1>
    <p class="meta">
<time datetime="2016-11-27T00:00:00-06:00" pubdate>Sun 27 November 2016</time>    </p>
</header>

  <div class="entry-content"><p>A single observation that is substantially different from all other observations can make a large difference in the results of your regression analysis.  If a single observation (or small group of observations) substantially changes your results, you would want to know about this and investigate further.  There are three ways that an observation can be unusual.</p>
<p><strong>Outliers</strong>: In linear regression, an outlier is an observation with large residual. In other words, it is an observation whose dependent-variable value is unusual given its values on the predictor variables. An outlier may indicate a sample peculiarity or may indicate a data entry error or other problem.</p>
<p><strong>Leverage</strong>: An observation with an extreme value on a predictor variable is called a point with high leverage. Leverage is a measure of how far an observation deviates from the mean of that variable. These leverage points can have an effect on the estimate of regression coefficients.</p>
<p><strong>Influence</strong>: An observation is said to be influential if removing the observation substantially changes the estimate of coefficients. Influence can be thought of as the product of leverage and outlierness.</p>
<p>The following is reference from stackexchange.</p>
<p>We need to understand three things:</p>
<ul>
<li>leverage,</li>
<li>standardized residuals, and</li>
<li>Cook's distance.</li>
</ul>
<p>To understand <a href="https://en.wikipedia.org/wiki/Leverage_%28statistics%29">leverage</a>, recognize that <a href="https://en.wikipedia.org/wiki/Ordinary_least_squares">Ordinary Least Squares regression</a> fits a line that will pass through the center of your data, (<span class="math">\(\bar{X}\)</span>, <span class="math">\(\bar{Y}\)</span>)
. The line can be shallowly or steeply sloped, but it will pivot around that point like a <a href="https://en.wikipedia.org/wiki/Lever">lever</a> on a <a href="https://en.wiktionary.org/wiki/fulcrum">fulcrum</a>. We can take this analogy fairly literally: because OLS seeks to minimize the vertical distances between the data and the line*, the data points that are further out towards the extremes of <span class="math">\(\bar{X}\)</span> will push / pull harder on the lever (i.e., the regression line); they have more leverage. One result of this could be that the results you get are driven by a few data points; that's what this plot is intended to help you determine.</p>
<p>Another result of the fact that points further out on X have more leverage is that they tend to be closer to the regression line (or more accurately: the regression line is fit so as to be closer to them) than points that are near <span class="math">\(\bar{X}\)</span>. In other words, the residual standard deviation can differ at different points on X</p>
<p>(even if the error standard deviation is constant). To correct for this, residuals are often <a href="https://en.wikipedia.org/wiki/Studentized_residual">standardized</a> so that they have constant variance (assuming the underlying data generating process is homoscedastic, of course).</p>
<p>One way to think about whether or not the results you have were driven by a given data point is to calculate how far the predicted values for your data would move if your model were fit without the data point in question. This calculated total distance is called <a href="https://en.wikipedia.org/wiki/Cook%27s_distance">Cook's distance</a>. Fortunately, you don't have to rerun your regression model N times to find out how far the predicted values will move, Cook's D is a function of the leverage and standardized residual associated with each data point.</p>
<p>With these facts in mind, consider the plots associated with four different situations:</p>
<ol>
<li>a dataset where everything is fine</li>
<li>a dataset with a high-leverage, but low-standardized residual point</li>
<li>a dataset with a low-leverage, but high-standardized residual point</li>
<li>a dataset with a high-leverage, high-standardized residual point</li>
</ol>
<pre><code class="language-python">import pandas as pd
import numpy as np
import itertools
from itertools import chain, combinations
import statsmodels.formula.api as smf
import scipy.stats as scipystats
import statsmodels.api as sm
import statsmodels.stats.stattools as stools
import statsmodels.stats as stats 
from statsmodels.graphics.regressionplots import *
import matplotlib.pyplot as plt
import seaborn as sns
import copy
from sklearn.cross_validation import train_test_split
import math
import time

%matplotlib inline 
plt.rcParams['figure.figsize'] = (12, 8)
</code></pre>
<h6>case 1. erveything is fine. As is shown in the leverage-studentized residual plot, studenized residuals are among -2 to 2 and the leverage value is low. R2 is 0.576.</h6>
<pre><code class="language-python">np.random.seed(0)
x1 = np.random.normal(20, 3, 20)
y0 = 5 + 0.5 * x1
y1 = 5 + 0.5 * x1 + np.random.normal(0, 1, 20)

lm = sm.OLS(y1, sm.add_constant(x1)).fit()
print &quot;The rsquared values is &quot; + str(lm.rsquared)

plt.scatter(np.sort(x1), y1[np.argsort(x1)])
plt.scatter(np.mean(x1), np.mean(y1), color = &quot;green&quot;)
plt.plot(np.sort(x1), y0[np.argsort(x1)], label = &quot;actual&quot;)
plt.plot(np.sort(x1), lm.predict()[np.argsort(x1)], label = &quot;regression&quot;)
plt.title(&quot;Linear Regression plots with the regression line&quot;)
plt.legend()

fig, ax = plt.subplots(figsize=(12,8))
fig = sm.graphics.influence_plot(lm, alpha  = 0.05, ax = ax, criterion=&quot;cooks&quot;)
</code></pre>
<pre><code>The rsquared values is 0.575969602822
</code></pre>
<p><img alt="png" src="/figures/ucla_ats_linreg_2_0_01.png"></p>
<p><img alt="png" src="/figures/ucla_ats_linreg_2_0_02.png"></p>
<p>The first graph includes the (x, y) scatter plot, the actual function generates the data(blue line) and the predicted linear regression line(green line). The linear regression will go through the average point <span class="math">\((\bar{x}, \bar{y})\)</span> all the time. </p>
<p>The second graph is the Leverage v.s. Studentized residuals plot. y axis(verticle axis) is the studentized residuals indicating if there is any outliers based on the alpha value(significace level). It shows point 0(the first data point) is like an outlier a little based on current alpha. Point 5 and 3 are high leverage data points. Generally there isn't any issue with this regression fitting. </p>
<h6>case 2. There is high leverage point (30, 20.8). This point has higher leverage than the others but There is no outliers. Because of this, its R2=0.684 which is higher than the case 1.</h6>
<pre><code class="language-python">x2 = np.r_[x1, 30]
y2 = np.r_[y1, 20.8]
y20 = np.r_[y0, 20]

lm2 = sm.OLS(y2, sm.add_constant(x2)).fit()
print &quot;The rsquared values is &quot; + str(lm2.rsquared)

plt.scatter(np.sort(x2), y2[np.argsort(x2)])
plt.scatter(30, 20.8, color = &quot;red&quot;)
plt.scatter(np.mean(x2), np.mean(y2), color = &quot;green&quot;)
plt.plot(np.sort(x2), y20[np.argsort(x2)], label = &quot;actual&quot;)
plt.plot(np.sort(x2), lm2.predict()[np.argsort(x2)], label = &quot;regression&quot;)
plt.legend()
plt.plot()

fig, ax = plt.subplots(figsize=(12,8))
fig = sm.graphics.influence_plot(lm2, ax= ax, criterion=&quot;cooks&quot;)
</code></pre>
<pre><code>The rsquared values is 0.68352705876
</code></pre>
<p><img alt="png" src="/figures/ucla_ats_linreg_2_0_03.png"></p>
<p><img alt="png" src="/figures/ucla_ats_linreg_2_0_04.png"></p>
<h6>case 3. There is an outlier (19, 20.8). It has high normalized residual. Different from high leverage point, the outlier will distort the regression line thus the R2 is down to 0.274.</h6>
<pre><code class="language-python">x3 = np.r_[x1, 19]
y3 = np.r_[y1, 20.8]
y30 = np.r_[y0, 5 + .5 * 19]

lm3 = sm.OLS(y3, sm.add_constant(x3)).fit()
print &quot;The rsquared values is &quot; + str(lm3.rsquared)

plt.scatter(np.sort(x3), y3[np.argsort(x3)])
plt.scatter(19, 20.8, color = &quot;red&quot;)
plt.scatter(np.mean(x3), np.mean(y3), color = &quot;green&quot;)
plt.plot(np.sort(x3), y30[np.argsort(x3)], label = &quot;actual&quot;)
plt.plot(np.sort(x3), lm3.predict()[np.argsort(x3)], label = &quot;regression&quot;)
plt.legend()
plt.plot()

fig, ax = plt.subplots(figsize=(12,8))
fig = sm.graphics.influence_plot(lm3, ax= ax, criterion=&quot;cooks&quot;)
</code></pre>
<pre><code>The rsquared values is 0.27377526628
</code></pre>
<p><img alt="png" src="/figures/ucla_ats_linreg_2_0_05.png"></p>
<p><img alt="png" src="/figures/ucla_ats_linreg_2_0_06.png"></p>
<h6>There is high leverage and outlier point (30, 10). The regression line was distorted severely. R2 = 0.029 which is very low.</h6>
<pre><code class="language-python">x4 = np.r_[x1, 30]
y4 = np.r_[y1, 10]
y40 = np.r_[y0, 20]

lm4 = sm.OLS(y4, sm.add_constant(x4)).fit()
print &quot;The rsquared values is &quot; + str(lm4.rsquared)

plt.scatter(np.sort(x4), y4[np.argsort(x4)])
plt.scatter(30, 10, color = &quot;red&quot;)
plt.scatter(np.mean(x4), np.mean(y4), color = &quot;green&quot;)
plt.plot(np.sort(x4), y40[np.argsort(x4)], label = &quot;actual line&quot;)
plt.plot(np.sort(x4), lm4.predict()[np.argsort(x4)], label = &quot;regression line&quot;)
plt.legend()
plt.plot()

fig, ax = plt.subplots(figsize=(12,8))
fig = sm.graphics.influence_plot(lm4, ax= ax, criterion=&quot;cooks&quot;)
</code></pre>
<pre><code>The rsquared values is 0.028865535723
</code></pre>
<p><img alt="png" src="/figures/ucla_ats_linreg_2_0_07.png"></p>
<p><img alt="png" src="/figures/ucla_ats_linreg_2_0_08.png"></p>
<pre><code class="language-python">x4 = np.r_[x1, 30]
y4 = np.r_[y1, 10]
y40 = np.r_[y0, 20]

lm4 = sm.OLS(y4, sm.add_constant(x4)).fit()
print &quot;The rsquared values is &quot; + str(lm4.rsquared)


fig = plt.figure()
ax = fig.add_subplot(211)
ax2 = fig.add_subplot(212)

ax.scatter(np.sort(x4), y4[np.argsort(x4)])
ax.scatter(30, 10, color = &quot;red&quot;)
ax.scatter(np.mean(x4), np.mean(y4), color = &quot;green&quot;)
ax.plot(np.sort(x4), y40[np.argsort(x4)], label = &quot;actual line&quot;)
ax.plot(np.sort(x4), lm4.predict()[np.argsort(x4)], label = &quot;regression line&quot;)
ax.legend()

sm.graphics.influence_plot(lm4, ax = ax2, criterion=&quot;cooks&quot;)
plt.show()
</code></pre>
<pre><code>The rsquared values is 0.028865535723
</code></pre>
<p><img alt="png" src="/figures/ucla_ats_linreg_2_0_09.png"></p>
<h2>Reference</h2>
<ol>
<li><a href="http://stats.stackexchange.com/questions/58141/interpreting-plot-lm">Interpreting plot.lm()</a></li>
<li><a href="http://statsmodels.sourceforge.net/devel/examples/notebooks/generated/example_regression_plots.html">Regression Plots</a></li>
<li><a href="http://statsmodels.sourceforge.net/stable/graphics.html">statsmodels graphics</a></li>
</ol>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
        <a href="/author/huiming-song.html">Huiming Song</a>
    </span>
  </span>
<time datetime="2016-11-27T00:00:00-06:00" pubdate>Sun 27 November 2016</time>  <span class="categories">
    <a class='category' href='/category/python.html'>Python</a>
  </span>
  <span class="categories">
    <a class="category" href="/tag/python.html">python</a>,    <a class="category" href="/tag/data-minging.html">data minging</a>,    <a class="category" href="/tag/statsmodels.html">statsmodels</a>  </span>
</p><div class="sharing">
</div>    </footer>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="/pages/2025/02/23/deepseek-v3-learning-notes/">DeepSeek V3 learning notes</a>
      </li>
      <li class="post">
          <a href="/pages/2025/02/16/deepseek-v3/">DeepSeek V3</a>
      </li>
      <li class="post">
          <a href="/pages/2024/04/21/prediction-in-decoder-and-kv-cache/">Prediction in decoder and KV-Cache</a>
      </li>
      <li class="post">
          <a href="/pages/2023/10/01/image-generation-2-latent-diffusion-model-stable-diffusion/">Image Generation 2: Latent Diffusion model / Stable Diffusion</a>
      </li>
      <li class="post">
          <a href="/pages/2023/07/04/image-generation-1-diffusion-model/">Image Generation 1: Diffusion model</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="/category/career-growth.html">career growth</a></li>
        <li><a href="/category/linux.html">Linux</a></li>
        <li><a href="/category/python.html">python</a></li>
        <li><a href="/category/rthers.html">Rthers</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="/tag/python.html">python</a>,    <a href="/tag/ai.html">AI</a>,    <a href="/tag/llm.html">LLM</a>,    <a href="/tag/aig.html">AIG</a>,    <a href="/tag/agi.html">AGI</a>,    <a href="/tag/gpt.html">GPT</a>,    <a href="/tag/data-mining.html">data mining</a>,    <a href="/tag/sklearn.html">sklearn</a>,    <a href="/tag/pytorch.html">pytorch</a>,    <a href="/tag/career-growth.html">career growth</a>,    <a href="/tag/linux.html">linux</a>,    <a href="/tag/deep-learning.html">deep learning</a>,    <a href="/tag/leetcode.html">leetcode</a>,    <a href="/tag/dynamic-programming.html">dynamic programming</a>,    <a href="/tag/flask.html">flask</a>,    <a href="/tag/highcharts.html">highcharts</a>,    <a href="/tag/sql.html">sql</a>,    <a href="/tag/webcrawl.html">webCrawl</a>,    <a href="/tag/random-walk.html">random walk</a>,    <a href="/tag/multiprocessing.html">multiprocessing</a>,    <a href="/tag/data-visualization.html">data visualization</a>,    <a href="/tag/numpy.html">numpy</a>,    <a href="/tag/tensorflow.html">tensorflow</a>,    <a href="/tag/quant.html">quant</a>,    <a href="/tag/statsmodels.html">statsmodels</a>,    <a href="/tag/pandas.html">pandas</a>,    <a href="/tag/docker.html">docker</a>,    <a href="/tag/matplotlib.html">matplotlib</a>,    <a href="/tag/data-minging.html">data minging</a>,    <a href="/tag/remote-access.html">remote access</a>,    <a href="/tag/mysql.html">mysql</a>,    <a href="/tag/base.html">base</a>,    <a href="/tag/tweepy.html">tweepy</a>,    <a href="/tag/bokeh.html">bokeh</a>,    <a href="/tag/sentiment-analysis.html">sentiment analysis</a>,    <a href="/tag/map.html">map</a>,    <a href="/tag/apply.html">apply</a>,    <a href="/tag/apply_async.html">apply_async</a>,    <a href="/tag/git.html">git</a>,    <a href="/tag/pyqt.html">PyQt</a>,    <a href="/tag/cx_freeze.html">cx_freeze</a>,    <a href="/tag/tkinter.html">tkinter</a>,    <a href="/tag/pelican.html">pelican</a>,    <a href="/tag/spyre.html">spyre</a>,    <a href="/tag/shiny.html">shiny</a>,    <a href="/tag/r.html">R</a>,    <a href="/tag/re.html">re</a>  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://www.linkedin.com/pub/huiming-song/24/735/349" target="_blank">Linkedin</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://easysas.blogspot.com/" target="_blank">my old SAS blog</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2015&ndash;2025  shm &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="/theme/js/modernizr-2.0.js"></script>
  <script src="/theme/js/ender.js"></script>
  <script src="/theme/js/octopress.js" type="text/javascript"></script>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-65938411-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-65938411-1');
    ga('send', 'pageview');
</script>
  <script type="text/javascript">
    var disqus_shortname = 'songhuiming';
    var disqus_identifier = '/pages/2016/11/27/linear-regression-in-python-outliers-leverage-detect/';
    var disqus_url = '/pages/2016/11/27/linear-regression-in-python-outliers-leverage-detect/';
    var disqus_title = 'linear regression in python, outliers / leverage detect';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = "//" + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
  </script>
</body>
</html>