<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
<<<<<<< HEAD
  <title>DeepSeek V3 &mdash; pydata</title>
=======
  <title>DeepSeek V3 &mdash; pydata by Huiming</title>
>>>>>>> f34c8db9 (ubuntu2025 update)
  <meta name="author" content="shm">






  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


<<<<<<< HEAD
    <link href="/favicon.png" rel="icon">

  <link href="/theme/css/main.css" media="screen, projection"
=======
    <link href="https://songhuiming.github.io/favicon.png" rel="icon">

  <link href="https://songhuiming.github.io/theme/css/main.css" media="screen, projection"
>>>>>>> f34c8db9 (ubuntu2025 update)
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><hgroup>
<<<<<<< HEAD
  <h1><a href="/">pydata</a></h1>
=======
  <h1><a href="https://songhuiming.github.io/">pydata by Huiming</a></h1>
>>>>>>> f34c8db9 (ubuntu2025 update)
    <h2>Keep Looking, Don't Settle</h2>
</hgroup>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
        MathJax.Hub.Config({
            config: ["MMLorHTML.js"],
            extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js"],
            jax: ["input/TeX"],
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                processEscapes: false
            },
            TeX: {
                TagSide: "right",
                TagIndent: ".8em",
                MultLineWidth: "85%",
                equationNumbers: {
                   autoNumber: "AMS",
                },
                unicode: {
                   fonts: "STIXGeneral,'Arial Unicode MS'"
                }
            },
            showProcessingMessages: false
        });
</script></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
</ul>

<form class="search" action="/search.html">
    <input type="text" class="search-query" placeholder="Search" name="q" id="s">
</form>

<form action="https://www.google.com/search" method="get">
    <fieldset role="search">
       <input type="hidden" name="q" value="site:songhuiming.github.io" />
       <input class="search" type="text" name="q" results="0" placeholder="Search"/>
    </fieldset>
</form>


<ul class="main-navigation">
    <li><a href="/functions/archives.html">Archives</a></li>
      <li >
<<<<<<< HEAD
        <a href="/category/career-growth.html">Career growth</a>
      </li>
      <li >
        <a href="/category/linux.html">Linux</a>
      </li>
      <li class="active">
        <a href="/category/python.html">Python</a>
      </li>
      <li >
        <a href="/category/rthers.html">Rthers</a>
=======
        <a href="https://songhuiming.github.io/category/career-growth.html">Career growth</a>
      </li>
      <li >
        <a href="https://songhuiming.github.io/category/linux.html">Linux</a>
      </li>
      <li class="active">
        <a href="https://songhuiming.github.io/category/python.html">Python</a>
      </li>
      <li >
        <a href="https://songhuiming.github.io/category/rthers.html">Rthers</a>
>>>>>>> f34c8db9 (ubuntu2025 update)
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">DeepSeek V3</h1>
    <p class="meta">
<time datetime="2025-02-16T00:00:00-06:00" pubdate>Sun 16 February 2025</time>    </p>
</header>

  <div class="entry-content"><script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<<<<<<< HEAD

=======
>>>>>>> f34c8db9 (ubuntu2025 update)
<script>
        MathJax.Hub.Config({
            config: ["MMLorHTML.js"],
            extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js"],
            jax: ["input/TeX"],
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                processEscapes: false
            },
            TeX: {
                TagSide: "right",
                TagIndent: ".8em",
                MultLineWidth: "85%",
                equationNumbers: {
                   autoNumber: "AMS",
                },
                unicode: {
                   fonts: "STIXGeneral,'Arial Unicode MS'"
                }
            },
            showProcessingMessages: false
        });
</script>

<h2>1. What the problem to solve?</h2>
<p>春节回去的时候正好碰上DeepSeek发布新的模型，一时间各路媒体讨论的沸沸扬扬，几乎上升到国运的高度。讨论的最重要的应该是两点：第一个是媲美其他主流模型的benchmark分数；第二个是说训练速度快了很多，使用了少的多的GPU时间。可是各路讨论多是繁华之论以及振奋人心的消息，而没有具体的DS为什么好，怎么好的。回来的第一个周末，花了周末的时间读了一下DS V3的论文。之所以选择V3因为R1是之于V3进行了RL和SFT来增强模型的推理能力，基本的模型还是V3，而且DS V3的论文也更详细。文章的第二部分讲述了DS在模型的架构上（science）有一些什么样的改进，第三部分讲述了在模型的训练上（engineering）有什么改进，然后两部分讲了pretraining和posttraining以及evaluation相关的东西。</p>
<h2>2. How to solve?</h2>
<h3>2.1. Basic Architecture</h3>
<p>模型的基本架构里面主要有两点：1是把原来的Attention改成了Multi-head Latent Attention；2是把原来的FFN改成了DeepSeekMoE。这样做的目的一是减少了计算量；二是减少了cache的data，从而节约了GPU的内存。具体如下：</p>
<p>DeekSeek模型架构
<<<<<<< HEAD
<img alt="20250216_01_deepseek_v3_architecture.png" src="/figures/20250216_01_deepseek_v3_architecture.png" /></p>
=======
<img alt="20250216_01_deepseek_v3_architecture.png" src="/figures/20250216_01_deepseek_v3_architecture.png"></p>
>>>>>>> f34c8db9 (ubuntu2025 update)
<h4>2.1.1. Multi-head latent attention (MLA)</h4>
<p>相比较于原始的<a href="https://arxiv.org/abs/1706.03762">Attention</a>模型里面介绍的注意力机制, DS使用Multi-head latent attention (MLA)的架构，跟原来的Multi-head attention不一样的是这里面从 <span class="math">\(h_t\)</span> 来计算 <span class="math">\(k, q, v\)</span> 的时候，先进行降维，把 <span class="math">\(h_t \in \mathbb{R}^d\)</span> 投影到一个低维空间 <span class="math">\(\color{blue}{c_t^{KV} = W^{DKV} h_t}\)</span> ，然后再升维到 <span class="math">\(\color{blue}{k_t^C=W^{UK}c_t^{KV}}\)</span> ；以及投影到一个低维的 <span class="math">\(\color{blue}{c_t^Q=W^{DQ}h_t}\)</span>，然后再升维到 <span class="math">\(\color{blue}{q_t^C = W^{UQ} c_t^Q}\)</span>。这样的话在进行inference的时候只要保存低维的 <span class="math">\(\color{blue}{c_t^{KV}}\)</span> 和 <span class="math">\(\color{blue}{c_t^Q}\)</span>. 比如说，原来的 <span class="math">\(\text{dim}(h_t) = 7168\)</span>, 通过一个降维矩阵 <span class="math">\(\text{dim}(W^{DKV})=4096 \times 7186\)</span>把它降到4096维，那么需要保存的矩阵 <span class="math">\(\color{blue}{c_t^{KV}}\)</span>就小了很多。 具体地说，</p>
<div class="math">\begin{aligned}
&amp;  \textcolor{blue}{c_t^{KV}} = W^{DKV} h_t, \\
&amp;  [k_{t,1}^{C}, k_{t,2}^{C}, ..., k_{t,n_h}^{C}] = k_t^C = W^{UK} c_t^{KV}, \\
&amp;  \textcolor{blue}{k_t^R} = \text{RoPE}(W^{KR} h_t), \\
&amp;  k_{t,i} = \left[k_{t,i}^{C}; k_t^R \right], \\
&amp;  [v_{t,1}^{C}, v_{t,2}^{C}, ..., v_{t,n_h}^{C}] = v_t^C = W^{UV} c_t^{KV},
\end{aligned}</div>
<p>这里 <span class="math">\( W^{DKV} \in \mathbb{R}^{d_c \times d} $ 是一个降维投影矩阵; $W^{UK}, W^{UV} \in \mathbb{R}^{d_h n_h \times d_c}\)</span> 是对应的 keys 和 values 的升维矩阵。在做inference的时候，只需要<span class="math">\(\textcolor{blue}{c_t^{KV}}\)</span>和<span class="math">\(\textcolor{blue}{k_t^R}\)</span>，即节省了计算量，也节约了内存。</p>
<p>对Query，也有同样的处理来降维
</p>
<div class="math">\begin{aligned}
&amp; \textcolor{blue}{c_t^Q} = W^{DQ} h_t, \\
&amp; [q_{t,1}^{C}, q_{t,2}^{C}, ..., q_{t,n_h}^{C}] = q_t^C = W^{UQ} c_t^Q, \\
&amp; [q_{t,1}^{R}, q_{t,2}^{R}, ..., q_{t,n_h}^{R}] = q_t^R = \text{RoPE}(W^{QR} c_t^Q), \\
&amp; q_{t,i} = [q_{t,i}^{C}, q_{t,i}^{R}],
\end{aligned}</div>
<h4>2.1.2. DeepSeekMoE with Auxiliary-Loss-Free Load Balancing</h4>
<h5>Basic Architecture of DeepSeekMoE</h5>
<p>在2017年的Attention论文里面，decoder先是计算Attention，然后再计算FFN从而predict最后的token。DS里面，FFN被进一步改成了MoE。MoE的意思是模型是由一些列的Expert构成。每个Expert可以是一个MLP，一个CNN或者其他的神经网络模型，或者每个Expert可以是一个tansformer的encoder/decoder。每个 Expert 负责学习不同的数据模式，MoE 通过 Gating Network 选择合适的Expert，使得不同的数据被送往最擅长Expert家处理。每预测下一个token的时候，MoE不是使用某一个Expert，也不是使用所有的Expert，而是选择其中的Top <span class="math">\(K\)</span> 个Expert来进行预测。选哪 <span class="math">\(K\)</span> 个Expert是通过一个Gating网络来确定。通常 <span class="math">\(K \ll N\)</span>，所以MoE是一个稀疏网络。使用MoE第一个好处是通过更精细化的划分，模型有更大的灵活性，不同的Expert可以学习不同的数据。比如如果 <span class="math">\(N=16\)</span>，<span class="math">\(K=2\)</span>，那么就有 <span class="math">\(C(16, 2)=160\)</span> 个组合。如果每个Expert再split成4个小的Expert，那么总共的组合就是 <span class="math">\(C(64, 8)=4,426,165,368\)</span>。这样极大的增加了模型的灵活性。第二个好处是节省计算资源，因为每次只需要激活很少的Expert来参加计算，而不像transfomer那样所有的参数都参加计算。也就是说，MoE可以训练一个更大更多参数的模型，从而记住更多的知识，但是每次实际只有很少一部分参数参加计算。而且应为每个Expert是独立的模型，没有共享参数，所以他们可以并行进行计算。</p>
<p>MoE的架构见下图
<<<<<<< HEAD
<img alt="20250216_03_deepseek_v2_moe.png" src="/figures/20250216_03_deepseek_v2_moe.png" /></p>
<p>在DS的FFN里面，DeepSeekMoE在MOE的基础上更进一步：1）他们把Expert进一步细化，然后既有一些Expert用来做routing，具体地说，对routingd的Expert，预测只是route到这些Expert的某一些上面。同时，他们还有一些Expert是共享Expert，也就是说，在预测的时候，他们每次都是被使用。2）DS优化了Expert的选择，使用affinity score来选择专家。3）DS的Expert更finer，同时也更稀疏。这样进一步降低了运算成本。</p>
<p>DeepSeekMoE的架构见下图
<img alt="20250216_02_original_moe.png" src="/figures/20250216_02_original_moe.png" /></p>
=======
<img alt="20250216_03_deepseek_v2_moe.png" src="/figures/20250216_03_deepseek_v2_moe.png"></p>
<p>在DS的FFN里面，DeepSeekMoE在MOE的基础上更进一步：1）他们把Expert进一步细化，然后既有一些Expert用来做routing，具体地说，对routingd的Expert，预测只是route到这些Expert的某一些上面。同时，他们还有一些Expert是共享Expert，也就是说，在预测的时候，他们每次都是被使用。2）DS优化了Expert的选择，使用affinity score来选择专家。3）DS的Expert更finer，同时也更稀疏。这样进一步降低了运算成本。</p>
<p>DeepSeekMoE的架构见下图
<img alt="20250216_02_original_moe.png" src="/figures/20250216_02_original_moe.png"></p>
>>>>>>> f34c8db9 (ubuntu2025 update)
<p>假设每个Expert <span class="math">\(i\)</span> 的中心是 <span class="math">\(\mathbf{e}_{i}\)</span>，首先计算 <span class="math">\(\color{blue}{s_{i,t} = \sigma(\mathbf{u}_t^\top \mathbf{e}_i)}\)</span> 作为 token <span class="math">\(t\)</span> 与 Expert <span class="math">\(i\)</span> 的相似度： <span class="math">\(\mathbf{e}_i\)</span> 作为Expert <span class="math">\(i\)</span> 的中心向量，通过与token的输入 <span class="math">\(\mathbf{u}_t\)</span> 进行点积，再经过 sigmoid 计算出 token 对该Expert的 affinity，从而决定 token 是否被路由到该Expert。</p>
<p><span class="math">\(g^{\prime}_{i,t}\)</span> 是Expert <span class="math">\(i\)</span>的gating value，根据所有的Expert的 <span class="math">\(s_{i,t}\)</span>的值，来选择最高的 <span class="math">\(K_r\)</span>个。
</p>
<div class="math">$$
    g'_{i,t} =
    \begin{cases} 
        s_{i,t}, &amp; s_{i,t} \in \text{Topk}(\{s_{j,t} | 1 \leq j \leq N_r\}, K_r), \\
        0, &amp; \text{otherwise},
    \end{cases}
$$</div>
<p>然后算出这 <span class="math">\(K_r\)</span>个Expert的权重 <span class="math">\(\color{blue}{g_{i,t} = \frac{g^{\prime}_{i,t}}{\sum_{j=1}^{N_r} g'_{j,t}}}\)</span>。尽管这儿的公式看分母是<span class="math">\(N_r\)</span>个<span class="math">\(g'_{i,t}\)</span>相加，但是实际上有<span class="math">\(N_r - K_r\)</span>个为0.</p>
<p>最后得到新的output为 <span class="math">\(\color{blue}{\mathbf{h}'_t = \mathbf{u}_t + \sum_{i=1}^{N_s} \text{FFN}^{(s)}_i(\mathbf{u}_t) + \sum_{i=1}^{N_r} g_{i,t} \text{FFN}^{(r)}_i(\mathbf{u}_t)}\)</span>. 注意的是，这里面从 <span class="math">\(N_r\)</span> 个Expert里面选择了 <span class="math">\(K_r\)</span>个来进行计算，<span class="math">\(K_r \ll N_r\)</span>，从而节约了大量的计算。同时，相比较于一般的MoE，DS使用了 <span class="math">\(N_s\)</span>个 shared Expert，这些Expert参加所有的token的运算。通过引入共享专家，模型可以在不同任务之间共享通用知识，避免每个专家都独立学习相似的内容，从而减少了知识冗余。</p>
<h5>Auxiliary-Loss-Free Load Balancing in DeepSeek-V3</h5>
<p>实际运行的时候，可能会出现这种情况：模型的token大部分都是有某几个Expert来predict，剩下来的Expert使用率会比较少，导致Expert负载不均衡。以前的MOE使用auxiliary loss来让Expert负载均衡。通过惩罚imbalanced Expert utilization （加上更多的loss）来来达到均衡负载的目的。但是这样做有两个问题：1）Too strong auxiliary loss hurts model performance by interfering with learning objectives. 2）Difficult to tune: Balancing between efficiency and accuracy requires careful hyperparameter tuning.</p>
<p>DS提出了Auxiliary-Loss-Free Load Balancing来达到balanced routing of tokens to different Experts.具体的说实在gating function里面添加一个bias的项，通过bias的值来平衡Expert的调用。</p>
<p>具体的说，在计算权重<span class="math">\(g'_{i,t}\)</span>的时候，对每个token和Expert的affinity score都添加了一个bias <span class="math">\(b_i\)</span>，变成<span class="math">\(s_{i,t} + b_i \in \text{Topk}(\{s_{j,t} + b_j | 1 \leq j \leq N_r\}, K_r)\)</span>, 当某个Expert <span class="math">\(j\)</span>出现overload的时候，就把对应的<span class="math">\(b_j\)</span>减小<span class="math">\(\gamma\)</span> 。这样的话新的<span class="math">\(s_{j,t} + b_j\)</span>就会减小一点，这样的话 <span class="math">\(\textcolor{blue}{Top k}\)</span> 个选择的时候这个Expert就会排名靠后一点，更可能不会被选中因为<span class="math">\(g'_{i,t} = 0\)</span>。</p>
<h5>Complementary Sequence-Wise Auxiliary Loss</h5>
<p>DeepSeek-V3 主要依赖 Auxiliary-Loss-Free 负载均衡策略来确保 Experts 间的负载均衡。然而，为了防止单个序列内部的极端不平衡，DeepSeek-V3 还引入了 Complementary Sequence-Wise Auxiliary Loss. 通常MoE模型的负载均衡都在batch level进行，但是对一个batch的多个sequence，某个sequence 内部某些Expert可能用的很多，而其他Expert用的很少。DS的想法是要在每个sequence level，也尽可能的让Expert utilization均衡，负载不会过于集中或稀疏。同时该损失的强度非常低，以避免对模型性能产生负面影响。</p>
<p>下面我们主要来理解原文中的公式，为什么这个公式就能够均衡 Sequence level的Expert 负载。</p>
<div class="math">\begin{aligned}
&amp; \mathcal{L}_{\text{Bal}} = \alpha \sum_{i=1}^{N_r} f_i P_i, \\
&amp; f_i = \frac{N_r}{K_r T} \sum_{t=1}^{T} \mathbb{1} \left(s_{i,t} \in \text{Topk}(\{s_{j,t} | 1 \leq j \leq N_r\}, K_r) \right), \\
&amp; s'_{i,t} = \frac{s_{i,t}}{\sum_{j=1}^{N_r} s_{j,t}}, \\
&amp; P_i = \frac{1}{T} \sum_{t=1}^{T} s'_{i,t}
\end{aligned}</div>
<p><span class="math">\(P_i\)</span>是看在 sequence 上面 Expert 的使用是不是比较均衡。如果不均衡的话，<span class="math">\(P_i\)</span>的值就会比较大。具体原因：首先看<span class="math">\(s^{\prime}_{i,t}\)</span> 和 <span class="math">\(P_i\)</span>。对归一化的affinity score <span class="math">\(s^{\prime}_{i,t} = \frac{s_{i,t}}{\sum_{j=1}^{N_r} s_{j,t}}\)</span>, 计算Expert <span class="math">\(i\)</span> 在整个sequence (Sequence 的长度为 <span class="math">\(T\)</span>) 上面的的平均得分 <span class="math">\(P_i = \frac{1}{T} \sum_{t=1}^{T} s^{\prime}_{i,t}\)</span>: 如果Expert <span class="math">\(i\)</span> 在sequence的很多token <span class="math">\(t\)</span>上被选中，那么对应的 <span class="math">\(s_{i,t}\)</span> 就会被其他的<span class="math">\(s_{j,t}\)</span>大 (<span class="math">\(s_{i,t} \gg s_{j,t}\)</span> for <span class="math">\(j \neq i\)</span>), 而 <span class="math">\(s^{\prime}_{i,t}\)</span> 是 <span class="math">\(s_{i,t}\)</span>对所有的 Expert的归一化值，那么<span class="math">\(s^{\prime}_{i,t}\)</span>就相应的比较大。而<span class="math">\(P_i\)</span>是<span class="math">\(s^{\prime}_{i,t}\)</span>在整个 sequence 上的平均值，所以它也会比较大。最后相对应的损失函数 <span class="math">\(\mathcal{L}_{\text{Bal}} = \alpha \sum_{i=1}^{N_r} f_i P_i\)</span> 就比较大。</p>
<p><span class="math">\(f_i\)</span> 是 Expert <span class="math">\(i\)</span> 被使用的频率的归一化值。公式 <span class="math">\(f_i = \frac{N_r}{K_r T} \sum_{t=1}^{T} \mathbb{1} \left(s_{i,t} \in \text{Topk}(\{s_{j,t} | 1 \leq j \leq N_r\}, K_r) \right)\)</span> 统计了每个 Expert <span class="math">\(i\)</span> 在当前序列 <span class="math">\(T\)</span> 个token中被使用的频率 （<span class="math">\(\sum_{t=1}^{T} \mathbb{1} \left(s_{i,t} \in \text{Topk}(\{s_{j,t} | 1 \leq j \leq N_r\}, K_r) \right)\)</span>），然后做了归一化 <span class="math">\(\frac{N_r}{K_r T}\)</span>. 同样，如果 Expert <span class="math">\(i\)</span> 在这个 sequence 中被调用的次数很多，那么这个值也会更大。</p>
<p>最后，损失函数公式里的 <span class="math">\(\alpha\)</span> 是个取值很小的超参数。它的值很小是为了不过度影响主要训练目标。</p>
<h3>2.2. Multi-Token Prediction (MTP)</h3>
<p>DS还使用了MTP，而不是像一般的pre-training那样仅仅只预测 next token（2017的Attention文章就是只predict next token）。这有两个好处：1. 同时预测多个token可以提高data的使用效率。2. 让模型在准备representation的时候能够考虑的更长远。跟原始的MTP文章不同的是，DS不是同时predict <span class="math">\(D\)</span> 个token (输出一个 <span class="math">\(D \times V\)</span> 的矩阵， 其中 <span class="math">\(V\)</span> 是词表大小); 换个表达方式，对应的prediction 和损失函数是 <span class="math">\(L_n = -\sum_t \log P_{\theta} (x_{t+n:t+1} \mid x_{t:1})\)</span>.  DS是sequentially predict additional token。</p>
<p>MTP from Gloeckle et al. (2024), which is  <span class="math">\(D \times V\)</span> 的矩阵
<<<<<<< HEAD
<img alt="20250216_04_deepseek_orig_MTP.png" src="/figures/20250216_04_deepseek_orig_MTP.png" /></p>
<p>DS的MTP模块结构用一句话来简单概括就是：DS的MTP使用 <span class="math">\(D\)</span> 个sequential modules来预测 <span class="math">\(D\)</span> 个tokens。这 <span class="math">\(D\)</span> 个modules 共享 embedding <span class="math">\(\text{Emb}(\cdot)\)</span>，共享输出头 <span class="math">\(\text{OutHead}(\cdot)\)</span> 。 第 <span class="math">\(k\)</span> 个token的 MTP 模块有一个专用的 transformer 块 <span class="math">\(\text{TRM}_k(\cdot)\)</span>，以及一个投影矩阵 <span class="math">\(M_k \in \mathbb{R}^{d \times 2d}\)</span>  </p>
<p>DeepSeek V3 MTP: Use D MTP module and <span class="math">\(k\)</span>-th module predict <span class="math">\(k\)</span>-depth token
<img alt="20250216_05_deepseek_v3_MTP.png" src="/figures/20250216_05_deepseek_v3_MTP.png" /></p>
<p><strong>prediction</strong>：对于输入sequence的第 <span class="math">\(i\)</span> 个token <span class="math">\(t_i\)</span>，在第 <span class="math">\(k\)</span> 个prediction depth (也就是下面要 predict <span class="math">\(t_{i+k+1}\)</span>)，MTP module： 1）首先得到 <span class="math">\(i\)</span>-th token  在第 <span class="math">\((k-1)\)</span>-th 深度的表示 <span class="math">\(\mathbf{h}_i^{k-1} \in \mathbb{R}^{d}\)</span>， 以及第 <span class="math">\((i+k)\)</span>-th 个 token 的 embediding  <span class="math">\(Emb(t_{i+k}) \in \mathbb{R}^{d}\)</span>；  2）然后把他们concat起来（长度为 <span class="math">\(2d\)</span>），再通过 RMSNorm 和 投影矩阵 <span class="math">\(M_k \in \mathbb{R}^{d \times 2d}\)</span>} 来生成新的表示 
<span class="math">\(h’^k_i = M_k [\text{RMSNorm}(\mathbf{h}_i^{k-1}); \text{RMSNorm}(Emb(t_{i+k}))]\)</span>；3）然后 <span class="math">\(\mathbf{h}’^k_i\)</span>  作为输入到第 <span class="math">\(k\)</span>-th  个transformer 模块  <span class="math">\(\text{TRM}_k(\cdot)\)</span> ，生成当前深度的输出表示 <span class="math">\(\mathbf{h}^k_{1:T-k} = TRM_k(\mathbf{h}’^{k}_{1:T-k})\)</span>；最后使用 <span class="math">\(\text{OutHead}\)</span> 将 <span class="math">\(\mathbf{h}^k_i\)</span> 转换成预测概率 <span class="math">\(p_{i+k+1} = OutHead(\mathbf{h}^k_i) \in \mathbb{R}^{V}\)</span>。</p>
<p>我的理解：</p>
<p>1) 传统的next token prediction：<span class="math">\(t_1\)</span>-&gt; <span class="math">\(h_1\)</span> -&gt; <span class="math">\(\hat{t}_2\)</span>, <span class="math">\(t_2\)</span> -&gt; <span class="math">\(h_2\)</span> -&gt; <span class="math">\(\hat{t}_3}\)</span>, .... 也就是main model做的事情.</p>
=======
<img alt="20250216_04_deepseek_orig_MTP.png" src="/figures/20250216_04_deepseek_orig_MTP.png"></p>
<p>DS的MTP模块结构用一句话来简单概括就是：DS的MTP使用 <span class="math">\(D\)</span> 个sequential modules来预测 <span class="math">\(D\)</span> 个tokens。这 <span class="math">\(D\)</span> 个modules 共享 embedding <span class="math">\(\text{Emb}(\cdot)\)</span>，共享输出头 <span class="math">\(\text{OutHead}(\cdot)\)</span> 。 第 <span class="math">\(k\)</span> 个token的 MTP 模块有一个专用的 transformer 块 <span class="math">\(\text{TRM}_k(\cdot)\)</span>，以及一个投影矩阵 <span class="math">\(M_k \in \mathbb{R}^{d \times 2d}\)</span>  </p>
<p>DeepSeek V3 MTP: Use D MTP module and <span class="math">\(k\)</span>-th module predict <span class="math">\(k\)</span>-depth token
<img alt="20250216_05_deepseek_v3_MTP.png" src="/figures/20250216_05_deepseek_v3_MTP.png"></p>
<p><strong>prediction</strong>：对于输入sequence的第 <span class="math">\(i\)</span> 个token <span class="math">\(t_i\)</span>，在第 <span class="math">\(k\)</span> 个prediction depth (也就是下面要 predict <span class="math">\(t_{i+k+1}\)</span>)，MTP module： 1）首先得到 <span class="math">\(i\)</span>-th token  在第 <span class="math">\((k-1)\)</span>-th 深度的表示 <span class="math">\(\mathbf{h}_i^{k-1} \in \mathbb{R}^{d}\)</span>， 以及第 <span class="math">\((i+k)\)</span>-th 个 token 的 embediding  <span class="math">\(Emb(t_{i+k}) \in \mathbb{R}^{d}\)</span>；  2）然后把他们concat起来（长度为 <span class="math">\(2d\)</span>），再通过 RMSNorm 和 投影矩阵 <span class="math">\(M_k \in \mathbb{R}^{d \times 2d}\)</span>} 来生成新的表示 
<span class="math">\(h’^k_i = M_k [\text{RMSNorm}(\mathbf{h}_i^{k-1}); \text{RMSNorm}(Emb(t_{i+k}))]\)</span>；3）然后 <span class="math">\(\mathbf{h}’^k_i\)</span>  作为输入到第 <span class="math">\(k\)</span>-th  个transformer 模块  <span class="math">\(\text{TRM}_k(\cdot)\)</span> ，生成当前深度的输出表示 <span class="math">\(\mathbf{h}^k_{1:T-k} = TRM_k(\mathbf{h}’^{k}_{1:T-k})\)</span>；最后使用 <span class="math">\(\text{OutHead}\)</span> 将 <span class="math">\(\mathbf{h}^k_i\)</span> 转换成预测概率 <span class="math">\(p_{i+k+1} = OutHead(\mathbf{h}^k_i) \in \mathbb{R}^{V}\)</span>。</p>
<p>我的理解：</p>
<p>1) 传统的next token prediction：<span class="math">\(t_1\)</span>-&gt; <span class="math">\(h_1\)</span> -&gt; <span class="math">\(\hat{t}_2\)</span>, <span class="math">\(t_2\)</span> -&gt; <span class="math">\(h_2\)</span> -&gt; <span class="math">\(\hat{t}_3\)</span>, .... 也就是main model做的事情.</p>
>>>>>>> f34c8db9 (ubuntu2025 update)
<p>2) 在DS的 <span class="math">\(k\)</span>-th MTP 模块中，模型会根据第 <span class="math">\((k-1)\)</span>-depth 的 MTP representation <span class="math">\(h_i^{k-1}\)</span> 和 token <span class="math">\(t_{i+k}\)</span> 的embedding来的到 <span class="math">\(k\)</span>-depth 的representaion <span class="math">\(\mathbf{h}_i^k\)</span>，从而更进一步来预测 <span class="math">\((k+1)\)</span>-th token。下面用 <span class="math">\(k=1, 2, 3\)</span> 作为例子来说明是怎么工作的。 具体来说, 对输入 token <span class="math">\(i\)</span> :</p>
<p>在 <span class="math">\(k=1\)</span> 的时候，先把 <span class="math">\(t_i\)</span> 的representaion <span class="math">\(h_i^{k-1}=h_i^0\)</span> （from main model） 和 token <span class="math">\(t_{i+1}\)</span> (<span class="math">\(i+k=i+1\)</span>) 的embedding concat在一起得到 <span class="math">\(h’^1_i\)</span>，然后输入 <span class="math">\(TRM_1\)</span>， 得到 <span class="math">\(\mathbf{h}^1_{1:T-1} = TRM_1(\mathbf{h}’^{1}_{1:T-1})\)</span>， 最后得到token <span class="math">\(t_{i+2}\)</span> 的prediction 分布 <span class="math">\(p_{i+2}\)</span></p>
<p>在 <span class="math">\(k=2\)</span> 的时候，先把 <span class="math">\(t_i\)</span> 的representaion <span class="math">\(h_i^{k-1}=h_i^1\)</span> （from <span class="math">\(k=1\)</span> MTP module） 和 token <span class="math">\(t_{i+2}\)</span> ( <span class="math">\(i+k=i+2\)</span> ) 的embedding concat在一起得到 <span class="math">\(h’^2_i\)</span>，然后输入 <span class="math">\(TRM_2\)</span>， 得到 <span class="math">\(\mathbf{h}^2_{1:T-2} = TRM_2(\mathbf{h}’^{2}_{1:T-2})\)</span>， 最后得到token <span class="math">\(t_{i+3}\)</span>  的prediction 分布 <span class="math">\(p_{i+3}\)</span></p>
<p>在 <span class="math">\(k=3\)</span> 的时候，先把 <span class="math">\(t_i\)</span> 的representaion <span class="math">\(h_i^{k-1}=h_i^2\)</span> （from <span class="math">\(k=2\)</span> MTP module） 和 token <span class="math">\(t_{i+3}\)</span> ( <span class="math">\(i+k=i+3\)</span> ) 的embedding concat在一起得到 <span class="math">\(h’^3_i\)</span>，然后输入 <span class="math">\(\text{TRM}_3\)</span>， 得到 <span class="math">\(\mathbf{h}^3_{1:T-3} = TRM_3(\mathbf{h}’^{3}_{1:T-3})\)</span>， 最后得到token <span class="math">\(t_{i+4}\)</span>  的prediction 分布 <span class="math">\(p_{i+4}\)</span></p>
<p><strong>MTP 的目标函数</strong> 对每个predict depth k，其损失函数仍然是cross-entropy，定义为 <span class="math">\(\mathcal{L}_{\text{MTP}}^k\)</span> = <span class="math">\(\mathcal{L}_{\text{MTP}}^k\)</span> = <span class="math">\(\text{CrossEntropy}(P_{2+k:T+1}^{k}, t_{2+k:T+1})\)</span> = <span class="math">\(-\frac{1}{T} \sum_{i=2+k}^{T+1} \log p_i^k[t_i]\)</span>。其中 <span class="math">\(T\)</span> 是输入序列的长度, <span class="math">\(t_i\)</span> 是输入序列的第 <span class="math">\(i\)</span>-th 个真实值,  <span class="math">\(p_i^k[t_i]\)</span> 是第<span class="math">\(k\)</span>-th 个 MTP 模块对  <span class="math">\(t_i\)</span> 的prediciton probability.</p>
<p>最终 MTP 的损失函数是对所有的预测深度 (<span class="math">\(k\)</span> 从1 到<span class="math">\(D\)</span>) 的平均 乘以权重 <span class="math">\(\lambda\)</span> ，<span class="math">\(\mathcal{L}_{\text{MTP}}\)</span> = <span class="math">\(\frac{\lambda}{D} \sum_{k=1}^{D} \mathcal{L}_{\text{MTP}}^k\)</span> </p>
<p>从DS的paper公式25看，<span class="math">\(\mathcal{L}_{\text{MTP}}\)</span> 只是 MTP 的损失函数。最终的损失函数应该还要加上 <span class="math">\(\mathcal{L}_{\text{Main}}\)</span>。</p>
<p><strong>MTP 在推理的时候怎么用呢？</strong> MTP的主要目的是用来提高 main model的表现，在推理的时候，并不要使用MTP，而只是使用 main model来predict next token。</p>
<h3>未完待续</h3>
<h3>Reference</h3>
<ol>
<li><a href="https://github.com/deepseek-ai/DeepSeek-V3/blob/main/DeepSeek_V3.pdf">DeepSeek-V3 Technical Report</a></li>
</ol>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }
<<<<<<< HEAD
    
    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript'; 
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } }," +
=======

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','mhchem.js'], equationNumbers: { autoNumber: 'none' } }," +
>>>>>>> f34c8db9 (ubuntu2025 update)
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
<<<<<<< HEAD
=======
        "    messageStyle: 'normal'," +
>>>>>>> f34c8db9 (ubuntu2025 update)
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
<<<<<<< HEAD
=======
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
>>>>>>> f34c8db9 (ubuntu2025 update)
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
<<<<<<< HEAD
=======

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
>>>>>>> f34c8db9 (ubuntu2025 update)
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
<<<<<<< HEAD
        <a href="/author/huiming-song.html">Huiming Song</a>
    </span>
  </span>
<time datetime="2025-02-16T00:00:00-06:00" pubdate>Sun 16 February 2025</time>  <span class="categories">
    <a class='category' href='/category/python.html'>python</a>
  </span>
  <span class="categories">
    <a class="category" href="/tag/python.html">python</a>,    <a class="category" href="/tag/ai.html">AI</a>,    <a class="category" href="/tag/llm.html">LLM</a>,    <a class="category" href="/tag/aig.html">AIG</a>  </span>
=======
        <a href="https://songhuiming.github.io/author/huiming-song.html">Huiming Song</a>
    </span>
  </span>
<time datetime="2025-02-16T00:00:00-06:00" pubdate>Sun 16 February 2025</time>  <span class="categories">
    <a class='category' href='https://songhuiming.github.io/category/python.html'>python</a>
  </span>
  <span class="categories">
    <a class="category" href="https://songhuiming.github.io/tag/python.html">python</a>,    <a class="category" href="https://songhuiming.github.io/tag/ai.html">AI</a>,    <a class="category" href="https://songhuiming.github.io/tag/llm.html">LLM</a>,    <a class="category" href="https://songhuiming.github.io/tag/aig.html">AIG</a>  </span>
>>>>>>> f34c8db9 (ubuntu2025 update)
</p><div class="sharing">
</div>    </footer>
  </article>

<<<<<<< HEAD
=======
  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div>
  </section>
>>>>>>> f34c8db9 (ubuntu2025 update)
</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
<<<<<<< HEAD
          <a href="/pages/2025/02/16/deepseek-v3/">DeepSeek V3</a>
      </li>
      <li class="post">
          <a href="/pages/2023/10/01/image-generation-2-latent-diffusion-model-stable-diffusion/">Image Generation 2: Latent Diffusion model / Stable Diffusion</a>
      </li>
      <li class="post">
          <a href="/pages/2023/07/04/image-generation-1-diffusion-model/">Image Generation 1: Diffusion model</a>
      </li>
      <li class="post">
          <a href="/pages/2023/05/28/gpt-1-gpt-2-gpt-3-instructgpt-chatgpt-and-gpt-4-summary/">GPT-1, GPT-2, GPT-3, InstructGPT / ChatGPT and GPT-4 summary</a>
      </li>
      <li class="post">
          <a href="/pages/2021/12/31/recommendation-system-05-bayesian-optimization/">Recommendation System 05 - Bayesian Optimization</a>
=======
          <a href="https://songhuiming.github.io/pages/2025/02/16/deepseek-v3/">DeepSeek V3</a>
      </li>
      <li class="post">
          <a href="https://songhuiming.github.io/pages/2023/10/01/image-generation-2-latent-diffusion-model-stable-diffusion/">Image Generation 2: Latent Diffusion model / Stable Diffusion</a>
      </li>
      <li class="post">
          <a href="https://songhuiming.github.io/pages/2023/07/04/image-generation-1-diffusion-model/">Image Generation 1: Diffusion model</a>
      </li>
      <li class="post">
          <a href="https://songhuiming.github.io/pages/2023/05/28/gpt-1-gpt-2-gpt-3-instructgpt-chatgpt-and-gpt-4-summary/">GPT-1, GPT-2, GPT-3, InstructGPT / ChatGPT and GPT-4 summary</a>
      </li>
      <li class="post">
          <a href="https://songhuiming.github.io/pages/2021/12/31/recommendation-system-05-bayesian-optimization/">Recommendation System 05 - Bayesian Optimization</a>
>>>>>>> f34c8db9 (ubuntu2025 update)
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
<<<<<<< HEAD
        <li><a href="/category/career-growth.html">career growth</a></li>
        <li><a href="/category/linux.html">Linux</a></li>
        <li><a href="/category/python.html">python</a></li>
        <li><a href="/category/rthers.html">Rthers</a></li>
=======
        <li><a href="https://songhuiming.github.io/category/career-growth.html">career growth</a></li>
        <li><a href="https://songhuiming.github.io/category/linux.html">Linux</a></li>
        <li><a href="https://songhuiming.github.io/category/python.html">python</a></li>
        <li><a href="https://songhuiming.github.io/category/rthers.html">Rthers</a></li>
>>>>>>> f34c8db9 (ubuntu2025 update)
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
<<<<<<< HEAD
    <a href="/tag/pelican.html">pelican</a>,    <a href="/tag/apply_async.html">apply_async</a>,    <a href="/tag/ai.html">AI</a>,    <a href="/tag/mysql.html">mysql</a>,    <a href="/tag/deep-learning.html">deep learning</a>,    <a href="/tag/data-visualization.html">data visualization</a>,    <a href="/tag/llm.html">LLM</a>,    <a href="/tag/linux.html">linux</a>,    <a href="/tag/apply.html">apply</a>,    <a href="/tag/git.html">git</a>,    <a href="/tag/re.html">re</a>,    <a href="/tag/flask.html">flask</a>,    <a href="/tag/pyqt.html">PyQt</a>,    <a href="/tag/career-growth.html">career growth</a>,    <a href="/tag/python.html">python</a>,    <a href="/tag/bokeh.html">bokeh</a>,    <a href="/tag/quant.html">quant</a>,    <a href="/tag/remote-access.html">remote access</a>,    <a href="/tag/tensorflow.html">tensorflow</a>,    <a href="/tag/webcrawl.html">webCrawl</a>,    <a href="/tag/numpy.html">numpy</a>,    <a href="/tag/pandas.html">pandas</a>,    <a href="/tag/tweepy.html">tweepy</a>,    <a href="/tag/map.html">map</a>,    <a href="/tag/shiny.html">shiny</a>,    <a href="/tag/random-walk.html">random walk</a>,    <a href="/tag/dynamic-programming.html">dynamic programming</a>,    <a href="/tag/leetcode.html">leetcode</a>,    <a href="/tag/matplotlib.html">matplotlib</a>,    <a href="/tag/pytorch.html">pytorch</a>,    <a href="/tag/base.html">base</a>,    <a href="/tag/sentiment-analysis.html">sentiment analysis</a>,    <a href="/tag/sql.html">sql</a>,    <a href="/tag/docker.html">docker</a>,    <a href="/tag/data-minging.html">data minging</a>,    <a href="/tag/tkinter.html">tkinter</a>,    <a href="/tag/data-mining.html">data mining</a>,    <a href="/tag/spyre.html">spyre</a>,    <a href="/tag/highcharts.html">highcharts</a>,    <a href="/tag/r.html">R</a>,    <a href="/tag/statsmodels.html">statsmodels</a>,    <a href="/tag/aig.html">AIG</a>,    <a href="/tag/cx_freeze.html">cx_freeze</a>,    <a href="/tag/multiprocessing.html">multiprocessing</a>,    <a href="/tag/sklearn.html">sklearn</a>  </section>
=======
    <a href="https://songhuiming.github.io/tag/python.html">python</a>,    <a href="https://songhuiming.github.io/tag/ai.html">AI</a>,    <a href="https://songhuiming.github.io/tag/llm.html">LLM</a>,    <a href="https://songhuiming.github.io/tag/aig.html">AIG</a>,    <a href="https://songhuiming.github.io/tag/data-mining.html">data mining</a>,    <a href="https://songhuiming.github.io/tag/sklearn.html">sklearn</a>,    <a href="https://songhuiming.github.io/tag/pytorch.html">pytorch</a>,    <a href="https://songhuiming.github.io/tag/career-growth.html">career growth</a>,    <a href="https://songhuiming.github.io/tag/linux.html">linux</a>,    <a href="https://songhuiming.github.io/tag/deep-learning.html">deep learning</a>,    <a href="https://songhuiming.github.io/tag/leetcode.html">leetcode</a>,    <a href="https://songhuiming.github.io/tag/dynamic-programming.html">dynamic programming</a>,    <a href="https://songhuiming.github.io/tag/flask.html">flask</a>,    <a href="https://songhuiming.github.io/tag/highcharts.html">highcharts</a>,    <a href="https://songhuiming.github.io/tag/sql.html">sql</a>,    <a href="https://songhuiming.github.io/tag/webcrawl.html">webCrawl</a>,    <a href="https://songhuiming.github.io/tag/random-walk.html">random walk</a>,    <a href="https://songhuiming.github.io/tag/multiprocessing.html">multiprocessing</a>,    <a href="https://songhuiming.github.io/tag/data-visualization.html">data visualization</a>,    <a href="https://songhuiming.github.io/tag/numpy.html">numpy</a>,    <a href="https://songhuiming.github.io/tag/tensorflow.html">tensorflow</a>,    <a href="https://songhuiming.github.io/tag/quant.html">quant</a>,    <a href="https://songhuiming.github.io/tag/statsmodels.html">statsmodels</a>,    <a href="https://songhuiming.github.io/tag/pandas.html">pandas</a>,    <a href="https://songhuiming.github.io/tag/docker.html">docker</a>,    <a href="https://songhuiming.github.io/tag/matplotlib.html">matplotlib</a>,    <a href="https://songhuiming.github.io/tag/data-minging.html">data minging</a>,    <a href="https://songhuiming.github.io/tag/remote-access.html">remote access</a>,    <a href="https://songhuiming.github.io/tag/mysql.html">mysql</a>,    <a href="https://songhuiming.github.io/tag/base.html">base</a>,    <a href="https://songhuiming.github.io/tag/tweepy.html">tweepy</a>,    <a href="https://songhuiming.github.io/tag/bokeh.html">bokeh</a>,    <a href="https://songhuiming.github.io/tag/sentiment-analysis.html">sentiment analysis</a>,    <a href="https://songhuiming.github.io/tag/map.html">map</a>,    <a href="https://songhuiming.github.io/tag/apply.html">apply</a>,    <a href="https://songhuiming.github.io/tag/apply_async.html">apply_async</a>,    <a href="https://songhuiming.github.io/tag/git.html">git</a>,    <a href="https://songhuiming.github.io/tag/pyqt.html">PyQt</a>,    <a href="https://songhuiming.github.io/tag/cx_freeze.html">cx_freeze</a>,    <a href="https://songhuiming.github.io/tag/tkinter.html">tkinter</a>,    <a href="https://songhuiming.github.io/tag/pelican.html">pelican</a>,    <a href="https://songhuiming.github.io/tag/spyre.html">spyre</a>,    <a href="https://songhuiming.github.io/tag/shiny.html">shiny</a>,    <a href="https://songhuiming.github.io/tag/r.html">R</a>,    <a href="https://songhuiming.github.io/tag/re.html">re</a>  </section>
>>>>>>> f34c8db9 (ubuntu2025 update)


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://www.linkedin.com/pub/huiming-song/24/735/349" target="_blank">Linkedin</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://easysas.blogspot.com/" target="_blank">my old SAS blog</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2015&ndash;2025  shm &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
<<<<<<< HEAD
  <script src="/theme/js/modernizr-2.0.js"></script>
  <script src="/theme/js/ender.js"></script>
  <script src="/theme/js/octopress.js" type="text/javascript"></script>
=======
  <script src="https://songhuiming.github.io/theme/js/modernizr-2.0.js"></script>
  <script src="https://songhuiming.github.io/theme/js/ender.js"></script>
  <script src="https://songhuiming.github.io/theme/js/octopress.js" type="text/javascript"></script>
>>>>>>> f34c8db9 (ubuntu2025 update)
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-65938411-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-65938411-1');
    ga('send', 'pageview');
</script>
  <script type="text/javascript">
    var disqus_shortname = 'songhuiming';
    var disqus_identifier = '/pages/2025/02/16/deepseek-v3/';
<<<<<<< HEAD
    var disqus_url = '/pages/2025/02/16/deepseek-v3/';
=======
    var disqus_url = 'https://songhuiming.github.io/pages/2025/02/16/deepseek-v3/';
>>>>>>> f34c8db9 (ubuntu2025 update)
    var disqus_title = 'DeepSeek V3';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = "//" + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
  </script>
</body>
</html>