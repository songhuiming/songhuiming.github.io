<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Credit Card Fraud Detection / Imbalanced data modeling - Part III: Ensembling/Stacking models &mdash; pydata</title>
  <meta name="author" content="shm">






  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="/favicon.png" rel="icon">

  <link href="/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="/">pydata</a></h1>
    <h2>Keep Looking, Don't Settle</h2>
</hgroup>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
        MathJax.Hub.Config({
            config: ["MMLorHTML.js"],
            extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js"],
            jax: ["input/TeX"],
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                processEscapes: false
            },
            TeX: {
                TagSide: "right",
                TagIndent: ".8em",
                MultLineWidth: "85%",
                equationNumbers: {
                   autoNumber: "AMS",
                },
                unicode: {
                   fonts: "STIXGeneral,'Arial Unicode MS'"
                }
            },
            showProcessingMessages: false
        });
</script></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
</ul>

<form class="search" action="/search.html">
    <input type="text" class="search-query" placeholder="Search" name="q" id="s">
</form>

<form action="https://www.google.com/search" method="get">
    <fieldset role="search">
       <input type="hidden" name="q" value="site:songhuiming.github.io" />
       <input class="search" type="text" name="q" results="0" placeholder="Search"/>
    </fieldset>
</form>


<ul class="main-navigation">
    <li><a href="/functions/archives.html">Archives</a></li>
      <li >
        <a href="/category/career-growth.html">Career growth</a>
      </li>
      <li >
        <a href="/category/linux.html">Linux</a>
      </li>
      <li class="active">
        <a href="/category/python.html">Python</a>
      </li>
      <li >
        <a href="/category/rthers.html">Rthers</a>
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Credit Card Fraud Detection / Imbalanced data modeling - Part III: Ensembling/Stacking models</h1>
    <p class="meta">
<time datetime="2018-05-12T19:08:00-05:00" pubdate>Sat 12 May 2018</time>    </p>
</header>

  <div class="entry-content"><h1>Table of Contents<span class="tocSkip"></span></h1>

<div class="toc"><ul class="toc-item"><li><span><a href="#0.-Data-Preparation" data-toc-modified-id="0.-Data-Preparation-1">0. Data Preparation</a></span></li><li><span><a href="#Modeling-Part-3:-Ensembing(Stacking)-Models" data-toc-modified-id="Modeling-Part-3:-Ensembing(Stacking)-Models-2">Modeling Part 3: Ensembing(Stacking) Models</a></span></li><li><span><a href="#1.-More-models-with-GridSearchCV-to-Select-Hyperparameters" data-toc-modified-id="1.-More-models-with-GridSearchCV-to-Select-Hyperparameters-3">1. More models with GridSearchCV to Select Hyperparameters</a></span><ul class="toc-item"><li><span><a href="#1.1.-Prepare-base-models" data-toc-modified-id="1.1.-Prepare-base-models-3.1">1.1. Prepare base models</a></span></li><li><span><a href="#1.2.-GridSearch-to-find-the-best-hyperparameters" data-toc-modified-id="1.2.-GridSearch-to-find-the-best-hyperparameters-3.2">1.2. GridSearch to find the best hyperparameters</a></span></li><li><span><a href="#1.3.-Base-models-performance" data-toc-modified-id="1.3.-Base-models-performance-3.3">1.3. Base models performance</a></span></li><li><span><a href="#1.4.-Stacking" data-toc-modified-id="1.4.-Stacking-3.4">1.4. Stacking</a></span></li><li><span><a href="#1.5.-Single-base-model-parameters-and-results" data-toc-modified-id="1.5.-Single-base-model-parameters-and-results-3.5">1.5. Single base model parameters and results</a></span></li></ul></li></ul></div>

<div class="highlight"><pre><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">Normalizer</span><span class="p">,</span> <span class="n">scale</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">AdaBoostClassifier</span><span class="p">,</span> <span class="n">GradientBoostingClassifier</span><span class="p">,</span> <span class="n">ExtraTreesClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span><span class="p">,</span> <span class="n">LinearSVC</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">log_loss</span><span class="p">,</span> <span class="n">auc</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">precision_recall_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">fbeta_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">StratifiedShuffleSplit</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>

<span class="n">seed</span> <span class="o">=</span> <span class="mi">999</span>

<span class="n">creditcard</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;creditcard.csv&#39;</span><span class="p">)</span>
<span class="n">creditcard</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">creditcard</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
<span class="n">creditcard</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;class&#39;</span><span class="p">:</span> <span class="s1">&#39;fraud&#39;</span><span class="p">},</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
</pre></div>


<h1>0. Data Preparation</h1>
<p>Read in the data. Since the data is from <code>PCA</code>, there is no missing data issue. Then we will normalize the amount.</p>
<div class="highlight"><pre><span class="c1"># 1. Split Test Data Out</span>
<span class="n">creditcard</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="s1">&#39;time&#39;</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

<span class="c1"># Normalize the &#39;amount&#39; column</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">creditcard</span><span class="p">[</span><span class="s1">&#39;amount&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">creditcard</span><span class="p">[</span><span class="s1">&#39;amount&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="c1"># creditcard.drop(columns = &#39;amount&#39;, inplace = True)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">creditcard</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">creditcard</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="o">.</span><span class="mi">33</span><span class="p">,</span> <span class="n">stratify</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>
</pre></div>


<h1>Modeling Part 3: Ensembing(Stacking) Models</h1>
<p>In <a href="http://songhuiming.github.io/pages/2018/05/05/credit-card-fraud-detection-imbalanced-data-modeling-part-i-logistic-regression/">Part I</a> and <a href="http://songhuiming.github.io/pages/2018/05/12/credit-card-fraud-detection-imbalanced-data-modeling-part-ii-random-forest/">Part II</a>, we have tested the Logistic Regression and Random Forest models on this imbalanced data.</p>
<p>Here we will try the ebsembing models by combining the predictions of multiple machine learning models. The basic idea is to use multiple base models to predict the data, and then use another model to combine these base model results. Since these base models results will be used as input in the new model, the base models results will be better if they are higher in performance and less correlated. If the base models results are high correlated, then combining them will not improve too much since all the input are correlated. Ensembling / Stacking models have these advantages:</p>
<div class="highlight"><pre>1. A lot of the time, it can beat most state-of-art single model
2. Each single base model can be simple and built quickly
</pre></div>


<p>Here we will do these things:</p>
<div class="highlight"><pre>1. Prepare a series of base models: RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, and LinearSVC models.
2. Use GridSearchCV to select the hyperparameters for these candidate models
3. Use the output from the base models as input to build a new model
</pre></div>


<h1>1. More models with GridSearchCV to Select Hyperparameters</h1>
<h2>1.1. Prepare base models</h2>
<p>We will use these models: <code>RandomForestClassifier</code>, <code>ExtraTreesClassifier</code>, <code>AdaBoostClassifier</code>, <code>GradientBoostingClassifier</code>, and <code>LinearSVC</code> models.</p>
<div class="highlight"><pre><span class="n">seed</span> <span class="o">=</span> <span class="mi">999</span>

<span class="n">oversample_ratio</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ytrain</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ytrain</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># size to repeat y == 1</span>
<span class="c1"># repeat the positive data for X and y</span>
<span class="n">ytrain_pos_oversample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">ytrain</span><span class="p">[</span><span class="n">ytrain</span><span class="o">==</span><span class="mi">1</span><span class="p">]]</span> <span class="o">*</span> <span class="n">oversample_ratio</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">Xtrain_pos_oversample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">Xtrain</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">ytrain</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]]</span> <span class="o">*</span> <span class="n">oversample_ratio</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="c1"># concat the repeated data with the original data together</span>
<span class="n">ytrain_oversample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">ytrain</span><span class="p">,</span> <span class="n">ytrain_pos_oversample</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">Xtrain_oversample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtrain_pos_oversample</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

<span class="n">models</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;rf&#39;</span><span class="p">:</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">,</span> <span class="n">warm_start</span> <span class="o">=</span> <span class="bp">True</span><span class="p">),</span>  <span class="c1"># 0:17:24.925482</span>
    <span class="s1">&#39;et&#39;</span><span class="p">:</span> <span class="n">ExtraTreesClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">,</span> <span class="n">warm_start</span> <span class="o">=</span> <span class="bp">True</span><span class="p">),</span>  <span class="c1"># 0:02:45.797856</span>
    <span class="s1">&#39;ada&#39;</span><span class="p">:</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">),</span>   <span class="c1">#0:05:17.973671</span>
    <span class="s1">&#39;gb&#39;</span><span class="p">:</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">,</span> <span class="n">warm_start</span> <span class="o">=</span> <span class="bp">True</span><span class="p">),</span>   <span class="c1">#0:54:11.773175</span>
    <span class="s1">&#39;svc&#39;</span><span class="p">:</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span> <span class="p">}</span>   <span class="c1">#0:02:01.656640</span>

<span class="n">gv_parameters</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;rf&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span> <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">]},</span>
    <span class="s1">&#39;et&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span> <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">]},</span>
    <span class="s1">&#39;ada&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.75</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">]},</span>
    <span class="s1">&#39;gb&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span> <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">]},</span>
    <span class="s1">&#39;svc&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="mf">5.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">))}</span> <span class="p">}</span>
</pre></div>


<h2>1.2. GridSearch to find the best hyperparameters</h2>
<p>For each model's hyperparameter combinations, <code>GridSearchCV</code> will loop through the combinations and find the parameters that gives the best performance metric. This will be time consuming if the data is big or if the model is slow(like <code>SVM</code>) or complicated.</p>
<div class="highlight"><pre><span class="n">grid_searches</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">models</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;---------------------------------Running GridSearchCV for </span><span class="si">%s</span><span class="s2">. ---------------&quot;</span> <span class="o">%</span> <span class="n">key</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">gv_parameters</span><span class="p">[</span><span class="n">key</span><span class="p">]</span>
    <span class="n">gs</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="mi">70</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">wt_loss_score</span><span class="p">)</span>
    <span class="n">ts</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
    <span class="n">gs</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain_oversample</span><span class="p">,</span> <span class="n">ytrain_oversample</span><span class="p">)</span>
    <span class="n">te</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
    <span class="k">print</span> <span class="p">(</span><span class="s2">&quot;run time for &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; is: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">ts</span><span class="o">-</span><span class="n">te</span><span class="p">))</span>
    <span class="n">grid_searches</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">gs</span>

<span class="c1"># to get the summary information of the model results from GridSearchCV on all parameter combinations</span>
<span class="k">def</span> <span class="nf">grid_cv_summary</span><span class="p">(</span><span class="n">grid_searches</span><span class="p">):</span>
    <span class="n">cv_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">grid_searches</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">model_result</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">grid_searches</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>
        <span class="n">model_result</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">key</span>
        <span class="n">cv_results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">cv_results</span><span class="p">,</span> <span class="n">model_result</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cv_results</span>

<span class="n">cv_sum</span> <span class="o">=</span> <span class="n">grid_cv_summary</span><span class="p">(</span><span class="n">grid_searches</span><span class="p">)</span>
<span class="n">cv_grp</span> <span class="o">=</span> <span class="n">cv_sum</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">)</span>
<span class="c1"># get the best_params_ for the model with highest mean_test_score</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="n">cv_grp</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">mean_test_score</span> <span class="o">==</span> <span class="n">x</span><span class="o">.</span><span class="n">mean_test_score</span><span class="o">.</span><span class="n">max</span><span class="p">()])</span><span class="o">.</span><span class="n">params</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">best_params</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">get_level_values</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">best_params</span><span class="o">.</span><span class="n">values</span><span class="p">))</span>
</pre></div>


<h2>1.3. Base models performance</h2>
<p>For each base model, we print out their recall/performance/roc_auc score and confusion matrix. If we only look at ROC, then <code>LinearSVC</code> gives the best single model, although it has lower precision score than the other models.</p>
<div class="highlight"><pre><span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">grid_searches</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="n">pred_test</span> <span class="o">=</span> <span class="n">grid_searches</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
    <span class="k">print</span> <span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n\n</span><span class="s2">----------- For </span><span class="si">%s</span><span class="s2">, the metrics on TEST data is: ---------- </span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">%</span><span class="n">key</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;recall score on test data is </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span><span class="nb">str</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">)))</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;precision score on test data is </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span><span class="nb">str</span><span class="p">(</span><span class="n">precision_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">)))</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;roc_auc score on test data is </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span><span class="nb">str</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">)))</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;confusion matrix on the test data is: </span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre>----------- For et, the metrics on TEST data is: ----------

recall score on test data is 0.845679012345679
precision score on test data is 0.7696629213483146
roc_auc score on test data is 0.9226210142996714
confusion matrix on the test data is:

[[93784    41]
 [   25   137]]


----------- For rf, the metrics on TEST data is: ----------

recall score on test data is 0.8271604938271605
precision score on test data is 0.8481012658227848
roc_auc score on test data is 0.9134523492317259
confusion matrix on the test data is:

[[93801    24]
 [   28   134]]


----------- For ada, the metrics on TEST data is: ----------

recall score on test data is 0.845679012345679
precision score on test data is 0.7828571428571428
roc_auc score on test data is 0.9226370015099032
confusion matrix on the test data is:

[[93787    38]
 [   25   137]]


----------- For svc, the metrics on TEST data is: ----------

recall score on test data is 0.9320987654320988
precision score on test data is 0.06425531914893617
roc_auc score on test data is 0.9543307576161294
confusion matrix on the test data is:

[[91626  2199]
 [   11   151]]


----------- For gb, the metrics on TEST data is: ----------

recall score on test data is 0.8271604938271605
precision score on test data is 0.8535031847133758
roc_auc score on test data is 0.9134576783018031
confusion matrix on the test data is:

[[93802    23]
 [   28   134]]
</pre></div>


<h2>1.4. Stacking</h2>
<p>We will collect the output from the base models and put them as input into the new model. Here the base model outputs are correlated since there are too many 0. So the outpur from stacking did not improve too much compared to the single model. We can try GridSearch again to see if it can be improved. </p>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">multiple_pred</span><span class="p">(</span><span class="n">grid_searches</span><span class="p">,</span> <span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span><span class="p">):</span>
    <span class="n">train_pred</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">test_pred</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">grid_searches</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">train_pred</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">grid_searches</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">)</span>
        <span class="n">test_pred</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">grid_searches</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">((</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_pred</span><span class="p">),</span> <span class="n">ytrain</span><span class="p">),</span> <span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">test_pred</span><span class="p">),</span> <span class="n">ytest</span><span class="p">))</span>

<span class="n">ensemble_data</span> <span class="o">=</span> <span class="n">multiple_pred</span><span class="p">(</span><span class="n">grid_searches</span><span class="p">,</span> <span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span><span class="p">)</span>

<span class="c1"># ensembling model, change to xgb later</span>
<span class="n">gbc</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">()</span>
<span class="n">gbc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">ensemble_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">ensemble_data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>

<span class="n">pred</span> <span class="o">=</span> <span class="n">gbc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">ensemble_data</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>
<span class="k">print</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">ensemble_data</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">pred</span><span class="p">)</span>
<span class="k">print</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">ensemble_data</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">pred</span><span class="p">)</span>
<span class="k">print</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">ensemble_data</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">pred</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre>0.827160493827

[[93802    23]
 [   28   134]]

             precision    recall  f1-score   support

          0       1.00      1.00      1.00     93825
          1       0.85      0.83      0.84       162

avg / total       1.00      1.00      1.00     93987
</pre></div>


<h2>1.5. Single base model parameters and results</h2>
<div class="highlight"><pre><span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">grid_searches</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
    <span class="k">print</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">grid_searches</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
    <span class="n">pred_grid</span> <span class="o">=</span> <span class="n">grid_searches</span><span class="p">[</span><span class="n">key</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_grid</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_grid</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_grid</span><span class="p">))</span>
    <span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre>et
{&#39;n_estimators&#39;: 500, &#39;max_depth&#39;: 50, &#39;min_samples_leaf&#39;: 10}
0.9226210143
0.845679012346
[[93784    41]
 [   25   137]]


rf
{&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 50, &#39;min_samples_leaf&#39;: 10}
0.913452349232
0.827160493827
[[93801    24]
 [   28   134]]


ada
{&#39;n_estimators&#39;: 500, &#39;learning_rate&#39;: 1.5}
0.92263700151
0.845679012346
[[93787    38]
 [   25   137]]


svc
{&#39;C&#39;: 1.0}
0.954330757616
0.932098765432
[[91626  2199]
 [   11   151]]


gb
{&#39;n_estimators&#39;: 200, &#39;max_depth&#39;: 50, &#39;min_samples_leaf&#39;: 20}
0.913457678302
0.827160493827
[[93802    23]
 [   28   134]]
</pre></div></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
        <a href="/author/huiming-song.html">Huiming Song</a>
    </span>
  </span>
<time datetime="2018-05-12T19:08:00-05:00" pubdate>Sat 12 May 2018</time>  <span class="categories">
    <a class='category' href='/category/python.html'>Python</a>
  </span>
  <span class="categories">
    <a class="category" href="/tag/python.html">python</a>,    <a class="category" href="/tag/data-mining.html">data mining</a>,    <a class="category" href="/tag/sklearn.html">sklearn</a>  </span>
</p><div class="sharing">
</div>    </footer>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="/pages/2021/11/06/recommendation-system-03/">Recommendation System 03</a>
      </li>
      <li class="post">
          <a href="/pages/2021/11/06/recommendation-system-02/">Recommendation System 02</a>
      </li>
      <li class="post">
          <a href="/pages/2021/10/30/recommendation-system-01/">Recommendation System 01</a>
      </li>
      <li class="post">
          <a href="/pages/2021/10/22/zhi-chang-hua-ti-bei-mei-hua-ren-gao-guan-zong-jie-de-zhi-chang-shang-sheng-fang-fa/">职场话题——北美华人高管总结的职场上升方法</a>
      </li>
      <li class="post">
          <a href="/pages/2019/07/27/2019-07-27-week-30-gong-ju-he-ji/">2019-07-27 Week 30 工具合集</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="/category/career-growth.html">career growth</a></li>
        <li><a href="/category/linux.html">Linux</a></li>
        <li><a href="/category/python.html">python</a></li>
        <li><a href="/category/rthers.html">Rthers</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="/tag/pelican.html">pelican</a>,    <a href="/tag/apply_async.html">apply_async</a>,    <a href="/tag/mysql.html">mysql</a>,    <a href="/tag/deep-learning.html">deep learning</a>,    <a href="/tag/data-visualization.html">data visualization</a>,    <a href="/tag/linux.html">linux</a>,    <a href="/tag/apply.html">apply</a>,    <a href="/tag/git.html">git</a>,    <a href="/tag/re.html">re</a>,    <a href="/tag/flask.html">flask</a>,    <a href="/tag/pyqt.html">PyQt</a>,    <a href="/tag/career-growth.html">career growth</a>,    <a href="/tag/dynamic-programming.html">dynamic programming</a>,    <a href="/tag/bokeh.html">bokeh</a>,    <a href="/tag/quant.html">quant</a>,    <a href="/tag/remote-access.html">remote access</a>,    <a href="/tag/tensorflow.html">tensorflow</a>,    <a href="/tag/webcrawl.html">webCrawl</a>,    <a href="/tag/numpy.html">numpy</a>,    <a href="/tag/pandas.html">pandas</a>,    <a href="/tag/tweepy.html">tweepy</a>,    <a href="/tag/map.html">map</a>,    <a href="/tag/shiny.html">shiny</a>,    <a href="/tag/random-walk.html">random walk</a>,    <a href="/tag/python.html">python</a>,    <a href="/tag/leetcode.html">leetcode</a>,    <a href="/tag/matplotlib.html">matplotlib</a>,    <a href="/tag/pytorch.html">pytorch</a>,    <a href="/tag/base.html">base</a>,    <a href="/tag/sentiment-analysis.html">sentiment analysis</a>,    <a href="/tag/sql.html">sql</a>,    <a href="/tag/data-minging.html">data minging</a>,    <a href="/tag/tkinter.html">tkinter</a>,    <a href="/tag/data-mining.html">data mining</a>,    <a href="/tag/spyre.html">spyre</a>,    <a href="/tag/highcharts.html">highcharts</a>,    <a href="/tag/r.html">R</a>,    <a href="/tag/statsmodels.html">statsmodels</a>,    <a href="/tag/docker.html">docker</a>,    <a href="/tag/cx_freeze.html">cx_freeze</a>,    <a href="/tag/multiprocessing.html">multiprocessing</a>,    <a href="/tag/sklearn.html">sklearn</a>  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://www.linkedin.com/pub/huiming-song/24/735/349" target="_blank">Linkedin</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://easysas.blogspot.com/" target="_blank">my old SAS blog</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2015&ndash;2021  shm &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="/theme/js/modernizr-2.0.js"></script>
  <script src="/theme/js/ender.js"></script>
  <script src="/theme/js/octopress.js" type="text/javascript"></script>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-65938411-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-65938411-1');
    ga('send', 'pageview');
</script>
  <script type="text/javascript">
    var disqus_shortname = 'songhuiming';
    var disqus_identifier = '/pages/2018/05/12/credit-card-fraud-detection-imbalanced-data-modeling-part-iii-ensemblingstacking-models/';
    var disqus_url = '/pages/2018/05/12/credit-card-fraud-detection-imbalanced-data-modeling-part-iii-ensemblingstacking-models/';
    var disqus_title = 'Credit Card Fraud Detection / Imbalanced data modeling - Part III: Ensembling/Stacking models';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = "//" + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
  </script>
</body>
</html>