<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Credit Card Fraud Detection / Imbalanced data modeling - Part III: Ensembling/Stacking models &mdash; pydata: Huiming's learning notes</title>
  <meta name="author" content="shm">






  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="/favicon.png" rel="icon">

  <link href="/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><header>
  <h1><a href="/">pydata: Huiming's learning notes</a></h1>
    <h2>Keep Looking, Don't Settle</h2>
</header>

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],  // 允许 $...$ 和 \( ... \) 作为行内公式
    displayMath: [['$$', '$$'], ['\\[', '\\]']],  // 允许 $$...$$ 和 \[ ... \] 作为块级公式
    processEscapes: true,  // 允许在公式中使用转义符，如 \$ 表示美元符号
    processEnvironments: true  // 允许解析 \begin{equation} ... \end{equation} 等数学环境
  },
  options: {
    skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],  // 跳过某些 HTML 标签，防止错误解析
    renderActions: {
      addMenu: []  // 移除右键菜单
    }
  }
};

window.addEventListener('load', () => {
  document.querySelectorAll("mjx-container").forEach(x => {
    x.parentElement.classList.add('has-jax');  // 使用 classList.add() 避免字符串拼接错误
  });
});
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script></header>
  <nav role="navigation">

<form action="https://www.google.com/search" method="get">
    <fieldset role="search">
       <input type="hidden" name="q" value="site:songhuiming.github.io" />
       <input class="search" type="text" name="q" results="0" placeholder="Search"/>
    </fieldset>
</form>


<ul class="main-navigation">
    <li><a href="/functions/archives.html">Archives</a></li>
      <li >
        <a href="/category/career-growth.html">Career growth</a>
      </li>
      <li >
        <a href="/category/linux.html">Linux</a>
      </li>
      <li class="active">
        <a href="/category/python.html">Python</a>
      </li>
      <li >
        <a href="/category/rthers.html">Rthers</a>
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Credit Card Fraud Detection / Imbalanced data modeling - Part III: Ensembling/Stacking models</h1>
    <p class="meta">
<time datetime="2018-05-12T19:08:00-05:00" pubdate>Sat 12 May 2018</time>    </p>
</header>

  <div class="entry-content"><h1>Table of Contents<span class="tocSkip"></span></h1>
<div class="toc"><ul class="toc-item"><li><span><a href="#0.-Data-Preparation" data-toc-modified-id="0.-Data-Preparation-1">0. Data Preparation</a></span></li><li><span><a href="#Modeling-Part-3:-Ensembing(Stacking)-Models" data-toc-modified-id="Modeling-Part-3:-Ensembing(Stacking)-Models-2">Modeling Part 3: Ensembing(Stacking) Models</a></span></li><li><span><a href="#1.-More-models-with-GridSearchCV-to-Select-Hyperparameters" data-toc-modified-id="1.-More-models-with-GridSearchCV-to-Select-Hyperparameters-3">1. More models with GridSearchCV to Select Hyperparameters</a></span><ul class="toc-item"><li><span><a href="#1.1.-Prepare-base-models" data-toc-modified-id="1.1.-Prepare-base-models-3.1">1.1. Prepare base models</a></span></li><li><span><a href="#1.2.-GridSearch-to-find-the-best-hyperparameters" data-toc-modified-id="1.2.-GridSearch-to-find-the-best-hyperparameters-3.2">1.2. GridSearch to find the best hyperparameters</a></span></li><li><span><a href="#1.3.-Base-models-performance" data-toc-modified-id="1.3.-Base-models-performance-3.3">1.3. Base models performance</a></span></li><li><span><a href="#1.4.-Stacking" data-toc-modified-id="1.4.-Stacking-3.4">1.4. Stacking</a></span></li><li><span><a href="#1.5.-Single-base-model-parameters-and-results" data-toc-modified-id="1.5.-Single-base-model-parameters-and-results-3.5">1.5. Single base model parameters and results</a></span></li></ul></li></ul></div>

<pre><code class="language-python">import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler, Normalizer, scale
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.metrics import confusion_matrix, log_loss, auc, roc_curve, roc_auc_score, recall_score, precision_recall_curve
from sklearn.metrics import make_scorer, precision_score, fbeta_score, f1_score, classification_report
from sklearn.model_selection import cross_val_score, train_test_split, KFold, StratifiedShuffleSplit, GridSearchCV
from sklearn.linear_model import LogisticRegression

%matplotlib inline
plt.rcParams['figure.figsize'] = (16, 9)

seed = 999

creditcard = pd.read_csv('creditcard.csv')
creditcard.columns = [x.lower() for x in creditcard.columns]
creditcard.rename(columns = {'class': 'fraud'}, inplace = True)
</code></pre>
<h1>0. Data Preparation</h1>
<p>Read in the data. Since the data is from <code>PCA</code>, there is no missing data issue. Then we will normalize the amount.</p>
<pre><code class="language-python"># 1. Split Test Data Out
creditcard.drop(columns = 'time', inplace = True)

# Normalize the 'amount' column
scaler = StandardScaler()
creditcard['amount'] = scaler.fit_transform(creditcard['amount'].values.reshape(-1, 1))
# creditcard.drop(columns = 'amount', inplace = True)

X = creditcard.iloc[:, :-1]
y = creditcard.iloc[:, -1]
Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = .33, stratify = y, random_state = seed)
</code></pre>
<h1>Modeling Part 3: Ensembing(Stacking) Models</h1>
<p>In <a href="http://songhuiming.github.io/pages/2018/05/05/credit-card-fraud-detection-imbalanced-data-modeling-part-i-logistic-regression/">Part I</a> and <a href="http://songhuiming.github.io/pages/2018/05/12/credit-card-fraud-detection-imbalanced-data-modeling-part-ii-random-forest/">Part II</a>, we have tested the Logistic Regression and Random Forest models on this imbalanced data.</p>
<p>Here we will try the ebsembing models by combining the predictions of multiple machine learning models. The basic idea is to use multiple base models to predict the data, and then use another model to combine these base model results. Since these base models results will be used as input in the new model, the base models results will be better if they are higher in performance and less correlated. If the base models results are high correlated, then combining them will not improve too much since all the input are correlated. Ensembling / Stacking models have these advantages:</p>
<pre><code>1. A lot of the time, it can beat most state-of-art single model
2. Each single base model can be simple and built quickly
</code></pre>
<p>Here we will do these things:</p>
<pre><code>1. Prepare a series of base models: RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, and LinearSVC models.
2. Use GridSearchCV to select the hyperparameters for these candidate models
3. Use the output from the base models as input to build a new model
</code></pre>
<h1>1. More models with GridSearchCV to Select Hyperparameters</h1>
<h2>1.1. Prepare base models</h2>
<p>We will use these models: <code>RandomForestClassifier</code>, <code>ExtraTreesClassifier</code>, <code>AdaBoostClassifier</code>, <code>GradientBoostingClassifier</code>, and <code>LinearSVC</code> models.</p>
<pre><code class="language-python">seed = 999

oversample_ratio = sum(ytrain == 0) / sum(ytrain == 1)  # size to repeat y == 1
# repeat the positive data for X and y
ytrain_pos_oversample = pd.concat([ytrain[ytrain==1]] * oversample_ratio, axis = 0)
Xtrain_pos_oversample = pd.concat([Xtrain.loc[ytrain==1, :]] * oversample_ratio, axis = 0)
# concat the repeated data with the original data together
ytrain_oversample = pd.concat([ytrain, ytrain_pos_oversample], axis = 0).reset_index(drop = True)
Xtrain_oversample = pd.concat([Xtrain, Xtrain_pos_oversample], axis = 0).reset_index(drop = True)

models = {
    'rf': RandomForestClassifier(random_state = seed, warm_start = True),  # 0:17:24.925482
    'et': ExtraTreesClassifier(random_state = seed, warm_start = True),  # 0:02:45.797856
    'ada': AdaBoostClassifier(random_state = seed),   #0:05:17.973671
    'gb': GradientBoostingClassifier(random_state = seed, warm_start = True),   #0:54:11.773175
    'svc': LinearSVC(random_state = seed) }   #0:02:01.656640

gv_parameters = {
    'rf': {'n_estimators': [50, 100, 200, 500], 'max_depth': [10, 20, 50, 100], 'min_samples_leaf': [10, 20, 50]},
    'et': {'n_estimators': [50, 100, 200, 500], 'max_depth': [10, 20, 50, 100], 'min_samples_leaf': [10, 20, 50]},
    'ada': {'n_estimators': [50, 100, 200, 500], 'learning_rate': [0.75, 1, 1.5]},
    'gb': {'n_estimators': [50, 100, 200, 500], 'max_depth': [10, 20, 50, 100], 'min_samples_leaf': [10, 20, 50]},
    'svc': {'C': np.power(5.0, np.arange(-3,3))} }

</code></pre>
<h2>1.2. GridSearch to find the best hyperparameters</h2>
<p>For each model's hyperparameter combinations, <code>GridSearchCV</code> will loop through the combinations and find the parameters that gives the best performance metric. This will be time consuming if the data is big or if the model is slow(like <code>SVM</code>) or complicated.</p>
<pre><code class="language-python">grid_searches = {}
for key in models.keys():
    print(&quot;---------------------------------Running GridSearchCV for %s. ---------------&quot; % key)
    model = models[key]
    params = gv_parameters[key]
    gs = GridSearchCV(model, params, cv = 3, n_jobs = 70, verbose = 3, scoring=wt_loss_score)
    ts = datetime.datetime.now()
    gs.fit(Xtrain_oversample, ytrain_oversample)
    te = datetime.datetime.now()
    print (&quot;run time for &quot; + str(key) + &quot; is: &quot; + str(ts-te))
    grid_searches[key] = gs

# to get the summary information of the model results from GridSearchCV on all parameter combinations
def grid_cv_summary(grid_searches):
    cv_results = pd.DataFrame()
    for key in grid_searches.keys():
        model_result = pd.DataFrame(grid_searches[key].cv_results_)
        model_result['model'] = key
        cv_results = pd.concat([cv_results, model_result], axis = 0)
    return cv_results

cv_sum = grid_cv_summary(grid_searches)
cv_grp = cv_sum.groupby('model')
# get the best_params_ for the model with highest mean_test_score
best_params = cv_grp.apply(lambda x: x[x.mean_test_score == x.mean_test_score.max()]).params
best_params = dict(zip(best_params.index.get_level_values(0), best_params.values))
</code></pre>
<h2>1.3. Base models performance</h2>
<p>For each base model, we print out their recall/performance/roc_auc score and confusion matrix. If we only look at ROC, then <code>LinearSVC</code> gives the best single model, although it has lower precision score than the other models.</p>
<pre><code class="language-python">for key in grid_searches.keys():
    pred_test = grid_searches[key].predict(Xtest)
    print (&quot;\n\n\n----------- For %s, the metrics on TEST data is: ---------- \n&quot; %key)
    print(&quot;recall score on test data is %s&quot; %str(recall_score(ytest, pred_test)))
    print(&quot;precision score on test data is %s&quot; %str(precision_score(ytest, pred_test)))
    print(&quot;roc_auc score on test data is %s&quot; %str(roc_auc_score(ytest, pred_test)))
    print(&quot;confusion matrix on the test data is: \n&quot;)
    print(confusion_matrix(ytest, pred_test))
</code></pre>
<pre><code>----------- For et, the metrics on TEST data is: ----------

recall score on test data is 0.845679012345679
precision score on test data is 0.7696629213483146
roc_auc score on test data is 0.9226210142996714
confusion matrix on the test data is:

[[93784    41]
 [   25   137]]


----------- For rf, the metrics on TEST data is: ----------

recall score on test data is 0.8271604938271605
precision score on test data is 0.8481012658227848
roc_auc score on test data is 0.9134523492317259
confusion matrix on the test data is:

[[93801    24]
 [   28   134]]


----------- For ada, the metrics on TEST data is: ----------

recall score on test data is 0.845679012345679
precision score on test data is 0.7828571428571428
roc_auc score on test data is 0.9226370015099032
confusion matrix on the test data is:

[[93787    38]
 [   25   137]]


----------- For svc, the metrics on TEST data is: ----------

recall score on test data is 0.9320987654320988
precision score on test data is 0.06425531914893617
roc_auc score on test data is 0.9543307576161294
confusion matrix on the test data is:

[[91626  2199]
 [   11   151]]


----------- For gb, the metrics on TEST data is: ----------

recall score on test data is 0.8271604938271605
precision score on test data is 0.8535031847133758
roc_auc score on test data is 0.9134576783018031
confusion matrix on the test data is:

[[93802    23]
 [   28   134]]
</code></pre>
<h2>1.4. Stacking</h2>
<p>We will collect the output from the base models and put them as input into the new model. Here the base model outputs are correlated since there are too many 0. So the outpur from stacking did not improve too much compared to the single model. We can try GridSearch again to see if it can be improved. </p>
<pre><code class="language-python">def multiple_pred(grid_searches, Xtrain, Xtest, ytrain, ytest):
    train_pred = {}
    test_pred = {}
    for key in grid_searches.keys():
        train_pred[key] = grid_searches[key].predict(Xtrain)
        test_pred[key] = grid_searches[key].predict(Xtest)
    return ((pd.DataFrame(train_pred), ytrain), (pd.DataFrame(test_pred), ytest))

ensemble_data = multiple_pred(grid_searches, Xtrain, Xtest, ytrain, ytest)

# ensembling model, change to xgb later
gbc = GradientBoostingClassifier()
gbc.fit(ensemble_data[0][0], ensemble_data[0][1])

pred = gbc.predict(ensemble_data[1][0])
print recall_score(ensemble_data[1][1], pred)
print confusion_matrix(ensemble_data[1][1], pred)
print classification_report(ensemble_data[1][1], pred)
</code></pre>
<pre><code>0.827160493827

[[93802    23]
 [   28   134]]

             precision    recall  f1-score   support

          0       1.00      1.00      1.00     93825
          1       0.85      0.83      0.84       162

avg / total       1.00      1.00      1.00     93987
</code></pre>
<h2>1.5. Single base model parameters and results</h2>
<pre><code class="language-python">for key in grid_searches.keys():
    print(key)
    print(grid_searches[key].best_params_)
    pred_grid = grid_searches[key].predict(Xtest)
    print(roc_auc_score(ytest, pred_grid))
    print(recall_score(ytest, pred_grid))
    print(confusion_matrix(ytest, pred_grid))
    print('\n')
</code></pre>
<pre><code>et
{'n_estimators': 500, 'max_depth': 50, 'min_samples_leaf': 10}
0.9226210143
0.845679012346
[[93784    41]
 [   25   137]]


rf
{'n_estimators': 200, 'max_depth': 50, 'min_samples_leaf': 10}
0.913452349232
0.827160493827
[[93801    24]
 [   28   134]]


ada
{'n_estimators': 500, 'learning_rate': 1.5}
0.92263700151
0.845679012346
[[93787    38]
 [   25   137]]


svc
{'C': 1.0}
0.954330757616
0.932098765432
[[91626  2199]
 [   11   151]]


gb
{'n_estimators': 200, 'max_depth': 50, 'min_samples_leaf': 20}
0.913457678302
0.827160493827
[[93802    23]
 [   28   134]]
</code></pre></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
        <a href="/author/huiming-song.html">Huiming Song</a>
    </span>
  </span>
<time datetime="2018-05-12T19:08:00-05:00" pubdate>Sat 12 May 2018</time>  <span class="categories">
    <a class='category' href='/category/python.html'>Python</a>
  </span>
  <span class="categories">
    <a class="category" href="/tag/python.html">python</a>,    <a class="category" href="/tag/data-mining.html">data mining</a>,    <a class="category" href="/tag/sklearn.html">sklearn</a>  </span>
</p><div class="sharing">
</div>    </footer>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="/pages/2025/02/23/deepseek-v3-learning-notes/">DeepSeek V3 learning notes</a>
      </li>
      <li class="post">
          <a href="/pages/2025/02/16/deepseek-v3/">DeepSeek V3</a>
      </li>
      <li class="post">
          <a href="/pages/2024/04/21/prediction-in-decoder-and-kv-cache/">Prediction in decoder and KV-Cache</a>
      </li>
      <li class="post">
          <a href="/pages/2023/10/01/image-generation-2-latent-diffusion-model-stable-diffusion/">Image Generation 2: Latent Diffusion model / Stable Diffusion</a>
      </li>
      <li class="post">
          <a href="/pages/2023/07/04/image-generation-1-diffusion-model/">Image Generation 1: Diffusion model</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="/category/career-growth.html">career growth</a></li>
        <li><a href="/category/linux.html">Linux</a></li>
        <li><a href="/category/python.html">python</a></li>
        <li><a href="/category/rthers.html">Rthers</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="/tag/python.html">python</a>,    <a href="/tag/ai.html">AI</a>,    <a href="/tag/llm.html">LLM</a>,    <a href="/tag/aig.html">AIG</a>,    <a href="/tag/agi.html">AGI</a>,    <a href="/tag/gpt.html">GPT</a>,    <a href="/tag/data-mining.html">data mining</a>,    <a href="/tag/sklearn.html">sklearn</a>,    <a href="/tag/pytorch.html">pytorch</a>,    <a href="/tag/career-growth.html">career growth</a>,    <a href="/tag/linux.html">linux</a>,    <a href="/tag/deep-learning.html">deep learning</a>,    <a href="/tag/leetcode.html">leetcode</a>,    <a href="/tag/dynamic-programming.html">dynamic programming</a>,    <a href="/tag/flask.html">flask</a>,    <a href="/tag/highcharts.html">highcharts</a>,    <a href="/tag/sql.html">sql</a>,    <a href="/tag/webcrawl.html">webCrawl</a>,    <a href="/tag/random-walk.html">random walk</a>,    <a href="/tag/multiprocessing.html">multiprocessing</a>,    <a href="/tag/data-visualization.html">data visualization</a>,    <a href="/tag/numpy.html">numpy</a>,    <a href="/tag/tensorflow.html">tensorflow</a>,    <a href="/tag/quant.html">quant</a>,    <a href="/tag/statsmodels.html">statsmodels</a>,    <a href="/tag/pandas.html">pandas</a>,    <a href="/tag/docker.html">docker</a>,    <a href="/tag/matplotlib.html">matplotlib</a>,    <a href="/tag/data-minging.html">data minging</a>,    <a href="/tag/remote-access.html">remote access</a>,    <a href="/tag/mysql.html">mysql</a>,    <a href="/tag/base.html">base</a>,    <a href="/tag/tweepy.html">tweepy</a>,    <a href="/tag/bokeh.html">bokeh</a>,    <a href="/tag/sentiment-analysis.html">sentiment analysis</a>,    <a href="/tag/map.html">map</a>,    <a href="/tag/apply.html">apply</a>,    <a href="/tag/apply_async.html">apply_async</a>,    <a href="/tag/git.html">git</a>,    <a href="/tag/pyqt.html">PyQt</a>,    <a href="/tag/cx_freeze.html">cx_freeze</a>,    <a href="/tag/tkinter.html">tkinter</a>,    <a href="/tag/pelican.html">pelican</a>,    <a href="/tag/spyre.html">spyre</a>,    <a href="/tag/shiny.html">shiny</a>,    <a href="/tag/r.html">R</a>,    <a href="/tag/re.html">re</a>  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://www.linkedin.com/pub/huiming-song/24/735/349" target="_blank">Linkedin</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://easysas.blogspot.com/" target="_blank">my old SAS blog</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2015&ndash;2025  shm &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="/theme/js/modernizr-2.0.js"></script>
  <script src="/theme/js/ender.js"></script>
  <script src="/theme/js/octopress.js" type="text/javascript"></script>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-65938411-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-65938411-1');
    ga('send', 'pageview');
</script>
  <script type="text/javascript">
    var disqus_shortname = 'songhuiming';
    var disqus_identifier = '/pages/2018/05/12/credit-card-fraud-detection-imbalanced-data-modeling-part-iii-ensemblingstacking-models/';
    var disqus_url = '/pages/2018/05/12/credit-card-fraud-detection-imbalanced-data-modeling-part-iii-ensemblingstacking-models/';
    var disqus_title = 'Credit Card Fraud Detection / Imbalanced data modeling - Part III: Ensembling/Stacking models';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = "//" + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
  </script>
</body>
</html>