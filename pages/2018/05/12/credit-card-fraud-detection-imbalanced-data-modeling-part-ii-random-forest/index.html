<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Credit Card Fraud Detection / Imbalanced data modeling - Part II: Random Forest &mdash; pydata: Huiming's learning notes</title>
  <meta name="author" content="shm">






  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="/favicon.png" rel="icon">

  <link href="/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><header>
  <h1><a href="/">pydata: Huiming's learning notes</a></h1>
    <h2>Keep Looking, Don't Settle</h2>
</header>

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],  // 允许 $...$ 和 \( ... \) 作为行内公式
    displayMath: [['$$', '$$'], ['\\[', '\\]']],  // 允许 $$...$$ 和 \[ ... \] 作为块级公式
    processEscapes: true,  // 允许在公式中使用转义符，如 \$ 表示美元符号
    processEnvironments: true  // 允许解析 \begin{equation} ... \end{equation} 等数学环境
  },
  options: {
    skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],  // 跳过某些 HTML 标签，防止错误解析
    renderActions: {
      addMenu: []  // 移除右键菜单
    }
  }
};

window.addEventListener('load', () => {
  document.querySelectorAll("mjx-container").forEach(x => {
    x.parentElement.classList.add('has-jax');  // 使用 classList.add() 避免字符串拼接错误
  });
});
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script></header>
  <nav role="navigation">

<form action="https://www.google.com/search" method="get">
    <fieldset role="search">
       <input type="hidden" name="q" value="site:songhuiming.github.io" />
       <input class="search" type="text" name="q" results="0" placeholder="Search"/>
    </fieldset>
</form>


<ul class="main-navigation">
    <li><a href="/functions/archives.html">Archives</a></li>
      <li >
        <a href="/category/career-growth.html">Career growth</a>
      </li>
      <li >
        <a href="/category/linux.html">Linux</a>
      </li>
      <li class="active">
        <a href="/category/python.html">Python</a>
      </li>
      <li >
        <a href="/category/rthers.html">Rthers</a>
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Credit Card Fraud Detection / Imbalanced data modeling - Part II: Random Forest</h1>
    <p class="meta">
<time datetime="2018-05-12T18:08:00-05:00" pubdate>Sat 12 May 2018</time>    </p>
</header>

  <div class="entry-content"><h1>Table of Contents<span class="tocSkip"></span></h1>
<div class="toc"><ul class="toc-item"><li><span><a href="#0.-Introduction" data-toc-modified-id="0.-Introduction-1">0. Introduction</a></span><ul class="toc-item"><li><span><a href="#Conclusion:" data-toc-modified-id="Conclusion:-1.1">Conclusion:</a></span></li></ul></li><li><span><a href="#Modeling-Part-2:-RandomForestClassifier" data-toc-modified-id="Modeling-Part-2:-RandomForestClassifier-2">Modeling Part 2: RandomForestClassifier</a></span></li><li><span><a href="#1.-Use-the-Imbalanced-Data-Directly-in-RandomForestClassifier" data-toc-modified-id="1.-Use-the-Imbalanced-Data-Directly-in-RandomForestClassifier-3">1. Use the Imbalanced Data Directly in RandomForestClassifier</a></span></li><li><span><a href="#2.-Create-Over-sampling-data-and-Fit-the-model" data-toc-modified-id="2.-Create-Over-sampling-data-and-Fit-the-model-4">2. Create Over-sampling data and Fit the model</a></span></li><li><span><a href="#3.-RandomForestClassifier-with-class_weight" data-toc-modified-id="3.-RandomForestClassifier-with-class_weight-5">3. RandomForestClassifier with class_weight</a></span></li><li><span><a href="#4.-Self-defined-Score-and-GridSearchCV-of-hyperparameter" data-toc-modified-id="4.-Self-defined-Score-and-GridSearchCV-of-hyperparameter-6">4. Self-defined Score and GridSearchCV of hyperparameter</a></span></li></ul></div>

<h1>0. Introduction</h1>
<p>It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.</p>
<p>The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.</p>
<p><a href="http://songhuiming.github.io/pages/2018/05/05/credit-card-fraud-detection-imbalanced-data-modeling-part-i-logistic-regression/">In the first part, Loigstic regression model was built do different kind of analysis</a>. In this part, we will try Random Forest models.Since this is imbalanced data, we will try different methods and compare their results:</p>
<div class="highlight"><pre><span></span><code><span class="mf">1.</span><span class="w"> </span><span class="n">Model</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="n">imbalanced</span><span class="w"> </span><span class="kd">data</span><span class="w"> </span><span class="n">directly</span>
<span class="mf">2.</span><span class="w"> </span><span class="n">Model</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="n">over</span><span class="o">-</span><span class="n">sampling</span><span class="w"> </span><span class="kd">data</span>
<span class="mf">3.</span><span class="w"> </span><span class="n">Assign</span><span class="w"> </span><span class="n">more</span><span class="w"> </span><span class="n">weights</span><span class="w"> </span><span class="kr">on</span><span class="w"> </span><span class="n">rare</span><span class="w"> </span><span class="n">class</span>
<span class="mf">4.</span><span class="w"> </span><span class="n">Use</span><span class="w"> </span><span class="n">customed</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">function</span>
</code></pre></div>

<h2>Conclusion:</h2>
<ol>
<li>As expected, use the imbalanced data is not a good way. The performance is the worst compaed to using over-sampling or class weights</li>
<li>Use imbalanced data, RandomForestClassifier result is better than LogisticRegression. </li>
<li>If we can custom a good loss function, the model performance will be better: here the customed loss function performance is better than roc_auc scoring function.</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">,</span> <span class="n">Normalizer</span><span class="p">,</span> <span class="n">scale</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">AdaBoostClassifier</span><span class="p">,</span> <span class="n">GradientBoostingClassifier</span><span class="p">,</span> <span class="n">ExtraTreesClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span><span class="p">,</span> <span class="n">LinearSVC</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">log_loss</span><span class="p">,</span> <span class="n">auc</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">roc_auc_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">precision_recall_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">fbeta_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">StratifiedShuffleSplit</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>

<span class="n">seed</span> <span class="o">=</span> <span class="mi">999</span>

<span class="n">creditcard</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;creditcard.csv&#39;</span><span class="p">)</span>
<span class="n">creditcard</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">creditcard</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
<span class="n">creditcard</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;class&#39;</span><span class="p">:</span> <span class="s1">&#39;fraud&#39;</span><span class="p">},</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1"># 1. Split Test Data Out</span>
<span class="n">creditcard</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="s1">&#39;time&#39;</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="c1"># Normalize the &#39;amount&#39; column</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">creditcard</span><span class="p">[</span><span class="s1">&#39;amount&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">creditcard</span><span class="p">[</span><span class="s1">&#39;amount&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="c1"># creditcard.drop(columns = &#39;amount&#39;, inplace = True)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">creditcard</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">creditcard</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">.33</span><span class="p">,</span> <span class="n">stratify</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>
</code></pre></div>

<p>The reason why I check this:</p>
<p>For non-fraud transactions, the average amount is 88. For fraud transactions, the average amount is 122.
So, in average there will be 122 loss for a fraud. Suppose for each transaction, the company can get 2% transaction fee. 
That is, the average is 88 * 2% = 1.76. </p>
<p>That means: if we predict a non-fraud as fraud, we might loss 1.76. However, if we miss to detect a fraud transaction, we will
loss about 122.</p>
<p>Later I will use this to build a customed loss function.</p>
<h1>Modeling Part 2: RandomForestClassifier</h1>
<p>Usually for imbalanced data, we can try:</p>
<div class="highlight"><pre><span></span><code><span class="mf">1.</span><span class="w"> </span><span class="n">Collect</span><span class="w"> </span><span class="n">more</span><span class="w"> </span><span class="kd">data</span><span class="w"> </span><span class="p">(</span><span class="n">which</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="n">work</span><span class="w"> </span><span class="n">here</span><span class="w"> </span><span class="nb">sin</span><span class="n">ce</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="kd">data</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">given</span><span class="p">)</span>
<span class="mf">2.</span><span class="w"> </span><span class="n">Down</span><span class="o">-</span><span class="n">Sampling</span><span class="w"> </span><span class="ow">or</span><span class="w"> </span><span class="n">Over</span><span class="o">-</span><span class="n">Sampling</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="kr">get</span><span class="w"> </span><span class="n">balanced</span><span class="w"> </span><span class="n">samples</span>
<span class="mf">3.</span><span class="w"> </span><span class="n">Change</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">Thresholds</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="n">adjust</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">prediction</span>
<span class="mf">4.</span><span class="w"> </span><span class="n">Assign</span><span class="w"> </span><span class="n">class</span><span class="w"> </span><span class="n">weights</span><span class="w"> </span><span class="kr">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">low</span><span class="w"> </span><span class="n">rate</span><span class="w"> </span><span class="n">class</span>
</code></pre></div>

<p>Here we will try 4 different ways and compare their results:</p>
<div class="highlight"><pre><span></span><code><span class="mf">2.1.</span><span class="w"> </span><span class="n">Do</span><span class="w"> </span><span class="ow">not</span><span class="n">hing</span><span class="p">,</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="ow">or</span><span class="n">iginal</span><span class="w"> </span><span class="kd">data</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="n">model</span>
<span class="mf">2.2.</span><span class="w"> </span><span class="n">Do</span><span class="w"> </span><span class="n">Over</span><span class="o">-</span><span class="n">Sampling</span><span class="p">,</span><span class="w"> </span><span class="n">use</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">over</span><span class="o">-</span><span class="n">sampled</span><span class="w"> </span><span class="kd">data</span><span class="w"> </span><span class="kr">to</span><span class="w"> </span><span class="n">model</span>
<span class="mf">2.3.</span><span class="w"> </span><span class="n">Assigning</span><span class="w"> </span><span class="n">sample</span><span class="w"> </span><span class="n">weights</span><span class="w"> </span><span class="n">in</span><span class="w"> </span><span class="n">RandomForestClassifier</span>
<span class="mf">2.4.</span><span class="w"> </span><span class="n">Use</span><span class="w"> </span><span class="n">customed</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="n">function</span>
</code></pre></div>

<p>Since this is Fraud detection question, if we miss predicting a fraud, the credit company will lose a lot. If we miss predicting a normal transaction as Fraud, we can still let the exprt to review the transactions or we can ask the user to verify the transaction. So in this specific case, False Positive will cause more loss than False Negative.  </p>
<h1>1. Use the Imbalanced Data Directly in RandomForestClassifier</h1>
<div class="highlight"><pre><span></span><code><span class="n">X</span> <span class="o">=</span> <span class="n">creditcard</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">creditcard</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">.33</span><span class="p">,</span> <span class="n">stratify</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>

<span class="n">estimator</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">warm_start</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="n">rf_tuned_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span> <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">]}</span>

<span class="n">cv_grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">param_grid</span> <span class="o">=</span> <span class="n">rf_tuned_parameters</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="mi">70</span><span class="p">)</span> <span class="c1"># &#39;recall&#39;, my_score</span>
<span class="n">cv_grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>

<span class="c1"># print cv_grid.cv_results_</span>

<span class="n">best_parameters</span> <span class="o">=</span> <span class="n">cv_grid</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>

<span class="c1"># for param_name in sorted(rf_tuned_parameters.keys()):</span>
<span class="c1">#     print(&quot;\t%s: %r&quot; % (param_name, best_parameters[param_name]))</span>

<span class="n">pred_test</span> <span class="o">=</span> <span class="n">cv_grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">))</span>     <span class="c1"># 0.65</span>
<span class="nb">print</span><span class="p">(</span><span class="n">precision_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">))</span>  <span class="c1"># 0.85</span>
<span class="nb">print</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">))</span>    <span class="c1"># 0.83</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;confustion matrix on validation data: </span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">)))</span>
</code></pre></div>

<p>confustion matrix on validation data: </p>
<div class="highlight"><pre><span></span><code><span class="k">[[93807    18]</span>
<span class="w"> </span><span class="k">[   57   105]]</span>
</code></pre></div>

<p>If we use the imbalanced data directly in the RandomForestClassifier, we will find the result is not very good: recall score is 0.65 and the auc = 0.83. Although this result is better than the result from Logistic Regression using imbalanced data directly. To improve the model performance, we will try two methods: over-sampling and assigning more weights to rare class.</p>
<h1>2. Create Over-sampling data and Fit the model</h1>
<div class="highlight"><pre><span></span><code><span class="n">oversample_ratio</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ytrain</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ytrain</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># size to repeat y == 1</span>
<span class="c1"># repeat the positive data for X and y</span>
<span class="n">ytrain_pos_oversample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">ytrain</span><span class="p">[</span><span class="n">ytrain</span><span class="o">==</span><span class="mi">1</span><span class="p">]]</span> <span class="o">*</span> <span class="n">oversample_ratio</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">Xtrain_pos_oversample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">Xtrain</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">ytrain</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]]</span> <span class="o">*</span> <span class="n">oversample_ratio</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="c1"># concat the repeated data with the original data together</span>
<span class="n">ytrain_oversample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">ytrain</span><span class="p">,</span> <span class="n">ytrain_pos_oversample</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">Xtrain_oversample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtrain_pos_oversample</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="n">ytrain_oversample</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">dropna</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>   <span class="c1"># 50:50</span>

<span class="n">estimator</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">warm_start</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="n">rf_tuned_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span> <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">]}</span>

<span class="n">cv_grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">param_grid</span> <span class="o">=</span> <span class="n">rf_tuned_parameters</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="mi">70</span><span class="p">)</span> <span class="c1"># &#39;recall&#39;, my_score</span>
<span class="n">cv_grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain_oversample</span><span class="p">,</span> <span class="n">ytrain_oversample</span><span class="p">)</span>

<span class="c1"># print cv_grid.best_params_</span>
<span class="c1"># print cv_grid.cv_results_</span>

<span class="n">best_parameters</span> <span class="o">=</span> <span class="n">cv_grid</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>

<span class="c1"># for param_name in sorted(rf_tuned_parameters.keys()):</span>
<span class="c1">#     print(&quot;\t%s: %r&quot; % (param_name, best_parameters[param_name]))</span>

<span class="n">pred_test</span> <span class="o">=</span> <span class="n">cv_grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">))</span>     <span class="c1"># 0.83</span>
<span class="nb">print</span><span class="p">(</span><span class="n">precision_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">))</span>  <span class="c1"># 0.83</span>
<span class="nb">print</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">))</span>    <span class="c1"># 0.92</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> confustion matrix on validation data: </span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">)))</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="k">[[93798    27]</span>
<span class="w"> </span><span class="k">[   27   135]]</span>
</code></pre></div>

<p>By using over-sampling, we can find the model performance is improved a lot. recall score = 0.83 now and the auc = 0.92
From the confusion matrix, 135 frauds from 162 True frauds are detected. There are 27 non-frauds are mistakenly predicted
as frauds. We can do fine-tuning by changeing the thresholds to get less false negatives. The price will be getting more
false positives.</p>
<p>Next we will test using class_weights rather than over-sampling. We know if Logistic Regression these two are equivalent.
We will have a try to see what will happen for RandomForest?</p>
<h1>3. RandomForestClassifier with class_weight</h1>
<p>Rather than over-sampling, we can assign more weights to the lower rate class.</p>
<div class="highlight"><pre><span></span><code><span class="n">X</span> <span class="o">=</span> <span class="n">creditcard</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">creditcard</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtest</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">.33</span><span class="p">,</span> <span class="n">stratify</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>

<span class="n">positive_weight</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ytrain</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ytrain</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># size to repeat y == 1</span>

<span class="n">estimator</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">class_weight</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="p">:</span> <span class="n">positive_weight</span><span class="p">},</span> <span class="n">warm_start</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="n">rf_tuned_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span> <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">]}</span>

<span class="n">cv_grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">param_grid</span> <span class="o">=</span> <span class="n">rf_tuned_parameters</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="mi">70</span><span class="p">)</span> <span class="c1"># &#39;recall&#39;, my_score</span>
<span class="n">cv_grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>

<span class="c1"># print cv_grid.cv_results_</span>

<span class="n">best_parameters</span> <span class="o">=</span> <span class="n">cv_grid</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>

<span class="c1"># for param_name in sorted(rf_tuned_parameters.keys()):</span>
<span class="c1">#     print(&quot;\t%s: %r&quot; % (param_name, best_parameters[param_name]))</span>

<span class="n">pred_test</span> <span class="o">=</span> <span class="n">cv_grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">))</span>     <span class="c1">#  0.85</span>
<span class="nb">print</span><span class="p">(</span><span class="n">precision_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">))</span>  <span class="c1">#  0.81</span>
<span class="nb">print</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">))</span>    <span class="c1">#  0.92</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> confustion matrix on validation data: </span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">)))</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="k">[[93793    32]</span>
<span class="w"> </span><span class="k">[   25   137]]</span>
</code></pre></div>

<p>Compared with over-sampling, the recall score increased from 0.83 to 0.85, while the precision decreases from 0.83 to 0.81.
The auc is 0.92, which is close the the result of over-sampling.</p>
<p>Overall, I think this model works well: 85% of the frauds can be detected by this model, which will prevent a lot of loss.
At the same time, only 0.03% of the non-frauds will be mistakenly predicted as frauds. This will result in very little potential
loss for the company. The company can also do manual review of these false fraud detections.</p>
<h1>4. Self-defined Score and GridSearchCV of hyperparameter</h1>
<p>Since the loss from frauds and false predicted frauds are different for us. We will define a function to re-weight the 
effects by average loss from missing predicted frauds and falsely predicted frauds.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">scoring</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    based on results above about the average loss from false positive and false negative predictions.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">cmatrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
    <span class="n">fp</span> <span class="o">=</span> <span class="n">cmatrix</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">fn</span> <span class="o">=</span> <span class="n">cmatrix</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span>  <span class="n">fn</span> <span class="o">*</span> <span class="mi">122</span> <span class="o">+</span> <span class="n">fp</span> <span class="o">*</span> <span class="mf">1.76</span>

<span class="n">wt_loss_score</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">scoring</span><span class="p">,</span> <span class="n">greater_is_better</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>

<span class="n">oversample_ratio</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ytrain</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">ytrain</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># size to repeat y == 1</span>
<span class="c1"># repeat the positive data for X and y</span>
<span class="n">ytrain_pos_oversample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">ytrain</span><span class="p">[</span><span class="n">ytrain</span><span class="o">==</span><span class="mi">1</span><span class="p">]]</span> <span class="o">*</span> <span class="n">oversample_ratio</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">Xtrain_pos_oversample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">Xtrain</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">ytrain</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]]</span> <span class="o">*</span> <span class="n">oversample_ratio</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="c1"># concat the repeated data with the original data together</span>
<span class="n">ytrain_oversample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">ytrain</span><span class="p">,</span> <span class="n">ytrain_pos_oversample</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">Xtrain_oversample</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">Xtrain</span><span class="p">,</span> <span class="n">Xtrain_pos_oversample</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="n">ytrain_oversample</span><span class="o">.</span><span class="n">value_counts</span><span class="p">(</span><span class="n">dropna</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>   <span class="c1"># 50:50</span>

<span class="n">estimator</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">warm_start</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

<span class="n">rf_tuned_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">],</span> 
                       <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">]}</span>

<span class="n">cv_grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">param_grid</span> <span class="o">=</span> <span class="n">rf_tuned_parameters</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="n">wt_loss_score</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="mi">70</span><span class="p">)</span>
<span class="n">cv_grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xtrain_oversample</span><span class="p">,</span> <span class="n">ytrain_oversample</span><span class="p">)</span>

<span class="c1"># print cv_grid.best_params_</span>

<span class="n">pred_test</span> <span class="o">=</span> <span class="n">cv_grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">))</span>     <span class="c1"># 0.84</span>
<span class="nb">print</span><span class="p">(</span><span class="n">precision_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">))</span>  <span class="c1"># 0.84</span>
<span class="nb">print</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">))</span>    <span class="c1"># 0.92</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> confustion matrix on validation data: </span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred_test</span><span class="p">)))</span>
</code></pre></div>

<p>With the self defined loss function, the confusion matrix is:</p>
<div class="highlight"><pre><span></span><code><span class="k">[[93800    25]</span>
<span class="w"> </span><span class="k">[   26   136]]</span>
</code></pre></div>

<p>Compared to the same setup but using 'roc_auc' as the scoring function results:</p>
<div class="highlight"><pre><span></span><code><span class="k">[[93798    27]</span>
<span class="w"> </span><span class="k">[   27   135]]</span>
</code></pre></div></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
        <a href="/author/huiming-song.html">Huiming Song</a>
    </span>
  </span>
<time datetime="2018-05-12T18:08:00-05:00" pubdate>Sat 12 May 2018</time>  <span class="categories">
    <a class='category' href='/category/python.html'>Python</a>
  </span>
  <span class="categories">
    <a class="category" href="/tag/python.html">python</a>,    <a class="category" href="/tag/data-mining.html">data mining</a>,    <a class="category" href="/tag/sklearn.html">sklearn</a>  </span>
</p><div class="sharing">
</div>    </footer>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="/pages/2025/02/23/deepseek-v3-learning-notes/">DeepSeek V3 learning notes</a>
      </li>
      <li class="post">
          <a href="/pages/2025/02/16/deepseek-v3/">DeepSeek V3</a>
      </li>
      <li class="post">
          <a href="/pages/2023/10/01/image-generation-2-latent-diffusion-model-stable-diffusion/">Image Generation 2: Latent Diffusion model / Stable Diffusion</a>
      </li>
      <li class="post">
          <a href="/pages/2023/07/04/image-generation-1-diffusion-model/">Image Generation 1: Diffusion model</a>
      </li>
      <li class="post">
          <a href="/pages/2023/05/28/gpt-1-gpt-2-gpt-3-instructgpt-chatgpt-and-gpt-4-summary/">GPT-1, GPT-2, GPT-3, InstructGPT / ChatGPT and GPT-4 summary</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="/category/career-growth.html">career growth</a></li>
        <li><a href="/category/linux.html">Linux</a></li>
        <li><a href="/category/python.html">python</a></li>
        <li><a href="/category/rthers.html">Rthers</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="/tag/python.html">python</a>,    <a href="/tag/ai.html">AI</a>,    <a href="/tag/llm.html">LLM</a>,    <a href="/tag/aig.html">AIG</a>,    <a href="/tag/data-mining.html">data mining</a>,    <a href="/tag/sklearn.html">sklearn</a>,    <a href="/tag/pytorch.html">pytorch</a>,    <a href="/tag/career-growth.html">career growth</a>,    <a href="/tag/linux.html">linux</a>,    <a href="/tag/deep-learning.html">deep learning</a>,    <a href="/tag/leetcode.html">leetcode</a>,    <a href="/tag/dynamic-programming.html">dynamic programming</a>,    <a href="/tag/flask.html">flask</a>,    <a href="/tag/highcharts.html">highcharts</a>,    <a href="/tag/sql.html">sql</a>,    <a href="/tag/webcrawl.html">webCrawl</a>,    <a href="/tag/random-walk.html">random walk</a>,    <a href="/tag/multiprocessing.html">multiprocessing</a>,    <a href="/tag/data-visualization.html">data visualization</a>,    <a href="/tag/numpy.html">numpy</a>,    <a href="/tag/tensorflow.html">tensorflow</a>,    <a href="/tag/quant.html">quant</a>,    <a href="/tag/statsmodels.html">statsmodels</a>,    <a href="/tag/pandas.html">pandas</a>,    <a href="/tag/docker.html">docker</a>,    <a href="/tag/matplotlib.html">matplotlib</a>,    <a href="/tag/data-minging.html">data minging</a>,    <a href="/tag/remote-access.html">remote access</a>,    <a href="/tag/mysql.html">mysql</a>,    <a href="/tag/base.html">base</a>,    <a href="/tag/tweepy.html">tweepy</a>,    <a href="/tag/bokeh.html">bokeh</a>,    <a href="/tag/sentiment-analysis.html">sentiment analysis</a>,    <a href="/tag/map.html">map</a>,    <a href="/tag/apply.html">apply</a>,    <a href="/tag/apply_async.html">apply_async</a>,    <a href="/tag/git.html">git</a>,    <a href="/tag/pyqt.html">PyQt</a>,    <a href="/tag/cx_freeze.html">cx_freeze</a>,    <a href="/tag/tkinter.html">tkinter</a>,    <a href="/tag/pelican.html">pelican</a>,    <a href="/tag/spyre.html">spyre</a>,    <a href="/tag/shiny.html">shiny</a>,    <a href="/tag/r.html">R</a>,    <a href="/tag/re.html">re</a>  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://www.linkedin.com/pub/huiming-song/24/735/349" target="_blank">Linkedin</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://easysas.blogspot.com/" target="_blank">my old SAS blog</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2015&ndash;2025  shm &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="/theme/js/modernizr-2.0.js"></script>
  <script src="/theme/js/ender.js"></script>
  <script src="/theme/js/octopress.js" type="text/javascript"></script>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-65938411-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-65938411-1');
    ga('send', 'pageview');
</script>
  <script type="text/javascript">
    var disqus_shortname = 'songhuiming';
    var disqus_identifier = '/pages/2018/05/12/credit-card-fraud-detection-imbalanced-data-modeling-part-ii-random-forest/';
    var disqus_url = '/pages/2018/05/12/credit-card-fraud-detection-imbalanced-data-modeling-part-ii-random-forest/';
    var disqus_title = 'Credit Card Fraud Detection / Imbalanced data modeling - Part II: Random Forest';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = "//" + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
  </script>
</body>
</html>