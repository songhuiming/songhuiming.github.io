<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Credit Card Fraud Detection / Imbalanced data modeling - Part I: Logistic Regression &mdash; pydata: Huiming's learning notes</title>
  <meta name="author" content="shm">






  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="/favicon.png" rel="icon">

  <link href="/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><header>
  <h1><a href="/">pydata: Huiming's learning notes</a></h1>
    <h2>Keep Looking, Don't Settle</h2>
</header>

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],  // 允许 $...$ 和 \( ... \) 作为行内公式
    displayMath: [['$$', '$$'], ['\\[', '\\]']],  // 允许 $$...$$ 和 \[ ... \] 作为块级公式
    processEscapes: true,  // 允许在公式中使用转义符，如 \$ 表示美元符号
    processEnvironments: true  // 允许解析 \begin{equation} ... \end{equation} 等数学环境
  },
  options: {
    skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],  // 跳过某些 HTML 标签，防止错误解析
    renderActions: {
      addMenu: []  // 移除右键菜单
    }
  }
};

window.addEventListener('load', () => {
  document.querySelectorAll("mjx-container").forEach(x => {
    x.parentElement.classList.add('has-jax');  // 使用 classList.add() 避免字符串拼接错误
  });
});
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script></header>
  <nav role="navigation">

<form action="https://www.google.com/search" method="get">
    <fieldset role="search">
       <input type="hidden" name="q" value="site:songhuiming.github.io" />
       <input class="search" type="text" name="q" results="0" placeholder="Search"/>
    </fieldset>
</form>


<ul class="main-navigation">
    <li><a href="/functions/archives.html">Archives</a></li>
      <li >
        <a href="/category/career-growth.html">Career growth</a>
      </li>
      <li >
        <a href="/category/linux.html">Linux</a>
      </li>
      <li class="active">
        <a href="/category/python.html">Python</a>
      </li>
      <li >
        <a href="/category/rthers.html">Rthers</a>
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Credit Card Fraud Detection / Imbalanced data modeling - Part I: Logistic Regression</h1>
    <p class="meta">
<time datetime="2018-05-05T18:08:00-05:00" pubdate>Sat 05 May 2018</time>    </p>
</header>

  <div class="entry-content"><h1>Table of Contents<span class="tocSkip"></span></h1>
<div class="toc"><ul class="toc-item"><li><span><a href="#0.-Introduction" data-toc-modified-id="0.-Introduction-1">0. Introduction</a></span></li><li><span><a href="#1.-Read-in-data-and-the-libraries" data-toc-modified-id="1.-Read-in-data-and-the-libraries-2">1. Read in data and the libraries</a></span></li><li><span><a href="#Modeling-Part-I:-Logistic-Regression-method" data-toc-modified-id="Modeling-Part-I:-Logistic-Regression-method-3">Modeling Part I: Logistic Regression method</a></span><ul class="toc-item"><li><span><a href="#Preprocess-data" data-toc-modified-id="Preprocess-data-3.1">Preprocess data</a></span></li></ul></li><li><span><a href="#1.-Model-imbalanced-data-directly" data-toc-modified-id="1.-Model-imbalanced-data-directly-4">1. Model imbalanced data directly</a></span><ul class="toc-item"><li><span><a href="#1.1.-Change-the-Thresholds" data-toc-modified-id="1.1.-Change-the-Thresholds-4.1">1.1. Change the Thresholds</a></span></li></ul></li><li><span><a href="#2.-Create-Over-sampling-data-and-Fit-the-model" data-toc-modified-id="2.-Create-Over-sampling-data-and-Fit-the-model-5">2. Create Over-sampling data and Fit the model</a></span><ul class="toc-item"><li><span><a href="#2.1-Change-the-Thresholds" data-toc-modified-id="2.1-Change-the-Thresholds-5.1">2.1 Change the Thresholds</a></span></li></ul></li><li><span><a href="#3.-Logistic-Regression-with-class_weight" data-toc-modified-id="3.-Logistic-Regression-with-class_weight-6">3. Logistic Regression with class_weight</a></span><ul class="toc-item"><li><span><a href="#Reference" data-toc-modified-id="Reference-6.1">Reference</a></span></li></ul></li></ul></div>

<div id="toc"></div>

<h1>0. Introduction</h1>
<p>It is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.</p>
<p>The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.</p>
<p>It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.</p>
<h1>1. Read in data and the libraries</h1>
<p>The data is in good shape, that is, there is no missing. </p>
<ol>
<li>Data Clean (missing impute / outliers / normalize)</li>
<li>Feature Engineering (Categorical variables, transformation, correlation analysis)</li>
</ol>
<p>The provided data is imbalanced, with positive rate around 0.17%.</p>
<p>If we use this data directly to feed the model, the model will prefer to predict all as 0 for a high accuracy of 0 prediction. </p>
<pre><code class="language-python">import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler, Normalizer, scale
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.metrics import confusion_matrix, log_loss, auc, roc_curve, roc_auc_score, recall_score, precision_recall_curve
from sklearn.metrics import make_scorer, precision_score, fbeta_score, f1_score, classification_report
from sklearn.model_selection import cross_val_score, train_test_split, KFold, StratifiedShuffleSplit, GridSearchCV
from sklearn.linear_model import LogisticRegression

%matplotlib inline
plt.rcParams['figure.figsize'] = (16, 9)

seed = 999

creditcard = pd.read_csv('creditcard.csv')
creditcard.columns = [x.lower() for x in creditcard.columns]
creditcard.rename(columns = {'class': 'fraud'}, inplace = True)
</code></pre>
<p>Imbalanced data with very low proportion of positive signals</p>
<pre><code class="language-python">creditcard.fraud.value_counts(dropna = False)
</code></pre>
<pre><code>0    284315
1       492
</code></pre>
<p>There are 284315 rows (99.8%) with y = 0, and only 492 rows (0.172%) with y = 1. So it is very imbalanced data. </p>
<p>Usually we have these methods to deal with imbalanced data:
1. Collect more data
2. Over-Sampling or Down-Sampling
3. Change the prediction thresholds
4. Assign weights</p>
<p>Here we will do two things: </p>
<ol>
<li>
<p>Use LogisticRegression directly to model the data; </p>
</li>
<li>
<p>Over-sampling the data to get a balanced proportion of positive/negative values</p>
</li>
</ol>
<p>Before oversampling, we will first take a random sample as Test data.</p>
<pre><code class="language-python">creditcard.groupby('fraud').amount.mean()
</code></pre>
<pre><code>fraud
0     88.291022
1    122.211321
</code></pre>
<p>The reason why I check this:</p>
<p>For non-fraud transactions, the average amount is 88. For fraud transactions, the average amount is 122.
So, in average there will be 122 loss for a fraud. Suppose for each transaction, the company can get 2% transaction fee. 
That is, the average is 88*2% = 1.76. </p>
<p>That means: if we predict a non-fraud as fraud, we might loss 1.76. However, if we miss to detect a fraud transaction, we will
loss about 122.</p>
<p>Later I will use this to build a self-defined loss function.</p>
<h1>Modeling Part I: Logistic Regression method</h1>
<p>Usually for imbalanced data, we can try:</p>
<pre><code>1. Collect more data (which not work here since the data is given)
2. Down-Sampling or Over-Sampling to get balanced samples
3. Change the Thresholds to adjust the prediction
4. Assign class weights for the low rate class
</code></pre>
<p>Here we will try 5 different ways and compare their results:</p>
<pre><code>2.1. Do nothing, use original data to model
2.2. Do Over-Sampling, use the over-sampled data to model
2.3. Change the threshold to selected value, rather than using default 0.5
2.4. Assigning sample weights in Logistic Regression
2.5. Change the performance metric, like using ROC, f1-score rather than using accuracy
</code></pre>
<p>Since this is Fraud detection question, if we miss predicting a fraud, the credit company will lose a lot. If we miss predicting a normal transaction as Fraud, we can still let the exprt to review the transactions or we can ask the user to verify the transaction. So in this specific case, False Positive will cause more loss than False Negative.  </p>
<h2>Preprocess data</h2>
<pre><code class="language-python"># 1. Split Test Data Out
creditcard.drop(columns = 'time', inplace = True)

# Normalize the 'amount' column
scaler = StandardScaler()
creditcard['amount'] = scaler.fit_transform(creditcard['amount'].values.reshape(-1, 1))
# creditcard.drop(columns = 'amount', inplace = True)

X = creditcard.iloc[:, :-1]
y = creditcard.iloc[:, -1]
Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = .33, stratify = y, random_state = seed)
</code></pre>
<h1>1. Model imbalanced data directly</h1>
<p>We will use the imbalanced data directly in logistic regression. That is, the positive rate is about 0.172%. Accuracy is not good since if all predicted as 0, the accuracy for 0 is very high. So, here <code>recall</code>, <code>precision</code>, <code>roc</code> and <code>confusion_matrix</code> are listed to compare model performance.</p>
<pre><code class="language-python"># 2. If we don't do Over-sampling, what will happen?
X = creditcard.iloc[:, :-1]
y = creditcard.iloc[:, -1]
Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size = .33, stratify = y, random_state = seed)

logitreg_parameters = {'C': np.power(10.0, np.arange(-3, 3))}
logitreg = LogisticRegression(verbose = 3, warm_start = True)
logitreg_grid = GridSearchCV(logitreg, param_grid = logitreg_parameters, scoring = 'roc_auc', n_jobs = 70)

logitreg_grid.fit(Xtrain, ytrain)   # logitreg_grid.best_params_ ; logitreg_grid.best_estimator_

# on OVER-Sampled TRAINing data
print(&quot;\n Thre recall score on Training data is:&quot;)
print recall_score(ytrain, logitreg_grid.predict(Xtrain))    # 0.58
print(&quot;\n Thre precision score on Training data is:&quot;)
print precision_score(ytrain, logitreg_grid.predict(Xtrain))   # 0.89

# on the separated TEST data
print(&quot;\n Thre recall score on Test data is:&quot;)
print recall_score(ytest, logitreg_grid.predict(Xtest))   # 0.58
print(&quot;\n Thre precision score on Test data is:&quot;)
print precision_score(ytest, logitreg_grid.predict(Xtest))   # 0.86
print(&quot;\n Thre Confusion Matrix on Test data is:&quot;)
print confusion_matrix(ytest, logitreg_grid.predict(Xtest))
</code></pre>
<pre><code>[LibLinear]
 Thre recall score on Training data is:
0.584848484848

 Thre precision score on Training data is:
0.893518518519

 Thre recall score on Test data is:
0.586419753086

 Thre precision score on Test data is:
0.863636363636

 Thre Confusion Matrix on Test data is:
[[93810    15]
 [   67    95]]
</code></pre>
<p>Conclusions:</p>
<p>From the output above, we know on the training data, the recall score is 0.58 which means 58 over 100 of the 
True positive conditions are predicted correctly. And 89 over 100 of the predicted positives are True Positive.</p>
<p>On the Test data, the model performance metric evalued by recall or precision are close to the Training data.
There is a precision score of 0.86 on the Test data, which means 86 out of 100 predicted positives are True positives.</p>
<p>From Confusion Matrix, 95 of 162 True Positives are predicted as positives. And of all 110 predicted as positive, 95 of 
them are True positives.</p>
<h2>1.1. Change the Thresholds</h2>
<pre><code class="language-python">ytrain_pred_probas = logitreg_grid.predict_proba(Xtrain)[:, 1]   # prob of predict as 1
fpr, tpr, thresholds = roc_curve(ytrain, ytrain_pred_probas)   # precision_recall_curve
roc = pd.DataFrame({'FPR':fpr,'TPR':tpr,'Thresholds':thresholds})
</code></pre>
<pre><code class="language-python">_ = plt.figure()
plt.plot(roc.FPR, roc.TPR)
plt.axvline(0.1, color = '#00C851', linestyle = '--')
plt.xlabel(&quot;FPR&quot;)
plt.ylabel(&quot;TPR&quot;)
</code></pre>
<p><img alt="png" src="/figures/20180505_creditCardFraudDetection_01.png"></p>
<p>By default, the threshold is 0.5. Since the recall score is low, we shall lower the threshold to get more predicted as Positive. 
At the same time, more True Negative data will be falsely predicted as Positive. So the Precision score will be lower.</p>
<pre><code class="language-python">ytest_pred_probas = logitreg_grid.predict_proba(Xtest)[:, 1]
new_threshold = 0.1   # 0.5 is the default value
ytest_pred = (ytest_pred_probas &gt;= new_threshold).astype(int)

print(&quot;After change threshold to 0.1, the recall socre on Test data is:&quot;)
print recall_score(ytest, ytest_pred)     # 0.827
print(&quot;\n After change threshold to 0.1, the precision socre on Test data is:&quot;)
print precision_score(ytest, ytest_pred)  # 0.812
print(&quot;\nAfter change threshold to 0.1, the Confusion Matrix on Test data is:&quot;)
print confusion_matrix(ytest, ytest_pred)
</code></pre>
<pre><code>After change threshold to 0.1, the recall socre on Test data is:
0.827160493827

 After change threshold to 0.1, the precision socre on Test data is:
0.812121212121

After change threshold to 0.1, the Confusion Matrix on Test data is:
[[93794    31]
 [   28   134]]
</code></pre>
<p>If we lower the threshold to 0.1, we will get recall rate of 0.827. That is, 134 of 162 True Frauds will be detected while
only 31 on 165 predicted Frauds are not True Frauds.</p>
<p>If we lower the threshold to 0.01, then the recall score will be 0.91 while the precision score is 0.1.</p>
<h1>2. Create Over-sampling data and Fit the model</h1>
<p>Since there are much more samples </p>
<pre><code class="language-python">oversample_ratio = sum(ytrain == 0) / sum(ytrain == 1)  # size to repeat y == 1
# repeat the positive data for X and y
ytrain_pos_oversample = pd.concat([ytrain[ytrain==1]] * oversample_ratio, axis = 0)
Xtrain_pos_oversample = pd.concat([Xtrain.loc[ytrain==1, :]] * oversample_ratio, axis = 0)
# concat the repeated data with the original data together
ytrain_oversample = pd.concat([ytrain, ytrain_pos_oversample], axis = 0).reset_index(drop = True)
Xtrain_oversample = pd.concat([Xtrain, Xtrain_pos_oversample], axis = 0).reset_index(drop = True)

ytrain_oversample.value_counts(dropna = False, normalize = True)   # 50:50

logitreg_parameters = {'C': np.power(10.0, np.arange(-3, 3))}
logitreg = LogisticRegression(verbose = 3, warm_start = True)
logitreg_grid = GridSearchCV(logitreg, param_grid = logitreg_parameters, scoring = 'roc_auc', n_jobs = 70)

logitreg_grid.fit(Xtrain_oversample, ytrain_oversample)   # logitreg_grid.best_params_ ; logitreg_grid.best_estimator_

# on OVER-Sampled TRAINing data
print(&quot;\n After Over-Sampling, the recall score on Training data is&quot;)
print recall_score(ytrain_oversample, logitreg_grid.predict(Xtrain_oversample))    # 0.918
print(&quot;\n After Over-Sampling, the precision score on Training data is&quot;)
print precision_score(ytrain_oversample, logitreg_grid.predict(Xtrain_oversample))   # 0.971

# on the separated TEST data
print(&quot;\n After Over-Sampling, the recall score on Test data is&quot;)
print recall_score(ytest, logitreg_grid.predict(Xtest))   #  0.932
print(&quot;\n After Over-Sampling, the precision score on Test data is&quot;)
print precision_score(ytest, logitreg_grid.predict(Xtest))   # 0.056
print(&quot;\n After Over-Sampling, the Confusion Matrix on Test data is&quot;)
print confusion_matrix(ytest, logitreg_grid.predict(Xtest))
</code></pre>
<pre><code>[LibLinear]
 After Over-Sampling, the recall score on Training data is
0.918181818182

 After Over-Sampling, the precision score on Training data is
0.971089227494

 After Over-Sampling, the recall score on Test data is
0.932098765432

 After Over-Sampling, the precision score on Test data is
0.0562383612663

 After Over-Sampling, the Confusion Matrix on Test data is
[[91291  2534]
 [   11   151]]
</code></pre>
<p>From the output above, we know on the training data, the recall score is 0.918 which means 91.8 over 100 of the  True conditions are predicted correctly. And 97 over 100 of the predicted positives are really positive.</p>
<p>However, there is only a precision score of 0.056 on the Test data, which means only 5.6 out of 100 predicted positives are real positives.</p>
<p>From Confusion Matrix, 151 of 162 True Positives are predicted as positives. However, the model predicted 2533 Negative data as Positive.</p>
<p>That is, out model has pretty strong over-fitting.</p>
<h2>2.1 Change the Thresholds</h2>
<pre><code class="language-python">ytrain_pred_probas = logitreg_grid.predict_proba(Xtrain)[:, 1]
fpr, tpr, thresholds = roc_curve(ytrain, ytrain_pred_probas)   # precision_recall_curve
roc = pd.DataFrame({'FPR':fpr,'TPR':tpr,'Thresholds':thresholds})

_ = plt.figure()
plt.plot(roc.FPR, roc.TPR)
plt.axvline(0.2, color = '#00C851', linestyle = '--')
plt.xlabel(&quot;FPR&quot;)
plt.ylabel(&quot;TPR&quot;)
</code></pre>
<p><img alt="png" src="/figures/20180505_creditCardFraudDetection_02.png"></p>
<pre><code class="language-python">ytest_pred_probas = logitreg_grid.predict_proba(Xtest)[:, 1]
new_threshold = 0.2
ytest_pred = (ytest_pred_probas &gt;= new_threshold).astype(int)

print(&quot;After change threshold to 0.2, the recall socre on Test data is:&quot;)
print recall_score(ytest, ytest_pred)
print(&quot;\n After change threshold to 0.2, the precision socre on Test data is:&quot;)
print precision_score(ytest, ytest_pred)
print(&quot;\n After change threshold to 0.2, the Confusion Matrix on Test data is:&quot;)
print confusion_matrix(ytest, ytest_pred)
</code></pre>
<pre><code>After change threshold to 0.2, the recall socre on Test data is:
0.956790123457

 After change threshold to 0.2, the precision socre on Test data is:
0.016130710792

 After change threshold to 0.2, the Confusion Matrix on Test data is:
[[84371  9454]
 [    7   155]]
</code></pre>
<p>Conclusion: After over-sampling, the model will have higher recall rate. That is, the model will work better on detect the Frauds from True Frauds. The price we paid is the lower precision rate.</p>
<h1>3. Logistic Regression with class_weight</h1>
<p>Rather than over-sampling, we can assign more weights to the lower rate class. In fact, if you write out the Likelihood function for Logistic Regression, the Over-Sampling and the assigning more Weights will be equivalent.</p>
<pre><code class="language-python">positive_weight = sum(ytrain == 0) / sum(ytrain == 1)  # size to repeat y == 1

logitreg_parameters = {'C': np.power(10.0, np.arange(-3, 3))}
logitreg = LogisticRegression(class_weight = {0 : 1, 1 : positive_weight}, verbose = 3, warm_start = True)
logitreg_grid = GridSearchCV(logitreg, param_grid = logitreg_parameters, scoring = 'roc_auc', n_jobs = 70)

logitreg_grid.fit(Xtrain, ytrain)
</code></pre>
<pre><code>[LibLinear]


GridSearchCV(cv=None, error_score='raise',
       estimator=LogisticRegression(C=1.0, class_weight={0: 1, 1: 577}, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,
          solver='liblinear', tol=0.0001, verbose=3, warm_start=True),
       fit_params=None, iid=True, n_jobs=70,
       param_grid={'C': array([  1.00000e-03,   1.00000e-02,   1.00000e-01,   1.00000e+00,
         1.00000e+01,   1.00000e+02])},
       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',
       scoring='roc_auc', verbose=0)
</code></pre>
<pre><code class="language-python">print(&quot;\n After assign class_weight, the recall score on Training data is&quot;)
print recall_score(ytrain_oversample, logitreg_grid.predict(Xtrain_oversample))    # 0.912
print(&quot;\n After assign class_weight, the precision score on Training data is&quot;)
print precision_score(ytrain_oversample, logitreg_grid.predict(Xtrain_oversample))   # 0.972

# on the separated TEST data
print(&quot;\n After assign class_weight, the recall score on Test data is&quot;)
print recall_score(ytest, logitreg_grid.predict(Xtest))   #  0.932
print(&quot;\n After assign class_weight, the precision score on Test data is&quot;)
print precision_score(ytest, logitreg_grid.predict(Xtest))   # 0.058
print(&quot;\n After assign class_weight, the Confusion Matrix on Test data is&quot;)
print confusion_matrix(ytest, logitreg_grid.predict(Xtest))
print(&quot;\n After assign class_weight, the ROC AUC Score on Test data is&quot;)
print roc_auc_score(ytest, logitreg_grid.predict(Xtest))
</code></pre>
<pre><code> After assign class_weight, the recall score on Training data is
0.912121212121

 After assign class_weight, the precision score on Training data is
0.972226568612

 After assign class_weight, the recall score on Test data is
0.932098765432

 After assign class_weight, the precision score on Test data is
0.0581888246628

 After assign class_weight, the Confusion Matrix on Test data is
[[91381  2444]
 [   11   151]]

 After assign class_weight, the ROC AUC Score on Test data is
0.953025135447
</code></pre>
<p>If we set up the class weight for the positive as the ratio of non-Fraud / Fraud, we will get the result close to the over-sampling.</p>
<p>So, in summary:
This specific data is about fraud detection. So the model should focus on to find the frauds
to avoid potential loss for the bank. That is, we should focus on RECALL rate. </p>
<ol>
<li>If we use the imbalanced data directly, we will get low performance model since the model prefer to predict to the class with dominated frequency class. The recall rate is 0.58. That is, only 58% of the frauds can be detected by this model.</li>
<li>To fix that, one way is to do over-sampling or down-sampling. If we use over-sampling, the model performance will be  improved a lot. For this specific case, the recall rate on the independent test set will be improved from 0.58 to 0.932</li>
<li>Another way to improve the model performance is to assign more weights to the low frequency class. Generally speaking, for Logistic Regression, assigning weights is similar to over-sampling, from the likelihood function perspective. The final output results are close too as demonstrated above.</li>
</ol>
<h2>Reference</h2>
<ol>
<li><a href="https://www.kaggle.com/mlg-ulb/creditcardfraud">Credit Card Fraud Detection</a></li>
<li><a href="https://bitbucket.org/songhuiming/test/src/master/test1/20180510_CreditCardFraudDetection.py">CreditCardFraudDetection.py</a></li>
</ol></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
        <a href="/author/huiming-song.html">Huiming Song</a>
    </span>
  </span>
<time datetime="2018-05-05T18:08:00-05:00" pubdate>Sat 05 May 2018</time>  <span class="categories">
    <a class='category' href='/category/python.html'>Python</a>
  </span>
  <span class="categories">
    <a class="category" href="/tag/python.html">python</a>,    <a class="category" href="/tag/data-mining.html">data mining</a>,    <a class="category" href="/tag/sklearn.html">sklearn</a>  </span>
</p><div class="sharing">
</div>    </footer>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="/pages/2025/02/23/deepseek-v3-learning-notes/">DeepSeek V3 learning notes</a>
      </li>
      <li class="post">
          <a href="/pages/2025/02/16/deepseek-v3/">DeepSeek V3</a>
      </li>
      <li class="post">
          <a href="/pages/2024/04/21/prediction-in-decoder-and-kv-cache/">Prediction in decoder and KV-Cache</a>
      </li>
      <li class="post">
          <a href="/pages/2023/10/01/image-generation-2-latent-diffusion-model-stable-diffusion/">Image Generation 2: Latent Diffusion model / Stable Diffusion</a>
      </li>
      <li class="post">
          <a href="/pages/2023/07/04/image-generation-1-diffusion-model/">Image Generation 1: Diffusion model</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="/category/career-growth.html">career growth</a></li>
        <li><a href="/category/linux.html">Linux</a></li>
        <li><a href="/category/python.html">python</a></li>
        <li><a href="/category/rthers.html">Rthers</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="/tag/python.html">python</a>,    <a href="/tag/ai.html">AI</a>,    <a href="/tag/llm.html">LLM</a>,    <a href="/tag/aig.html">AIG</a>,    <a href="/tag/agi.html">AGI</a>,    <a href="/tag/gpt.html">GPT</a>,    <a href="/tag/data-mining.html">data mining</a>,    <a href="/tag/sklearn.html">sklearn</a>,    <a href="/tag/pytorch.html">pytorch</a>,    <a href="/tag/career-growth.html">career growth</a>,    <a href="/tag/linux.html">linux</a>,    <a href="/tag/deep-learning.html">deep learning</a>,    <a href="/tag/leetcode.html">leetcode</a>,    <a href="/tag/dynamic-programming.html">dynamic programming</a>,    <a href="/tag/flask.html">flask</a>,    <a href="/tag/highcharts.html">highcharts</a>,    <a href="/tag/sql.html">sql</a>,    <a href="/tag/webcrawl.html">webCrawl</a>,    <a href="/tag/random-walk.html">random walk</a>,    <a href="/tag/multiprocessing.html">multiprocessing</a>,    <a href="/tag/data-visualization.html">data visualization</a>,    <a href="/tag/numpy.html">numpy</a>,    <a href="/tag/tensorflow.html">tensorflow</a>,    <a href="/tag/quant.html">quant</a>,    <a href="/tag/statsmodels.html">statsmodels</a>,    <a href="/tag/pandas.html">pandas</a>,    <a href="/tag/docker.html">docker</a>,    <a href="/tag/matplotlib.html">matplotlib</a>,    <a href="/tag/data-minging.html">data minging</a>,    <a href="/tag/remote-access.html">remote access</a>,    <a href="/tag/mysql.html">mysql</a>,    <a href="/tag/base.html">base</a>,    <a href="/tag/tweepy.html">tweepy</a>,    <a href="/tag/bokeh.html">bokeh</a>,    <a href="/tag/sentiment-analysis.html">sentiment analysis</a>,    <a href="/tag/map.html">map</a>,    <a href="/tag/apply.html">apply</a>,    <a href="/tag/apply_async.html">apply_async</a>,    <a href="/tag/git.html">git</a>,    <a href="/tag/pyqt.html">PyQt</a>,    <a href="/tag/cx_freeze.html">cx_freeze</a>,    <a href="/tag/tkinter.html">tkinter</a>,    <a href="/tag/pelican.html">pelican</a>,    <a href="/tag/spyre.html">spyre</a>,    <a href="/tag/shiny.html">shiny</a>,    <a href="/tag/r.html">R</a>,    <a href="/tag/re.html">re</a>  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://www.linkedin.com/pub/huiming-song/24/735/349" target="_blank">Linkedin</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://easysas.blogspot.com/" target="_blank">my old SAS blog</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2015&ndash;2025  shm &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="/theme/js/modernizr-2.0.js"></script>
  <script src="/theme/js/ender.js"></script>
  <script src="/theme/js/octopress.js" type="text/javascript"></script>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-65938411-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-65938411-1');
    ga('send', 'pageview');
</script>
  <script type="text/javascript">
    var disqus_shortname = 'songhuiming';
    var disqus_identifier = '/pages/2018/05/05/credit-card-fraud-detection-imbalanced-data-modeling-part-i-logistic-regression/';
    var disqus_url = '/pages/2018/05/05/credit-card-fraud-detection-imbalanced-data-modeling-part-i-logistic-regression/';
    var disqus_title = 'Credit Card Fraud Detection / Imbalanced data modeling - Part I: Logistic Regression';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = "//" + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
  </script>
</body>
</html>