<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>working with text data in sklearn &mdash; pydata: Huiming's learning notes</title>
  <meta name="author" content="shm">






  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="/favicon.png" rel="icon">

  <link href="/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><header>
  <h1><a href="/">pydata: Huiming's learning notes</a></h1>
    <h2>Keep Looking, Don't Settle</h2>
</header>

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],  // 允许 $...$ 和 \( ... \) 作为行内公式
    displayMath: [['$$', '$$'], ['\\[', '\\]']],  // 允许 $$...$$ 和 \[ ... \] 作为块级公式
    processEscapes: true,  // 允许在公式中使用转义符，如 \$ 表示美元符号
    processEnvironments: true  // 允许解析 \begin{equation} ... \end{equation} 等数学环境
  },
  options: {
    skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],  // 跳过某些 HTML 标签，防止错误解析
    renderActions: {
      addMenu: []  // 移除右键菜单
    }
  }
};

window.addEventListener('load', () => {
  document.querySelectorAll("mjx-container").forEach(x => {
    x.parentElement.classList.add('has-jax');  // 使用 classList.add() 避免字符串拼接错误
  });
});
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script></header>
  <nav role="navigation">

<form action="https://www.google.com/search" method="get">
    <fieldset role="search">
       <input type="hidden" name="q" value="site:songhuiming.github.io" />
       <input class="search" type="text" name="q" results="0" placeholder="Search"/>
    </fieldset>
</form>


<ul class="main-navigation">
    <li><a href="/functions/archives.html">Archives</a></li>
      <li >
        <a href="/category/career-growth.html">Career growth</a>
      </li>
      <li >
        <a href="/category/linux.html">Linux</a>
      </li>
      <li class="active">
        <a href="/category/python.html">Python</a>
      </li>
      <li >
        <a href="/category/rthers.html">Rthers</a>
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">working with text data in sklearn</h1>
    <p class="meta">
<time datetime="2015-10-01T00:00:00-05:00" pubdate>Thu 01 October 2015</time>    </p>
</header>

  <div class="entry-content"><h3>处理文本文档</h3>
<h6>本文以kaggle的一个竞赛data为例  <a href="http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html">CrowdFlower</a></h6>
<ol>
<li>计算词频 (CountVectorizer, TfidfTransformer)</li>
<li>训练分类器</li>
<li>Pipeline，自动化 (以后扩展为不同的列用不同的变换)</li>
<li>网格搜索来选择最优参数 (GridSearch)</li>
</ol>
<pre><code class="language-python">import numpy as np
from scipy.sparse import hstack
import pandas as pd
import re
from sklearn.base import BaseEstimator
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.grid_search import GridSearchCV

# Load the training and test file
train = pd.read_csv(&quot;H:\\python\\kaggle\\CrowdFlower\\train.csv&quot;).fillna(&quot;&quot;)
test  = pd.read_csv(&quot;H:\\python\\kaggle\\CrowdFlower\\test.csv&quot;).fillna(&quot;&quot;)

# Drop the ID columns
idx = test.id.values.astype(int)
train, test = train.drop('id', axis=1), test.drop('id', axis=1)

# create labels and drop variance
y = train.median_relevance.values
train = train.drop(['median_relevance', 'relevance_variance'], axis=1)
train.head(5)
</code></pre>
<div style="max-height:1000px;max-width:1500px;overflow:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>query</th>
      <th>product_title</th>
      <th>product_description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td> bridal shower decorations</td>
      <td>       Accent Pillow with Heart Design - Red/Black</td>
      <td> Red satin accent pillow embroidered with a hea...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>      led christmas lights</td>
      <td> Set of 10 Battery Operated Multi LED Train Chr...</td>
      <td> Set of 10 Battery Operated Train Christmas Lig...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>                 projector</td>
      <td>        ViewSonic Pro8200 DLP Multimedia Projector</td>
      <td>                                                  </td>
    </tr>
    <tr>
      <th>3</th>
      <td>                 wine rack</td>
      <td> Concept Housewares WR-44526 Solid-Wood Ceiling...</td>
      <td> Like a silent and sturdy tree, the Southern En...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>                light bulb</td>
      <td> Wintergreen Lighting Christmas LED Light Bulb ...</td>
      <td> WTGR1011\nFeatures\nNickel base, 60,000 averag...</td>
    </tr>
  </tbody>
</table>
</div>

<pre><code class="language-python"># 计算query和title或者description的相交的长度
token_pattern = re.compile(u'(?u)\\b\\w\\w+\\b')

for i, row in train.iterrows():
    query = set(x.lower() for x in token_pattern.findall(row[&quot;query&quot;]))
    title = set(x.lower() for x in token_pattern.findall(row[&quot;product_title&quot;]))
    description = set(x.lower() for x in token_pattern.findall(row[&quot;product_description&quot;]))
    if len(title) &gt; 0:
        train.set_value(i, &quot;query_in_title&quot;, len(query.intersection(title)) / float(len(title)))
    if len(description) &gt; 0:
        train.set_value(i, &quot;query_in_description&quot;, len(query.intersection(description)) / float(len(description)))
</code></pre>
<h6>1. 计算query里面各个单词出现的次数(occurance count)，</h6>
<p>比如'ecco'在query里面总共出现了29次，python里面  <code>[x for x in train["query"] if 'ecco' in x.lower()]</code> 可以查看所有包含'ecco'的行</p>
<p>1.1. 对query统计词频，然后查看ecco出现的频率</p>
<pre><code class="language-python">cnt = CountVectorizer(token_pattern = u'(?u)\\b\\w\\w+\\b')      #调用函数
cntn = cnt.fit_transform(train[&quot;query&quot;]).toarray()               #fit data
print cntn.shape                                                 # (10158L, 487L)
print cnt.vocabulary_.get('ecco')                                #’ecco'在query所有单词的次序中排第142位(从0开始是141)
sum(cntn[:, cnt.vocabulary_.get('ecco')])                        #找出ecco出现的频率，为29
</code></pre>
<p>1.2. 同样可以对product_title， product_description做相似的统计</p>
<pre><code class="language-python">cnt.fit_transform(train[&quot;product_title&quot;])

cnt.fit_transform(train['product_description'])
</code></pre>
<pre><code>    &lt;10158x26155 sparse matrix of type '&lt;type 'numpy.int64'&gt;'
    with 432648 stored elements in Compressed Sparse Row format&gt;
</code></pre>
<p>很明显的是product_description里面单词太多了，导致产生的矩阵(sparse matrix)的维数为 <code>10158x26155</code>。我们可以只取出现频率最高的200个单词 (<code>max_features=200</code>) 作为我们的feature。也可以设置最小出现的频率为20 (<code>min_df = 10</code>) 。</p>
<pre><code class="language-python">cnt = CountVectorizer(token_pattern = u'(?u)\\b\\w\\w+\\b', max_features=200, min_df = 20)      #调用函数
cnt.fit_transform(train['product_description'])
</code></pre>
<pre><code>&lt;10158x200 sparse matrix of type '&lt;type 'numpy.int64'&gt;'
    with 158472 stored elements in Compressed Sparse Row format&gt;
</code></pre>
<h6>2. TfidfVeftorizer()计算 <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">TF-IDF feature</a></h6>
<p>仅仅计算occurance count有一个问题：越长的文档通常会有越高的词频。为避免这个潜在的问题，可以用 <code>tf</code> (term frequency)来解决：<code>tf</code>会把上面的词频除以文档中所有的单词数（to divide the number of occurrences of each word in a document by the total number of words in the document: these new features are called tf for Term Frequencies）。</p>
<p><code>tf</code>的另一个改进是减小了那些在很多文档中都出现的单词的权重。sklearn中把这个过程叫 <code>tf–idf</code>: “Term Frequency times Inverse Document Frequency”.</p>
<p>下面给出的例子是计算 <code>train['product_title']</code> 在 <code>train['query']</code> 里面的TF-IDF</p>
<pre><code class="language-python">tfv = TfidfVectorizer(token_pattern = u'(?u)\\b\\w\\w+\\b', max_features=200, min_df = 20)      #调用TfvifVectorizer函数
tfv.fit(train['query'])
tfvm = tfv.transform(train['product_title']).toarray()
tfv.vocabulary_.get('zippo')
sum(tfvm[:, tfv.vocabulary_.get('zippo')])                      # 47.881802215754419
</code></pre>
<h6>3. Build estimator to fit data</h6>
<p>3.1. 下面以 randomForest 为例来建立模型. n_jobs = -1 表示并行运算</p>
<pre><code class="language-python"># RandomForest()

tfv.fit(train['query'])
tfvm_train = tfv.transform(train['product_title']).toarray()
tfvm_test = tfv.transform(test['product_title']).toarray()

clf = RandomForestClassifier(n_estimators=200, n_jobs = -1, min_samples_split = 2, random_state = 1)
clf.fit(tfvm_train, y)
pd.Series(clf.predict(tfvm_test)).value_counts(dropna = False).sort_index()
</code></pre>
<pre><code>1      372
2     1265
3     1344
4    19532
dtype: int64
</code></pre>
<p>3.2. SVM  通常有三个参数供我们选择：</p>
<p>参见 sklearn 自带的<a href="http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html">文档</a></p>
<p><code>C</code> 是error term的惩罚参数，用来折衷training data的模型复杂度和估计精度的。<code>C</code>越小模型越光滑，<code>C</code>越大越会overfitting。<code>C</code>越大越多的样本点会被选为supporting vector.</p>
<p><code>gamma</code> 用来描述training data单个点影响程度。参见 <a href="https://www.youtube.com/watch?v=KTeVOb8gaD4">视频</a>从第17分钟开始。<code>gamma</code>越小，模型越光滑，类似于线性模型。</p>
<p><code>kernel</code> 可以选择不同的核</p>
<p>参见此图:</p>
<p><img alt="alt text" src="http://scikit-learn.org/stable/_images/plot_rbf_parameters_001.png"></p>
<p>以及此图：</p>
<p><img alt="alt text" src="http://scikit-learn.org/stable/_images/plot_rbf_parameters_002.png"></p>
<pre><code class="language-python">clf = SVC(C = 10, gamma = 0.01)
clf.fit(tfvm_train, y)
pd.Series(clf.predict(tfvm_test)).value_counts(dropna = False).sort_index()
</code></pre>
<pre><code>2      106
3      127
4    22280
dtype: int64
</code></pre>
<p>3.3. 怎么选择C 和 gamma (GridSearchCV)</p>
<pre><code class="language-python">grid_params = {'C': [10e-2, 10e-1, 1, 10, 100], 'gamma': [10e-2, 10e-1, 1, 10, 100]}
clf = SVC()
gs_clf = GridSearchCV(clf, grid_params)
gs_clf.fit(tfvm_train, y)


# get the best estimator information,
best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])
for param_name in sorted(grid_params.keys()):
    print &quot;%s: %r&quot; %(param_name, best_parameters[param_name])
</code></pre>
<h6>参考文献  <a href="http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html">Working with Text Data</a></h6></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
        <a href="/author/huiming-song.html">Huiming Song</a>
    </span>
  </span>
<time datetime="2015-10-01T00:00:00-05:00" pubdate>Thu 01 October 2015</time>  <span class="categories">
    <a class='category' href='/category/python.html'>Python</a>
  </span>
  <span class="categories">
    <a class="category" href="/tag/python.html">python</a>,    <a class="category" href="/tag/sklearn.html">sklearn</a>,    <a class="category" href="/tag/data-mining.html">data mining</a>  </span>
</p><div class="sharing">
</div>    </footer>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="/pages/2025/02/23/deepseek-v3-learning-notes/">DeepSeek V3 learning notes</a>
      </li>
      <li class="post">
          <a href="/pages/2025/02/16/deepseek-v3/">DeepSeek V3</a>
      </li>
      <li class="post">
          <a href="/pages/2024/04/21/prediction-in-decoder-and-kv-cache/">Prediction in decoder and KV-Cache</a>
      </li>
      <li class="post">
          <a href="/pages/2023/10/01/image-generation-2-latent-diffusion-model-stable-diffusion/">Image Generation 2: Latent Diffusion model / Stable Diffusion</a>
      </li>
      <li class="post">
          <a href="/pages/2023/07/04/image-generation-1-diffusion-model/">Image Generation 1: Diffusion model</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="/category/career-growth.html">career growth</a></li>
        <li><a href="/category/linux.html">Linux</a></li>
        <li><a href="/category/python.html">python</a></li>
        <li><a href="/category/rthers.html">Rthers</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="/tag/python.html">python</a>,    <a href="/tag/ai.html">AI</a>,    <a href="/tag/llm.html">LLM</a>,    <a href="/tag/aig.html">AIG</a>,    <a href="/tag/agi.html">AGI</a>,    <a href="/tag/gpt.html">GPT</a>,    <a href="/tag/data-mining.html">data mining</a>,    <a href="/tag/sklearn.html">sklearn</a>,    <a href="/tag/pytorch.html">pytorch</a>,    <a href="/tag/career-growth.html">career growth</a>,    <a href="/tag/linux.html">linux</a>,    <a href="/tag/deep-learning.html">deep learning</a>,    <a href="/tag/leetcode.html">leetcode</a>,    <a href="/tag/dynamic-programming.html">dynamic programming</a>,    <a href="/tag/flask.html">flask</a>,    <a href="/tag/highcharts.html">highcharts</a>,    <a href="/tag/sql.html">sql</a>,    <a href="/tag/webcrawl.html">webCrawl</a>,    <a href="/tag/random-walk.html">random walk</a>,    <a href="/tag/multiprocessing.html">multiprocessing</a>,    <a href="/tag/data-visualization.html">data visualization</a>,    <a href="/tag/numpy.html">numpy</a>,    <a href="/tag/tensorflow.html">tensorflow</a>,    <a href="/tag/quant.html">quant</a>,    <a href="/tag/statsmodels.html">statsmodels</a>,    <a href="/tag/pandas.html">pandas</a>,    <a href="/tag/docker.html">docker</a>,    <a href="/tag/matplotlib.html">matplotlib</a>,    <a href="/tag/data-minging.html">data minging</a>,    <a href="/tag/remote-access.html">remote access</a>,    <a href="/tag/mysql.html">mysql</a>,    <a href="/tag/base.html">base</a>,    <a href="/tag/tweepy.html">tweepy</a>,    <a href="/tag/bokeh.html">bokeh</a>,    <a href="/tag/sentiment-analysis.html">sentiment analysis</a>,    <a href="/tag/map.html">map</a>,    <a href="/tag/apply.html">apply</a>,    <a href="/tag/apply_async.html">apply_async</a>,    <a href="/tag/git.html">git</a>,    <a href="/tag/pyqt.html">PyQt</a>,    <a href="/tag/cx_freeze.html">cx_freeze</a>,    <a href="/tag/tkinter.html">tkinter</a>,    <a href="/tag/pelican.html">pelican</a>,    <a href="/tag/spyre.html">spyre</a>,    <a href="/tag/shiny.html">shiny</a>,    <a href="/tag/r.html">R</a>,    <a href="/tag/re.html">re</a>  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://www.linkedin.com/pub/huiming-song/24/735/349" target="_blank">Linkedin</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://easysas.blogspot.com/" target="_blank">my old SAS blog</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2015&ndash;2025  shm &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="/theme/js/modernizr-2.0.js"></script>
  <script src="/theme/js/ender.js"></script>
  <script src="/theme/js/octopress.js" type="text/javascript"></script>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-65938411-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-65938411-1');
    ga('send', 'pageview');
</script>
  <script type="text/javascript">
    var disqus_shortname = 'songhuiming';
    var disqus_identifier = '/pages/2015/10/01/working-with-text-data-in-sklearn/';
    var disqus_url = '/pages/2015/10/01/working-with-text-data-in-sklearn/';
    var disqus_title = 'working with text data in sklearn';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = "//" + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
  </script>
</body>
</html>