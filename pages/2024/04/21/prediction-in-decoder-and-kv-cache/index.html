<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Prediction in decoder and KV-Cache &mdash; pydata: Huiming's learning notes</title>
  <meta name="author" content="shm">






  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="/favicon.png" rel="icon">

  <link href="/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><header>
  <h1><a href="/">pydata: Huiming's learning notes</a></h1>
    <h2>Keep Looking, Don't Settle</h2>
</header>

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],  // 允许 $...$ 和 \( ... \) 作为行内公式
    displayMath: [['$$', '$$'], ['\\[', '\\]']],  // 允许 $$...$$ 和 \[ ... \] 作为块级公式
    processEscapes: true,  // 允许在公式中使用转义符，如 \$ 表示美元符号
    processEnvironments: true  // 允许解析 \begin{equation} ... \end{equation} 等数学环境
  },
  options: {
    skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],  // 跳过某些 HTML 标签，防止错误解析
    renderActions: {
      addMenu: []  // 移除右键菜单
    }
  }
};

window.addEventListener('load', () => {
  document.querySelectorAll("mjx-container").forEach(x => {
    x.parentElement.classList.add('has-jax');  // 使用 classList.add() 避免字符串拼接错误
  });
});
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script></header>
  <nav role="navigation">

<form action="https://www.google.com/search" method="get">
    <fieldset role="search">
       <input type="hidden" name="q" value="site:songhuiming.github.io" />
       <input class="search" type="text" name="q" results="0" placeholder="Search"/>
    </fieldset>
</form>


<ul class="main-navigation">
    <li><a href="/functions/archives.html">Archives</a></li>
      <li >
        <a href="/category/career-growth.html">Career growth</a>
      </li>
      <li >
        <a href="/category/linux.html">Linux</a>
      </li>
      <li class="active">
        <a href="/category/python.html">Python</a>
      </li>
      <li >
        <a href="/category/rthers.html">Rthers</a>
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Prediction in decoder and KV-Cache</h1>
    <p class="meta">
<time datetime="2024-04-21T00:00:00-05:00" pubdate>Sun 21 April 2024</time>    </p>
</header>

  <div class="entry-content"><h2><span style="color:blue">1. Prediciton in Decoder</span></h2>
<p>在前面<a href="https://songhuiming.github.io/pages/2023/05/28/gpt-1-gpt-2-gpt-3-instructgpt-chatgpt-and-gpt-4-summary/">GPT summary</a>里面对GPT的模型有一个综合的介绍，这里用一个fake example来解释一步步GPT是怎么做的，self attention是怎么计算的，KV cache是怎么回事。</p>
<p>GPT是decoder only的模型，根据前面的token来预测下一个token。比如有一个句子 "it is sunny today."，现在有初始输入 prompt “it is”，下面看怎么预测 “sunny” 和 “today”。假设单词表 <code>vocabulary = {"it", "is", "sunny", "today", "&lt;EOS&gt;"}</code>. 输入的prompt “it is”，对应的token id 是 <code>[0,1]</code>,</p>
<p><strong><span style="color:blue">1.1. Predict 1st token</span></strong>. prompt <code>[“it", "is”]</code>，token id 是 <code>[0,1]</code>。 为了简化问题，假设embedding+position encoding为 "it" (pos 1): <code>[0.1, 0.3, 0.3, 0.5]</code>，"is" (pos 2): <code>[0.6, 0.6, 0.8, 0.8]</code>。为了简化计算且不失一般性，假设 <span class="math">\(W\)</span>为单位阵 <span class="math">\(I\)</span>，也就是 <span class="math">\(W_K = W_Q = W_V = I_4\)</span>
    - 现有序列<code>["it", "is"]</code>，对应的输入矩阵为 
        </p>
<div class="math">$$X =
            \begin{bmatrix}
            0.1 &amp; 0.3 &amp; 0.3 &amp; 0.5 \\
            0.6 &amp; 0.6 &amp; 0.8 &amp; 0.8
            \end{bmatrix}$$</div>
<p>
计算 self-attention. 因为<span class="math">\(W=I\)</span>, 所以 <span class="math">\(𝑄 = 𝐾 = 𝑉 = 𝑋\)</span>. self attention = <span class="math">\(\frac{QK^T}{\sqrt{d_k}}\)</span>, <span class="math">\(d_k = 4\)</span>, 
        </p>
<div class="math">$$
            QK^T = \begin{bmatrix}
                0.1 &amp; 0.3 &amp; 0.3 &amp; 0.5 \\
                0.6 &amp; 0.6 &amp; 0.8 &amp; 0.8
                \end{bmatrix}
                \begin{bmatrix}
                0.1 &amp; 0.6 \\
                0.3 &amp; 0.6 \\
                0.3 &amp; 0.8 \\
                0.5 &amp; 0.8
                \end{bmatrix}
                \propto \begin{bmatrix}
                \text{["it" "it"}] &amp;  \text{["it" "is"]}\\
                \text{["is" "it"}] &amp;  \text{["is" "is"]}
                \end{bmatrix}
        $$</div>
<p>
除以<span class="math">\(\sqrt{d_k}\)</span>以后得到 
        </p>
<div class="math">$$\frac{QK^T}{\sqrt{d_k}} = 
                \begin{bmatrix}
                0.16 &amp; 0.52 \\
                0.52 &amp; 1.18
                \end{bmatrix}$$</div>
<p>
因为GPT是从前面的token来预测当前token，后面的token是看不到的。所以需要mask，表现在self attention矩阵上就是跟未来的token的权重为0. 更直白一点，self attention weights矩阵是下三角阵。
        </p>
<div class="math">$$
            \frac{QK^T}{\sqrt{d_k}} \text{ with mask } = \begin{bmatrix}
                0.16 &amp; -∞ \\
                0.52 &amp; 1.18
                \end{bmatrix}
        $$</div>
<p>
进行softmax以后得到
        </p>
<div class="math">$$
            \text{Attention weights} = \begin{bmatrix}
                1.0 &amp; 0.0 \\
                0.341 &amp; 0.659
                \end{bmatrix}
        $$</div>
<p>
再计算 weights 矩阵 和 <span class="math">\(V\)</span>的乘积, <span class="math">\(\text{weights} \cdot V\)</span>:
        </p>
<div class="math">$$
            \text{Attention} =
                \begin{bmatrix}
                1.0 \times 0.1 + 0.0 \times 0.6 &amp; \ldots \\ % \text{"it" attends only to itself}
                0.341 \times 0.1 + 0.659 \times 0.6 &amp; \ldots % \text{"is" attends to both}
                \end{bmatrix}
                =
                \begin{bmatrix}
                0.1 &amp; 0.3 &amp; 0.3 &amp; 0.5 \\
                0.447 &amp; 0.529 &amp; 0.653 &amp; 0.706
                \end{bmatrix}
        $$</div>
<p>
得到attention以后的V的weighted average以后，position 2的值<code>[0.447, 0.529, 0.653, 0.706]</code>再经过FFN（这里简化成一个 MLP）最有投影到 vocabulary 空间上得到logits。然后softmax over logits得到概率，比如 <code>"sunny" = 0.7</code>, <code>"today" = 0.2</code>, etc.). 最后根据position 2 的 Logits 得到 Sample <code>"sunny"</code>.</p>
<p><strong><span style="color:blue">1.2. Predict 2nd token</span></strong>. 有了 <code>["it", "is", "sunny"]</code>以后，继续预测下一个单词。sunny 对应的 embedding为 <code>[1.1, 0.9, 1.3, 1.1]</code>.</p>
<p>现在的输入矩阵相应的有3行，
        </p>
<div class="math">$$X =
        \begin{bmatrix}
        0.1 &amp; 0.3 &amp; 0.3 &amp; 0.5 \\
        0.6 &amp; 0.6 &amp; 0.8 &amp; 0.8 \\
        1.1 &amp; 0.9 &amp; 1.3 &amp; 1.1 \\
        \end{bmatrix}$$</div>
<p>
因为<span class="math">\(W = I\)</span>, 所以仍然<span class="math">\(𝑄 = 𝐾 = 𝑉 = X\)</span>，计算新的 attention 矩阵
        </p>
<div class="math">$$
        \frac{QK^\top}{\sqrt{d_k}} =
        \begin{bmatrix}
        0.16 &amp; 0.52 &amp; 0.74 \\
        0.52 &amp; 1.18 &amp; 1.66 \\
        0.74 &amp; 1.66 &amp; 2.34
        \end{bmatrix}$$</div>
<p>
同样，GPT decoder下，因为每个token只能跟它和它之前的token做attention，它之后的token都没有attention。
        </p>
<div class="math">$$
        \text{Causal Mask} =
        \begin{bmatrix}
        0.16 &amp; -\infty &amp; -\infty \\
        0.52 &amp; 1.18 &amp; -\infty \\
        0.74 &amp; 1.66 &amp; 2.34
        \end{bmatrix}$$</div>
<p>
把这个矩阵做softmax归一化，沿着dimension 1 做normalization，得到
            </p>
<div class="math">$$\text{Attention weights} = \begin{bmatrix}
            1.0 &amp; 0.0 &amp; 0.0 \\
            0.341 &amp; 0.659 &amp; 0.0 \\
            0.136 &amp; 0.309 &amp; 0.555
            \end{bmatrix}$$</div>
<p>
把这个矩阵再跟<span class="math">\(V\)</span>相乘，最后得到
        </p>
<div class="math">$$\text{Attention}  \begin{bmatrix}
        0.1 &amp; 0.3 &amp; 0.3 &amp; 0.5 \\
        0.447 &amp; 0.529 &amp; 0.653 &amp; 0.706 \\
        0.847 &amp; 0.779 &amp; 1.041 &amp; 0.961
        \end{bmatrix}$$</div>
<p>
根据最后一个输入的hidden status，<code>[0.847, 0.779, 1.041, 0.961]</code>，同样经过FFN，最后再把它投影到vocabulary 空间上得到logits。然后根据softmax选择概率最大的单词 <code>today</code>.</p>
<p><img alt="kv-cache" src="/figures/20240421_pv_cache_01.png">
<em>Fig 1. KV-cache explanation. Image from internet</em></p>
<h2><span style="color:blue">2. KV cache in decoder models</span></h2>
<p>从上面的计算可以看出，在预测第一个单词的时候，<span class="math">\(K = Q = X\)</span>, 
            </p>
<div class="math">$$X =
            \begin{bmatrix}
            0.1 &amp; 0.3 &amp; 0.3 &amp; 0.5 \\
            0.6 &amp; 0.6 &amp; 0.8 &amp; 0.8
            \end{bmatrix}$$</div>
<p>
当预测第二个单词的时候，新的<span class="math">\(K，V\)</span>第第一行，第二行（对应的"it", "is"）仍然还是原来的值，这个时候如果从新计算的话，会额外的占用GPU资源（从embedding开始，跟<span class="math">\(W\)</span>做矩阵相乘）。其实只要在每一步计算的时候，把前面的已经计算的值cache下来，这样就节省了计算资源。KV cache就是这个思路。</p>
<p>从新梳理一下，在计算第一个token的时候，cache下 <span class="math">\(K_{cache} =V_{cache}\)</span> 
            </p>
<div class="math">$$\begin{bmatrix}
            0.1 &amp; 0.3 &amp; 0.3 &amp; 0.5 \\
            0.6 &amp; 0.6 &amp; 0.8 &amp; 0.8
            \end{bmatrix}$$</div>
<p> 
然后当预测第二个token的时候，计算新predict的token的<span class="math">\(K\)</span>和<span class="math">\(Q\)</span>, <span class="math">\(Q_{new} = [1.1,0.9,1.3,1.1]\)</span>， <span class="math">\(K_{new} = V_{new} = [1.1,0.9,1.3,1.1]\)</span>。这样就得到新的 <span class="math">\(K_{cache}\)</span>, 
            </p>
<div class="math">$$\begin{bmatrix}
                0.1 &amp; 0.3 &amp; 0.3 &amp; 0.5 \\
                0.6 &amp; 0.6 &amp; 0.8 &amp; 0.8 \\
                1.1 &amp; 0.9 &amp; 1.3 &amp; 1.1 \\
                \end{bmatrix}$$</div>
<p>
同样，因为我们的<span class="math">\(W\)</span>设置，<span class="math">\(V_{cache}\)</span> 也是这个矩阵。这样就可以算出新的attention weight为 <span class="math">\(Q_{new} \cdot K_{cache}^T / \sqrt{4} =  [0.74, 1.66, 2.34]\)</span></p>
<pre><code class="language-python">import torch

# Setup
W_Q = W_K = W_V = torch.eye(4)
embeddings = {0: torch.tensor([0.1, 0.3, 0.3, 0.5]),  # &quot;it&quot;
              1: torch.tensor([0.6, 0.6, 0.8, 0.8]),  # &quot;is&quot;
              2: torch.tensor([1.1, 0.9, 1.3, 1.1])}  # &quot;sunny&quot;

# Initialize cache
K_cache = torch.empty(0, 4)
V_cache = torch.empty(0, 4)

def self_attention_with_cache(X_new, K_cache, V_cache):
    Q = X_new @ W_Q
    K_new = X_new @ W_K
    V_new = X_new @ W_V
    K_cache = torch.cat([K_cache, K_new], dim=0)
    V_cache = torch.cat([V_cache, V_new], dim=0)
    scores = Q @ K_cache.T / (4 ** 0.5)
    weights = torch.softmax(scores, dim=-1)
    output = weights @ V_cache
    return output, K_cache, V_cache

# Process prompt
prompt = torch.stack([embeddings[0], embeddings[1]])
for i in range(prompt.size(0)):
    output, K_cache, V_cache = self_attention_with_cache(prompt[i:i+1], K_cache, V_cache)
print(&quot;Prompt output:&quot;, output)

# Predict next token
new_token = embeddings[2].unsqueeze(0)
output, K_cache, V_cache = self_attention_with_cache(new_token, K_cache, V_cache)
print(&quot;Next token output:&quot;, output)
</code></pre>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        availableFonts: ['STIX', 'TeX']," +
        "        preferredFont: 'STIX'," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
        <a href="/author/huiming-song.html">Huiming Song</a>
    </span>
  </span>
<time datetime="2024-04-21T00:00:00-05:00" pubdate>Sun 21 April 2024</time>  <span class="categories">
    <a class='category' href='/category/python.html'>python</a>
  </span>
  <span class="categories">
    <a class="category" href="/tag/python.html">python</a>,    <a class="category" href="/tag/ai.html">AI</a>,    <a class="category" href="/tag/llm.html">LLM</a>,    <a class="category" href="/tag/agi.html">AGI</a>,    <a class="category" href="/tag/gpt.html">GPT</a>  </span>
</p><div class="sharing">
</div>    </footer>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="/pages/2025/02/23/deepseek-v3-learning-notes/">DeepSeek V3 learning notes</a>
      </li>
      <li class="post">
          <a href="/pages/2025/02/16/deepseek-v3/">DeepSeek V3</a>
      </li>
      <li class="post">
          <a href="/pages/2024/04/21/prediction-in-decoder-and-kv-cache/">Prediction in decoder and KV-Cache</a>
      </li>
      <li class="post">
          <a href="/pages/2023/10/01/image-generation-2-latent-diffusion-model-stable-diffusion/">Image Generation 2: Latent Diffusion model / Stable Diffusion</a>
      </li>
      <li class="post">
          <a href="/pages/2023/07/04/image-generation-1-diffusion-model/">Image Generation 1: Diffusion model</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="/category/career-growth.html">career growth</a></li>
        <li><a href="/category/linux.html">Linux</a></li>
        <li><a href="/category/python.html">python</a></li>
        <li><a href="/category/rthers.html">Rthers</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="/tag/python.html">python</a>,    <a href="/tag/ai.html">AI</a>,    <a href="/tag/llm.html">LLM</a>,    <a href="/tag/aig.html">AIG</a>,    <a href="/tag/agi.html">AGI</a>,    <a href="/tag/gpt.html">GPT</a>,    <a href="/tag/data-mining.html">data mining</a>,    <a href="/tag/sklearn.html">sklearn</a>,    <a href="/tag/pytorch.html">pytorch</a>,    <a href="/tag/career-growth.html">career growth</a>,    <a href="/tag/linux.html">linux</a>,    <a href="/tag/deep-learning.html">deep learning</a>,    <a href="/tag/leetcode.html">leetcode</a>,    <a href="/tag/dynamic-programming.html">dynamic programming</a>,    <a href="/tag/flask.html">flask</a>,    <a href="/tag/highcharts.html">highcharts</a>,    <a href="/tag/sql.html">sql</a>,    <a href="/tag/webcrawl.html">webCrawl</a>,    <a href="/tag/random-walk.html">random walk</a>,    <a href="/tag/multiprocessing.html">multiprocessing</a>,    <a href="/tag/data-visualization.html">data visualization</a>,    <a href="/tag/numpy.html">numpy</a>,    <a href="/tag/tensorflow.html">tensorflow</a>,    <a href="/tag/quant.html">quant</a>,    <a href="/tag/statsmodels.html">statsmodels</a>,    <a href="/tag/pandas.html">pandas</a>,    <a href="/tag/docker.html">docker</a>,    <a href="/tag/matplotlib.html">matplotlib</a>,    <a href="/tag/data-minging.html">data minging</a>,    <a href="/tag/remote-access.html">remote access</a>,    <a href="/tag/mysql.html">mysql</a>,    <a href="/tag/base.html">base</a>,    <a href="/tag/tweepy.html">tweepy</a>,    <a href="/tag/bokeh.html">bokeh</a>,    <a href="/tag/sentiment-analysis.html">sentiment analysis</a>,    <a href="/tag/map.html">map</a>,    <a href="/tag/apply.html">apply</a>,    <a href="/tag/apply_async.html">apply_async</a>,    <a href="/tag/git.html">git</a>,    <a href="/tag/pyqt.html">PyQt</a>,    <a href="/tag/cx_freeze.html">cx_freeze</a>,    <a href="/tag/tkinter.html">tkinter</a>,    <a href="/tag/pelican.html">pelican</a>,    <a href="/tag/spyre.html">spyre</a>,    <a href="/tag/shiny.html">shiny</a>,    <a href="/tag/r.html">R</a>,    <a href="/tag/re.html">re</a>  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://www.linkedin.com/pub/huiming-song/24/735/349" target="_blank">Linkedin</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://easysas.blogspot.com/" target="_blank">my old SAS blog</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2015&ndash;2025  shm &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="/theme/js/modernizr-2.0.js"></script>
  <script src="/theme/js/ender.js"></script>
  <script src="/theme/js/octopress.js" type="text/javascript"></script>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-65938411-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-65938411-1');
    ga('send', 'pageview');
</script>
  <script type="text/javascript">
    var disqus_shortname = 'songhuiming';
    var disqus_identifier = '/pages/2024/04/21/prediction-in-decoder-and-kv-cache/';
    var disqus_url = '/pages/2024/04/21/prediction-in-decoder-and-kv-cache/';
    var disqus_title = 'Prediction in decoder and KV-Cache';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = "//" + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
  </script>
</body>
</html>