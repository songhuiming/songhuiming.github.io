<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Data Engineering and Modeling 01: predict defaults with imbalanced data &mdash; pydata</title>
  <meta name="author" content="shm">






  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="/favicon.png" rel="icon">

  <link href="/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="/">pydata</a></h1>
    <h2>Keep Looking, Don't Settle</h2>
</hgroup>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
        MathJax.Hub.Config({
            config: ["MMLorHTML.js"],
            extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js"],
            jax: ["input/TeX"],
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                processEscapes: false
            },
            TeX: {
                TagSide: "right",
                TagIndent: ".8em",
                MultLineWidth: "85%",
                equationNumbers: {
                   autoNumber: "AMS",
                },
                unicode: {
                   fonts: "STIXGeneral,'Arial Unicode MS'"
                }
            },
            showProcessingMessages: false
        });
</script></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
</ul>

<form class="search" action="/search.html">
    <input type="text" class="search-query" placeholder="Search" name="q" id="s">
</form>

<form action="https://www.google.com/search" method="get">
    <fieldset role="search">
       <input type="hidden" name="q" value="site:songhuiming.github.io" />
       <input class="search" type="text" name="q" results="0" placeholder="Search"/>
    </fieldset>
</form>


<ul class="main-navigation">
    <li><a href="/functions/archives.html">Archives</a></li>
      <li >
        <a href="/category/career-growth.html">Career growth</a>
      </li>
      <li >
        <a href="/category/linux.html">Linux</a>
      </li>
      <li class="active">
        <a href="/category/python.html">Python</a>
      </li>
      <li >
        <a href="/category/rthers.html">Rthers</a>
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Data Engineering and Modeling 01: predict defaults with imbalanced data</h1>
    <p class="meta">
<time datetime="2017-09-23T18:08:00-05:00" pubdate>Sat 23 September 2017</time>    </p>
</header>

  <div class="entry-content"><h2>0. Description</h2>
<p>This data contains the recordings of a series of borrowers(based on id) from 2015-01-01 to 2015-11-02. The target variable is a categorical variable with value 0 or 1. target=1 means the borrower is default, otherwise it means the borrower is active. Totally there are 1168 unique borrower id.</p>
<p>Each borrower will have one recording or no recording everyday. The minimum number of recording is 3 and the maximum number of recording is 304.</p>
<p>For each recording, there are 9 independent variables named as x1 to x9.</p>
<p>The job is to predict the target variable based on the independent variables.</p>
<h2>1. Data View</h2>
<p>The data looks like</p>
<table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>date</th>      <th>id</th>      <th>target</th>      <th>x1</th>      <th>x2</th>      <th>x3</th>      <th>x4</th>      <th>x5</th>      <th>x6</th>      <th>x7</th>      <th>x8</th>      <th>x9</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>2015-01-01</td>      <td>S1F01085</td>      <td>0</td>      <td>215630672</td>      <td>56</td>      <td>0</td>      <td>52</td>      <td>6</td>      <td>407438</td>      <td>0</td>      <td>0</td>      <td>7</td>    </tr>    <tr>      <th>1</th>      <td>2015-01-01</td>      <td>S1F0166B</td>      <td>0</td>      <td>61370680</td>      <td>0</td>      <td>3</td>      <td>0</td>      <td>6</td>      <td>403174</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>2</th>      <td>2015-01-01</td>      <td>S1F01E6Y</td>      <td>0</td>      <td>173295968</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>12</td>      <td>237394</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>3</th>      <td>2015-01-01</td>      <td>S1F01JE0</td>      <td>0</td>      <td>79694024</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>6</td>      <td>410186</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>4</th>      <td>2015-01-01</td>      <td>S1F01R2B</td>      <td>0</td>      <td>135970480</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>15</td>      <td>313173</td>      <td>0</td>      <td>0</td>      <td>3</td>    </tr>    <tr>      <th>5</th>      <td>2015-11-02</td>      <td>Z1F0MA1S</td>      <td>0</td>      <td>18310224</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>10</td>      <td>353705</td>      <td>8</td>      <td>8</td>      <td>0</td>    </tr>    <tr>      <th>6</th>      <td>2015-11-02</td>      <td>Z1F0Q8RT</td>      <td>0</td>      <td>172556680</td>      <td>96</td>      <td>107</td>      <td>4</td>      <td>11</td>      <td>332792</td>      <td>0</td>      <td>0</td>      <td>13</td>    </tr>    <tr>      <th>7</th>      <td>2015-11-02</td>      <td>Z1F0QK05</td>      <td>0</td>      <td>19029120</td>      <td>4832</td>      <td>0</td>      <td>0</td>      <td>11</td>      <td>350410</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>8</th>      <td>2015-11-02</td>      <td>Z1F0QL3N</td>      <td>0</td>      <td>226953408</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>12</td>      <td>358980</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>9</th>      <td>2015-11-02</td>      <td>Z1F0QLC1</td>      <td>0</td>      <td>17572840</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>10</td>      <td>351431</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>  </tbody></table>

<ul>
<li>Target Variable: target is the categorical variable with values 0 and 1</li>
<li>Independent Variables: we can use all the other variables as the independent variables, including x1 to x9, even date and id if with proper transformation.</li>
</ul>
<p><strong>Some Observations</strong>:</p>
<ul>
<li>
<p>From the data we can see <code>x1</code> and <code>x6</code> are like numeric variable while the others are like categorical variable. We will do some analysis later.</p>
</li>
<li>
<p><code>x2</code>, <code>x3</code>, <code>x7</code>, <code>x8</code>, <code>x9</code> has lots of zeros </p>
</li>
<li>
<p>The first 3 characters of id might be useful to distinguish the target variable</p>
</li>
<li>
<p>The variable date might be useful: we can get month information which might be useful, or we can get the time duration from first recording time to positive target time</p>
</li>
</ul>
<p><strong>Some Extras</strong>:</p>
<ul>
<li>Totally there are 124494 rows in the data. But there are only 1168 unique ids.</li>
<li>Overall there are only 106 target=1. That is, the rate is about 0.08%.</li>
<li>Each id only has at most one time target=1.</li>
</ul>
<h3>1.1. Data summary and target info</h3>
<p>There are 124494 rows of data in all but there is only 106 target=1. So the data is very imbalanced.</p>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span>

<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">AdaBoostClassifier</span><span class="p">,</span> <span class="n">GradientBoostingClassifier</span><span class="p">,</span> <span class="n">ExtraTreesClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span><span class="p">,</span> <span class="n">LinearSVC</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">StratifiedShuffleSplit</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">log_loss</span>

<span class="kn">import</span> <span class="nn">plotly.offline</span> <span class="kn">as</span> <span class="nn">py</span>
<span class="n">py</span><span class="o">.</span><span class="n">init_notebook_mode</span><span class="p">(</span><span class="n">connected</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">plotly.graph_objs</span> <span class="kn">as</span> <span class="nn">go</span>
<span class="kn">import</span> <span class="nn">plotly.tools</span> <span class="kn">as</span> <span class="nn">tls</span>

<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="c1">#get_ipython().magic(&#39;matplotlib inline&#39;)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>

<span class="n">mypath</span> <span class="o">=</span> <span class="s1">r&#39;/home/shm/projects/blog_study_draft/data//&#39;</span>
<span class="n">indata</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">mypath</span> <span class="o">+</span> <span class="s1">r&#39;defaults.csv&#39;</span><span class="p">)</span>
</pre></div>


<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>

<div class="highlight"><pre><span class="k">print</span><span class="p">(</span><span class="n">indata</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">indata</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>


<div class="highlight"><pre>(124494, 12)
106
</pre></div>


<h3>1.2. Borrowers defaulted</h3>
<p>Since there are many target=0. We will check how many borrowers defaulted and how many not.</p>
<p>It shows there are 106 borrowers defaulted. The rest 1062 borrowers did not have any default during this observation time period.</p>
<div class="highlight"><pre><span class="n">defaultid</span> <span class="o">=</span> <span class="n">indata</span><span class="p">[</span><span class="n">indata</span><span class="o">.</span><span class="n">target</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="n">indata</span><span class="p">[</span><span class="n">indata</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">defaultid</span><span class="p">)]</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">indata</span><span class="p">[</span><span class="o">~</span><span class="n">indata</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">defaultid</span><span class="p">)]</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">indata</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre>(106,)
(1062,)
(1168,)
</pre></div>


<p>For furture use, I will pick out the defaulted borrowers to a standalone data set.</p>
<div class="highlight"><pre><span class="n">defaults</span> <span class="o">=</span> <span class="n">indata</span><span class="p">[</span><span class="n">indata</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">defaultid</span><span class="p">)]</span>
<span class="k">print</span><span class="p">(</span><span class="n">defaults</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre>(10713, 12)
</pre></div>


<h2>2. Data Engineering</h2>
<h3>2.1. Unique values for each variable</h3>
<p>The data does not have a dictionary to indicate clearly what does the x mean. I will determine them based on their values information. </p>
<p>x1 and x6 have lots of unique values, they are more like continuous variables. The other variables x are more like categorical variables.</p>
<div class="highlight"><pre><span class="c1"># pd.concat([indata[:5], indata[-5:]], axis = 0).reset_index(drop=True).to_html()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indata</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;For variable &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;, there are &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">indata</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()))</span> <span class="o">+</span> <span class="s2">&quot; unique values&quot;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre>For variable date, there are 304 unique values
For variable id, there are 1168 unique values
For variable target, there are 2 unique values
For variable x1, there are 123878 unique values
For variable x2, there are 558 unique values
For variable x3, there are 47 unique values
For variable x4, there are 115 unique values
For variable x5, there are 60 unique values
For variable x6, there are 44838 unique values
For variable x7, there are 28 unique values
For variable x8, there are 28 unique values
For variable x9, there are 65 unique values
</pre></div>


<h3>2.2. process variable date and id</h3>
<p>First I will grab the month informtion to have a look if the defaults have any relation with month. Also I will do the same thing for the id.</p>
<p>There are only 3 different values for the first 2 strings in id. I guess it is like geo info. I will check if will help to explain y.</p>
<p>From the plot it shows month 5 and month 7 are higher than the ohter months. There is also period default trend by month. </p>
<p>By id it shows w1 has higher default rate then z1. And z1 is higher than s1. Since extracted month and id0 are characters. I will replace them by the log(odds)</p>
<div class="highlight"><pre><span class="n">indata</span><span class="p">[</span><span class="s1">&#39;month&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">indata</span><span class="o">.</span><span class="n">date</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">indata</span><span class="p">[</span><span class="s1">&#39;id0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">indata</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">defaults</span><span class="p">[</span><span class="s1">&#39;month&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">defaults</span><span class="o">.</span><span class="n">date</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">defaults</span><span class="p">[</span><span class="s1">&#39;id0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">defaults</span><span class="o">.</span><span class="n">id</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>

<span class="k">def</span> <span class="nf">attr_f1</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">20</span> <span class="o">+</span> <span class="s2">&quot; this is for x &quot;</span> <span class="o">+</span> <span class="n">x</span> <span class="o">+</span> <span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span> 
    <span class="n">a</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">name</span><span class="p">]</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">how</span> <span class="o">=</span> <span class="s2">&quot;left&quot;</span><span class="p">,</span> <span class="n">on</span> <span class="o">=</span> <span class="n">x</span><span class="p">)</span>
    <span class="c1">#df.loc[:, name] = np.log((df.loc[:, name] + 1e-8)/(1 - df.loc[:, name] + 1e-8))</span>
    <span class="k">return</span> <span class="n">df</span>

<span class="n">indata</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">indata</span><span class="p">,</span> <span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="s2">&quot;a2&quot;</span><span class="p">)</span>
<span class="n">indata</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">indata</span><span class="p">,</span> <span class="s2">&quot;x3&quot;</span><span class="p">,</span> <span class="s2">&quot;a3&quot;</span><span class="p">)</span>
<span class="n">indata</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">indata</span><span class="p">,</span> <span class="s2">&quot;x4&quot;</span><span class="p">,</span> <span class="s2">&quot;a4&quot;</span><span class="p">)</span>
<span class="n">indata</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">indata</span><span class="p">,</span> <span class="s2">&quot;x5&quot;</span><span class="p">,</span> <span class="s2">&quot;a5&quot;</span><span class="p">)</span>
<span class="n">indata</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">indata</span><span class="p">,</span> <span class="s2">&quot;x7&quot;</span><span class="p">,</span> <span class="s2">&quot;a7&quot;</span><span class="p">)</span>
<span class="n">indata</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">indata</span><span class="p">,</span> <span class="s2">&quot;x8&quot;</span><span class="p">,</span> <span class="s2">&quot;a8&quot;</span><span class="p">)</span>
<span class="n">indata</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">indata</span><span class="p">,</span> <span class="s2">&quot;x9&quot;</span><span class="p">,</span> <span class="s2">&quot;a9&quot;</span><span class="p">)</span>
<span class="n">indata</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">indata</span><span class="p">,</span> <span class="s2">&quot;id0&quot;</span><span class="p">,</span> <span class="s2">&quot;id1&quot;</span><span class="p">)</span>
<span class="n">indata</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">indata</span><span class="p">,</span> <span class="s2">&quot;month&quot;</span><span class="p">,</span> <span class="s2">&quot;month0&quot;</span><span class="p">)</span>


<span class="n">defaults</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">defaults</span><span class="p">,</span> <span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="s2">&quot;a2&quot;</span><span class="p">)</span>
<span class="n">defaults</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">defaults</span><span class="p">,</span> <span class="s2">&quot;x3&quot;</span><span class="p">,</span> <span class="s2">&quot;a3&quot;</span><span class="p">)</span>
<span class="n">defaults</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">defaults</span><span class="p">,</span> <span class="s2">&quot;x4&quot;</span><span class="p">,</span> <span class="s2">&quot;a4&quot;</span><span class="p">)</span>
<span class="n">defaults</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">defaults</span><span class="p">,</span> <span class="s2">&quot;x5&quot;</span><span class="p">,</span> <span class="s2">&quot;a5&quot;</span><span class="p">)</span>
<span class="n">defaults</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">defaults</span><span class="p">,</span> <span class="s2">&quot;x7&quot;</span><span class="p">,</span> <span class="s2">&quot;a7&quot;</span><span class="p">)</span>
<span class="n">defaults</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">defaults</span><span class="p">,</span> <span class="s2">&quot;x8&quot;</span><span class="p">,</span> <span class="s2">&quot;a8&quot;</span><span class="p">)</span>
<span class="n">defaults</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">defaults</span><span class="p">,</span> <span class="s2">&quot;x9&quot;</span><span class="p">,</span> <span class="s2">&quot;a9&quot;</span><span class="p">)</span>
<span class="n">defaults</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">defaults</span><span class="p">,</span> <span class="s2">&quot;id0&quot;</span><span class="p">,</span> <span class="s2">&quot;id1&quot;</span><span class="p">)</span>
<span class="n">defaults</span> <span class="o">=</span> <span class="n">attr_f1</span><span class="p">(</span><span class="n">defaults</span><span class="p">,</span> <span class="s2">&quot;month&quot;</span><span class="p">,</span> <span class="s2">&quot;month0&quot;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="n">indata</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;month&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_01.png" title="Logo Title Text 1" /></p>
<div class="highlight"><pre><span class="n">indata</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;id0&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_02.png" title="Logo Title Text 1" /></p>
<p>However, when I only look at the defaults data, I will find that month 5 and month 7 are not the highest default month. The trend is not exactly the same as the trend from the full data set.</p>
<div class="highlight"><pre><span class="n">defaults</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;month&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_03.png" title="Logo Title Text 1" /></p>
<p>The transformed variable from id still works:</p>
<div class="highlight"><pre><span class="n">defaults</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;id0&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_04.png" title="Logo Title Text 1" /></p>
<div class="highlight"><pre><span class="n">sns</span><span class="o">.</span><span class="n">factorplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="s2">&quot;x3&quot;</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s2">&quot;target&quot;</span><span class="p">,</span> <span class="n">col</span> <span class="o">=</span> <span class="s2">&quot;id0&quot;</span><span class="p">,</span> 
               <span class="n">data</span> <span class="o">=</span> <span class="n">defaults</span><span class="p">[</span><span class="n">defaults</span><span class="o">.</span><span class="n">x3</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">],</span> <span class="n">kind</span> <span class="o">=</span> <span class="s2">&quot;count&quot;</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_05.png" title="Logo Title Text 1" /></p>
<h3>2.3. x1 and x6</h3>
<p>Let us look at the tow continuous variable x1 and x6. I will scatter plot the default rate based on the grids from x1 and x6.</p>
<p>target=0 will be colored as blue and target=1 will be colored as red. It shows most of the x1 are between 200000 to 500000. </p>
<div class="highlight"><pre><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="s1">&#39;#9bc3f6&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="s1">&#39;#ff0000&#39;</span><span class="p">}</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">indata</span><span class="o">.</span><span class="n">x1</span><span class="p">,</span> <span class="n">indata</span><span class="o">.</span><span class="n">x6</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">indata</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">colors</span><span class="p">[</span><span class="n">x</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span> 
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_06.png" title="Logo Title Text 1" /></p>
<div class="highlight"><pre><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">{</span><span class="mi">0</span><span class="p">:</span><span class="s1">&#39;#9bc3f6&#39;</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="s1">&#39;#ff0000&#39;</span><span class="p">}</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">defaults</span><span class="o">.</span><span class="n">x1</span><span class="p">,</span> <span class="n">defaults</span><span class="o">.</span><span class="n">x6</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">defaults</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">colors</span><span class="p">[</span><span class="n">x</span><span class="p">]))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_07.png" title="Logo Title Text 1" /></p>
<h3>2.4. Correlation</h3>
<p>It will be helpful to check the correlation between x and y. Also it is helpful to check the correlation between all the x so that we can know if there is any multicollinearity or not.</p>
<p>We can see there is high correlation between x7 and x8. Alao x9 and 3 has a correlation around 0.53.</p>
<div class="highlight"><pre><span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="s2">&quot;x3&quot;</span><span class="p">,</span> <span class="s2">&quot;x4&quot;</span><span class="p">,</span> <span class="s2">&quot;x5&quot;</span><span class="p">,</span> <span class="s2">&quot;x6&quot;</span><span class="p">,</span> <span class="s2">&quot;x7&quot;</span><span class="p">,</span> <span class="s2">&quot;x8&quot;</span><span class="p">,</span> <span class="s2">&quot;x9&quot;</span><span class="p">,</span> <span class="s2">&quot;id1&quot;</span><span class="p">,</span> <span class="s1">&#39;month0&#39;</span><span class="p">]</span>
<span class="n">colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">viridis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Pearson Correlation of Features&#39;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="mf">1.05</span><span class="p">,</span> <span class="n">size</span>  <span class="o">=</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">indata</span><span class="p">[[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">cols</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> 
            <span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">square</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">colormap</span><span class="p">,</span> <span class="n">linecolor</span> <span class="o">=</span> <span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">annot</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_08.png" title="Logo Title Text 1" /></p>
<div class="highlight"><pre><span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;x2&quot;</span><span class="p">,</span> <span class="s2">&quot;x3&quot;</span><span class="p">,</span> <span class="s2">&quot;x4&quot;</span><span class="p">,</span> <span class="s2">&quot;x5&quot;</span><span class="p">,</span> <span class="s2">&quot;x6&quot;</span><span class="p">,</span> <span class="s2">&quot;x7&quot;</span><span class="p">,</span> <span class="s2">&quot;x8&quot;</span><span class="p">,</span> <span class="s2">&quot;x9&quot;</span><span class="p">,</span> <span class="s2">&quot;id1&quot;</span><span class="p">,</span> <span class="s1">&#39;month0&#39;</span><span class="p">]</span>
<span class="n">colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">viridis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Pearson Correlation of Features&#39;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="mf">1.05</span><span class="p">,</span> <span class="n">size</span>  <span class="o">=</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">defaults</span><span class="p">[[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">cols</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> 
            <span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">square</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">colormap</span><span class="p">,</span> <span class="n">linecolor</span> <span class="o">=</span> <span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">annot</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_09.png" title="Logo Title Text 1" /></p>
<p>Also, we can check the correlation between y and the transformed values a.</p>
<div class="highlight"><pre><span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;a2&quot;</span><span class="p">,</span> <span class="s2">&quot;a3&quot;</span><span class="p">,</span> <span class="s2">&quot;a4&quot;</span><span class="p">,</span> <span class="s2">&quot;a5&quot;</span><span class="p">,</span> <span class="s2">&quot;x6&quot;</span><span class="p">,</span> <span class="s2">&quot;a7&quot;</span><span class="p">,</span> <span class="s2">&quot;a8&quot;</span><span class="p">,</span> <span class="s2">&quot;a9&quot;</span><span class="p">,</span> <span class="s2">&quot;id1&quot;</span><span class="p">,</span> <span class="s1">&#39;month0&#39;</span><span class="p">]</span>
<span class="n">colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">viridis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Pearson Correlation of Features&#39;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="mf">1.05</span><span class="p">,</span> <span class="n">size</span>  <span class="o">=</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">indata</span><span class="p">[[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">cols</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> 
            <span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">square</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">colormap</span><span class="p">,</span> <span class="n">linecolor</span> <span class="o">=</span> <span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">annot</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_10.png" title="Logo Title Text 1" /></p>
<div class="highlight"><pre><span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;a2&quot;</span><span class="p">,</span> <span class="s2">&quot;a3&quot;</span><span class="p">,</span> <span class="s2">&quot;a4&quot;</span><span class="p">,</span> <span class="s2">&quot;a5&quot;</span><span class="p">,</span> <span class="s2">&quot;x6&quot;</span><span class="p">,</span> <span class="s2">&quot;a7&quot;</span><span class="p">,</span> <span class="s2">&quot;a8&quot;</span><span class="p">,</span> <span class="s2">&quot;a9&quot;</span><span class="p">,</span> <span class="s2">&quot;id1&quot;</span><span class="p">,</span> <span class="s1">&#39;month0&#39;</span><span class="p">]</span>
<span class="n">colormap</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">viridis</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Pearson Correlation of Features&#39;</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="mf">1.05</span><span class="p">,</span> <span class="n">size</span>  <span class="o">=</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">defaults</span><span class="p">[[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">cols</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> 
            <span class="n">linewidth</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">square</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">colormap</span><span class="p">,</span> <span class="n">linecolor</span> <span class="o">=</span> <span class="s1">&#39;white&#39;</span><span class="p">,</span> <span class="n">annot</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_11.png" title="Logo Title Text 1" /></p>
<h2>3. Model</h2>
<h3>3.1. imbalanced Data</h3>
<p>Since there are only 106 defaults comparing to 1168 borrowers and 124494 observations, the proportion of target=1 is  very low. That is, our data is imbalanced data.</p>
<p>If we used imbalanced data directly to build the model, we might be in trouble because the model will be ignoring the target=1 data if we use accuracy to measure the model performance.</p>
<p>There are some methods to deal with the imbalanced data:</p>
<ol>
<li>
<p>oversampling: we repeat the low proportion data to make the proportion of target=1 and target=0 to be close in the oversampled data.</p>
</li>
<li>
<p>downsampling: unlike oversampling to increase the low proportion data, downsampling will try to sample from high proportion(target=1 here) to make the data balanced</p>
</li>
<li>
<p>adjust the low proportion data weight in the algorithm</p>
</li>
<li>
<p>adjust the decision threshold of the output probability to classify</p>
</li>
<li>
<p>adjust the lost function if we want to give more weights on the low proportion data</p>
</li>
</ol>
<h3>3.2. Oversampling</h3>
<p>Here we will do oversampling: </p>
<ol>
<li>
<p>we pick all the 10713 observations of 106 borrowers who has been defaulted. There are 106 target=1 with all the rest 10607 observations having target=0</p>
</li>
<li>
<p>Second we will repeat the 106 positive sample 10607/106 times. After this, in the oversampled data, the ratio of 1 v.s. 0 is about half half.</p>
</li>
</ol>
<p>After the new oversampled data is created, I will split them to training part and validation part.</p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">StratifiedShuffleSplit</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">log_loss</span><span class="p">,</span> <span class="n">auc</span><span class="p">,</span> <span class="n">roc_auc_score</span>

<span class="n">defaults_1</span> <span class="o">=</span> <span class="n">defaults</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;target == 1&#39;</span><span class="p">)</span>
<span class="n">defaults_0</span> <span class="o">=</span> <span class="n">defaults</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s1">&#39;target == 0&#39;</span><span class="p">)</span>
<span class="n">defaults_1_rep</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">defaults_1</span><span class="p">]</span><span class="o">*</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">defaults_0</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">defaults_1</span><span class="p">))),</span> <span class="n">ignore_index</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">defaults_new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">defaults_0</span><span class="p">,</span> <span class="n">defaults_1_rep</span><span class="p">],</span> <span class="n">ignore_index</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">cols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;x1&quot;</span><span class="p">,</span> <span class="s2">&quot;a2&quot;</span><span class="p">,</span> <span class="s2">&quot;a3&quot;</span><span class="p">,</span> <span class="s2">&quot;a4&quot;</span><span class="p">,</span> <span class="s2">&quot;a5&quot;</span><span class="p">,</span> <span class="s2">&quot;x6&quot;</span><span class="p">,</span> <span class="s2">&quot;a7&quot;</span><span class="p">,</span> <span class="s2">&quot;a9&quot;</span><span class="p">,</span> <span class="s2">&quot;id1&quot;</span><span class="p">,</span> <span class="s1">&#39;month0&#39;</span><span class="p">]</span>
<span class="n">ftrain</span> <span class="o">=</span> <span class="n">defaults_new</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span>
<span class="n">fx_train</span> <span class="o">=</span> <span class="n">defaults_new</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">fy_train</span> <span class="o">=</span> <span class="n">defaults_new</span><span class="p">[[</span><span class="s2">&quot;target&quot;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">fy_train</span><span class="p">))</span>

<span class="n">xtrain</span><span class="p">,</span> <span class="n">xtest</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">ytest</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">fx_train</span><span class="p">,</span> <span class="n">fy_train</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">999</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">ytest</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>


<div class="highlight"><pre>10600
4168
</pre></div>


<h3>3.3. First Model: RandomForestClassifier with growing number of estimatiors</h3>
<p>RandomForest is the decision tree based algorithm which builds several decision trees and then combine their output to improve the ability of the model. The method of combining trees is known as ensemble method. <font color="red">Ensembing means combination of weak learners to produce a stronger learner.</font> </p>
<h4>3.3.1. Growing RandomForest</h4>
<p>RandomForstClassifier is a combination of many decision trees. In the first example, I will show how the <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">AUC</a> chages based on different number of decision trees. <code>n_estimators</code> is the hyperparameter indicating how many decision trees will be used. We will start from 100 and increase 10 in each loop. Then we will draw the graph of AUC v.s. n_estimators. </p>
<p>Another benifits is we can get the variable importances from the RandomForest output. The variable importances are measured by the total decrease of node impurities from splitting on the variable.</p>
<div class="highlight"><pre><span class="n">auc</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">growing_rf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;gini&#39;</span><span class="p">,</span> <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> 
                                    <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">max_features</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span><span class="p">,</span> 
                                    <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">warm_start</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">168</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
    <span class="n">growing_rf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>
    <span class="n">growing_rf</span><span class="o">.</span><span class="n">n_estimators</span> <span class="o">+=</span> <span class="mi">10</span>
    <span class="n">auc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">roc_auc_score</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">growing_rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xtest</span><span class="p">)))</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">auc</span><span class="p">,</span> <span class="s1">&#39;-r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Growing RandomForest AUC on validation data&quot;</span><span class="p">)</span>
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_12.png" title="Logo Title Text 1" /></p>
<p>Feature importance plot shows that a2 is the most important feature, and a4 is the next most important.</p>
<div class="highlight"><pre><span class="n">rf_importance</span> <span class="o">=</span> <span class="n">growing_rf</span><span class="o">.</span><span class="n">feature_importances_</span>

<span class="n">feature_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;features&#39;</span><span class="p">:</span> <span class="n">cols</span><span class="p">,</span> <span class="s1">&#39;RandomForest feature importances&#39;</span><span class="p">:</span> <span class="n">rf_importance</span><span class="p">})</span>

<span class="n">trace</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="n">feature_df</span><span class="p">[</span><span class="s1">&#39;RandomForest feature importances&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                  <span class="n">x</span> <span class="o">=</span> <span class="n">feature_df</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                  <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;markers&quot;</span><span class="p">,</span>
                  <span class="n">marker</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">sizemode</span> <span class="o">=</span> <span class="s2">&quot;diameter&quot;</span><span class="p">,</span>
                               <span class="n">sizeref</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                               <span class="n">size</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span>
                               <span class="n">color</span> <span class="o">=</span> <span class="n">feature_df</span><span class="p">[</span><span class="s1">&#39;RandomForest feature importances&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                               <span class="n">colorscale</span> <span class="o">=</span> <span class="s2">&quot;Portland&quot;</span><span class="p">,</span>
                               <span class="n">showscale</span> <span class="o">=</span> <span class="bp">True</span><span class="p">),</span>
                  <span class="n">text</span> <span class="o">=</span> <span class="n">feature_df</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">trace</span><span class="p">]</span>

<span class="n">layout</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Layout</span><span class="p">(</span><span class="n">autosize</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
                  <span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Growing RandomForest Feature Importances&quot;</span><span class="p">,</span>
                  <span class="n">hovermode</span> <span class="o">=</span> <span class="s2">&quot;closest&quot;</span><span class="p">,</span>
                  <span class="n">yaxis</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Feature Importances&quot;</span><span class="p">,</span>
                              <span class="n">ticklen</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> 
                              <span class="n">gridwidth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">),</span>
                  <span class="n">showlegend</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">,</span> <span class="n">layout</span> <span class="o">=</span> <span class="n">layout</span><span class="p">)</span>

<span class="n">py</span><span class="o">.</span><span class="n">iplot</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;scatter2010&#39;</span><span class="p">)</span>
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_13.png" title="Logo Title Text 1" /></p>
<p>Finally we will apply the built RandomForestClassifier on the original data set. We will get 31 defaults predicted correctly. There are 75 defaults are wrongly predicted as non-defaults. There are also 10 non-defaults are predicted as defaults.</p>
<p>This result also show accuracy is not a good measure here as mentioned above because there are 124378 non-defaults are predicted correctly. So the overall accuracy is very high.</p>
<div class="highlight"><pre><span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">indata</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">growing_rf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">indata</span><span class="p">[</span><span class="n">cols</span><span class="p">])))</span>
</pre></div>


<div class="highlight"><pre><span class="k">[[124384      4]</span>
 <span class="k">[    86     20]]</span>
</pre></div>


<h3>3.4. GridSearch Hyperparameters</h3>
<p>RandomForestClassifier have several hyperparameters to choose.  <code>n_estimator</code> will enable you to choose how many decision trees will be used. <code>max_depth</code> will decide how deep the decision tree will be. <code>min_samples_leaf</code> is the minimum number of samples required to be at a leaf node. </p>
<p>We will test the combination of these hyperparameters and let the data decide which hyperparameter is the best. To do that, we first need to define the scoring function which will be the rule to select hyperparameters. From above the main issue here is we are likely to make type 1 and type 2 errors. So I will define a function to minimize the type 1 and type 2 predictions.  </p>
<div class="highlight"><pre><span class="kn">from</span> <span class="nn">sklearn.grid_search</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span>

<span class="k">def</span> <span class="nf">myscoring</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
    <span class="n">cmatrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
    <span class="n">fp</span> <span class="o">=</span> <span class="n">cmatrix</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">fn</span> <span class="o">=</span> <span class="n">cmatrix</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span>  <span class="n">fn</span> <span class="o">+</span> <span class="n">fp</span>

<span class="n">my_score</span> <span class="o">=</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">myscoring</span><span class="p">,</span> <span class="n">greater_is_better</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="n">estimator</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">rf_tuned_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> 
                       <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">]}</span>

<span class="n">cv_grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">param_grid</span> <span class="o">=</span> <span class="n">rf_tuned_parameters</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="n">my_score</span><span class="p">)</span>
<span class="n">cv_grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>

<span class="n">best_parameters</span> <span class="o">=</span> <span class="n">cv_grid</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>

<span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">rf_tuned_parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="si">%s</span><span class="s2">: </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">param_name</span><span class="p">,</span> <span class="n">best_parameters</span><span class="p">[</span><span class="n">param_name</span><span class="p">]))</span>
<span class="n">pred1</span> <span class="o">=</span> <span class="n">cv_grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xtest</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;confustion matrix on validation data: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred1</span><span class="p">)))</span>
</pre></div>


<div class="highlight"><pre>    max_depth: 20
    min_samples_leaf: 2
    n_estimators: 100
confustion matrix on validation data: [[4259   56]
 [   0 4168]]
</pre></div>


<div class="highlight"><pre><span class="n">pred_full</span> <span class="o">=</span> <span class="n">cv_grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">indata</span><span class="p">[</span><span class="n">cols</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">indata</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">pred_full</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre><span class="k">[[124384      4]</span>
 <span class="k">[    88     18]]</span>
</pre></div>


<h3>3.5. ExtraTreeClassifier, AdaboostClassifier, GradientBoostingClassifier, LinearSVC, Logistic Regression</h3>
<p>Next I will build some other classification learners. Then these models will be combined together as input for another model. It is like a new ensembling model is created.</p>
<p>Each classifier has its own hyperparameters. It is better to grad search for finetuning hyperparameters and find the best hyperparameters. But that will take longer time to do. To save time I assigned the hyperparameter directly.</p>
<p>The modeling data(oversampled data) will be split into 5 folders. Each time 4 folders data will be used to train a model and the left 1 folder will be used for test data. </p>
<h4>3.5.1. Build Model</h4>
<div class="highlight"><pre><span class="n">ntrain</span> <span class="o">=</span> <span class="n">fx_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">nfolds</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">888</span>
<span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">ntrain</span><span class="p">,</span> <span class="n">n_folds</span><span class="o">=</span><span class="n">nfolds</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">SklearnClassifier</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">clf</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="mi">999</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="n">params</span><span class="p">[</span><span class="s1">&#39;random_state&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">feature_importances</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">feature_importances_</span>

<span class="k">def</span> <span class="nf">get_oof</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">):</span>
    <span class="n">oof_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">ntrain</span><span class="p">,</span> <span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kf</span><span class="p">):</span>
        <span class="n">x_tr</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
        <span class="n">y_tr</span> <span class="o">=</span> <span class="n">y_train</span><span class="p">[</span><span class="n">train_index</span><span class="p">]</span>
        <span class="n">x_te</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
        <span class="n">y_te</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span>
        <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_tr</span><span class="p">,</span> <span class="n">y_tr</span><span class="p">)</span>
        <span class="n">oof_train</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_te</span><span class="p">)</span>
    <span class="n">full_predict</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">indata</span><span class="p">[</span><span class="n">cols</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">oof_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">full_predict</span><span class="p">)</span>

<span class="c1"># random forest parameters</span>
<span class="n">rf_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_jobs&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> 
            <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
            <span class="s1">&#39;warm_start&#39;</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
            <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
            <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span>
            <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="s1">&#39;sqrt&#39;</span><span class="p">,</span>
            <span class="s1">&#39;verbose&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">}</span>

<span class="c1"># extra tree parameters</span>
<span class="n">et_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_jobs&#39;</span><span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
            <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
            <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
            <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
            <span class="s1">&#39;verbose&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">}</span>

<span class="c1"># adaboost parameters</span>
<span class="n">ada_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
             <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.75</span><span class="p">}</span>

<span class="c1"># gradient boosting parameters</span>
<span class="n">gb_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
            <span class="s1">&#39;max_features&#39;</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
            <span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
            <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span>
            <span class="s1">&#39;verbose&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">}</span>

<span class="c1"># LinearSVC parameters</span>
<span class="n">svc_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="mf">0.25</span><span class="p">}</span>
</pre></div>


<div class="highlight"><pre><span class="n">rf</span> <span class="o">=</span> <span class="n">SklearnClassifier</span><span class="p">(</span><span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">rf_params</span><span class="p">)</span>
<span class="n">et</span> <span class="o">=</span> <span class="n">SklearnClassifier</span><span class="p">(</span><span class="n">clf</span> <span class="o">=</span> <span class="n">ExtraTreesClassifier</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">et_params</span><span class="p">)</span>
<span class="n">ada</span> <span class="o">=</span> <span class="n">SklearnClassifier</span><span class="p">(</span><span class="n">clf</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">ada_params</span><span class="p">)</span>
<span class="n">gb</span> <span class="o">=</span> <span class="n">SklearnClassifier</span><span class="p">(</span><span class="n">clf</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">gb_params</span><span class="p">)</span>
<span class="n">svc</span> <span class="o">=</span> <span class="n">SklearnClassifier</span><span class="p">(</span><span class="n">clf</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">svc_params</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">datetime</span>
<span class="n">startt</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>

<span class="p">(</span><span class="n">rf_oof_train</span><span class="p">,</span> <span class="n">rf_oof_full</span><span class="p">)</span> <span class="o">=</span> <span class="n">get_oof</span><span class="p">(</span><span class="n">rf</span><span class="p">,</span> <span class="n">fx_train</span><span class="p">,</span> <span class="n">fy_train</span><span class="p">)</span>  <span class="c1"># 0:00:02.194219</span>
<span class="p">(</span><span class="n">et_oof_train</span><span class="p">,</span> <span class="n">et_oof_full</span><span class="p">)</span> <span class="o">=</span> <span class="n">get_oof</span><span class="p">(</span><span class="n">et</span><span class="p">,</span> <span class="n">fx_train</span><span class="p">,</span> <span class="n">fy_train</span><span class="p">)</span>  <span class="c1"># 0:00:05.207521</span>
<span class="p">(</span><span class="n">ada_oof_train</span><span class="p">,</span>  <span class="n">ada_oof_full</span><span class="p">)</span> <span class="o">=</span> <span class="n">get_oof</span><span class="p">(</span><span class="n">ada</span><span class="p">,</span> <span class="n">fx_train</span><span class="p">,</span> <span class="n">fy_train</span><span class="p">)</span> <span class="c1"># 0:00:27.385738</span>
<span class="p">(</span><span class="n">gb_oof_train</span><span class="p">,</span> <span class="n">gb_oof_full</span><span class="p">)</span> <span class="o">=</span> <span class="n">get_oof</span><span class="p">(</span><span class="n">gb</span><span class="p">,</span> <span class="n">fx_train</span><span class="p">,</span> <span class="n">fy_train</span><span class="p">)</span>  <span class="c1"># 0:00:16.449645</span>
<span class="c1"># SVM usually takes too long time to run, use LinearSVC</span>
<span class="c1">#https://stackoverflow.com/questions/40077432/scikit-learn-svm-svc-is-extremely-slow</span>
<span class="p">(</span><span class="n">svc_oof_train</span><span class="p">,</span> <span class="n">svc_oof_full</span><span class="p">)</span> <span class="o">=</span> <span class="n">get_oof</span><span class="p">(</span><span class="n">svc</span><span class="p">,</span> <span class="n">fx_train</span><span class="p">,</span> <span class="n">fy_train</span><span class="p">)</span>

<span class="n">endt</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="n">endt</span> <span class="o">-</span> <span class="n">startt</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="mi">0</span><span class="o">:</span><span class="mi">00</span><span class="o">:</span><span class="mf">30.987350</span>
</pre></div>


<h4>3.5.2. Feature Importances</h4>
<p>Next we will get the feature importances and plot them. SVM does not have feature importances because it depends on the boundary data points(supporting vectors) on the splitting surface.</p>
<div class="highlight"><pre><span class="n">rf_features</span> <span class="o">=</span> <span class="n">rf</span><span class="o">.</span><span class="n">feature_importances</span><span class="p">(</span><span class="n">fx_train</span><span class="p">,</span> <span class="n">fy_train</span><span class="p">)</span>
<span class="n">et_features</span> <span class="o">=</span> <span class="n">et</span><span class="o">.</span><span class="n">feature_importances</span><span class="p">(</span><span class="n">fx_train</span><span class="p">,</span> <span class="n">fy_train</span><span class="p">)</span>
<span class="n">ada_features</span> <span class="o">=</span> <span class="n">ada</span><span class="o">.</span><span class="n">feature_importances</span><span class="p">(</span><span class="n">fx_train</span><span class="p">,</span> <span class="n">fy_train</span><span class="p">)</span>
<span class="n">gb_features</span> <span class="o">=</span> <span class="n">gb</span><span class="o">.</span><span class="n">feature_importances</span><span class="p">(</span><span class="n">fx_train</span><span class="p">,</span> <span class="n">fy_train</span><span class="p">)</span>

<span class="n">feature_dataframe</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;features&#39;</span><span class="p">:</span><span class="n">cols</span><span class="p">,</span> 
                                 <span class="s1">&#39;Random Forest feature importances&#39;</span><span class="p">:</span> <span class="n">rf_features</span><span class="p">,</span>
                                 <span class="s1">&#39;AdaBoost feature importances&#39;</span><span class="p">:</span> <span class="n">ada_features</span><span class="p">,</span>
                                 <span class="s1">&#39;Gradient Boost feature importances&#39;</span><span class="p">:</span> <span class="n">gb_features</span><span class="p">,</span>
                                 <span class="s1">&#39;Extra trees feature importances&#39;</span><span class="p">:</span> <span class="n">et_features</span><span class="p">})</span>
</pre></div>


<div class="highlight"><pre><span class="k">def</span> <span class="nf">scatter_plot</span><span class="p">(</span><span class="n">picked_feature_name</span> <span class="o">=</span> <span class="s1">&#39;Random Forest feature importances&#39;</span><span class="p">):</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="n">y</span> <span class="o">=</span> <span class="n">feature_dataframe</span><span class="p">[</span><span class="n">picked_feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                      <span class="n">x</span> <span class="o">=</span> <span class="n">feature_dataframe</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                      <span class="n">mode</span> <span class="o">=</span> <span class="s2">&quot;markers&quot;</span><span class="p">,</span>
                      <span class="n">marker</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">sizemode</span> <span class="o">=</span> <span class="s2">&quot;diameter&quot;</span><span class="p">,</span>
                                   <span class="n">sizeref</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                                   <span class="n">size</span> <span class="o">=</span> <span class="mi">25</span><span class="p">,</span>
                                   <span class="n">color</span> <span class="o">=</span> <span class="n">feature_dataframe</span><span class="p">[</span><span class="n">picked_feature_name</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
                                   <span class="n">colorscale</span> <span class="o">=</span> <span class="s2">&quot;Portland&quot;</span><span class="p">,</span>
                                   <span class="n">showscale</span> <span class="o">=</span> <span class="bp">True</span><span class="p">),</span>
                      <span class="n">text</span> <span class="o">=</span> <span class="n">feature_dataframe</span><span class="p">[</span><span class="s1">&#39;features&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">trace</span><span class="p">]</span>

    <span class="n">layout</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Layout</span><span class="p">(</span><span class="n">autosize</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
                      <span class="n">title</span> <span class="o">=</span> <span class="n">picked_feature_name</span><span class="p">,</span>
                      <span class="n">hovermode</span> <span class="o">=</span> <span class="s2">&quot;closest&quot;</span><span class="p">,</span>
                      <span class="n">yaxis</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">title</span> <span class="o">=</span> <span class="s2">&quot;Feature Importances&quot;</span><span class="p">,</span>
                                  <span class="n">ticklen</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> 
                                  <span class="n">gridwidth</span> <span class="o">=</span> <span class="mi">2</span><span class="p">),</span>
                      <span class="n">showlegend</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

    <span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">,</span> <span class="n">layout</span> <span class="o">=</span> <span class="n">layout</span><span class="p">)</span>

    <span class="n">py</span><span class="o">.</span><span class="n">iplot</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">filename</span> <span class="o">=</span> <span class="s1">&#39;scatter2010&#39;</span><span class="p">)</span>
</pre></div>


<h5>3.5.2.1. RandomForestClassifier Feature Importances</h5>
<div class="highlight"><pre><span class="n">scatter_plot</span><span class="p">(</span><span class="n">picked_feature_name</span> <span class="o">=</span> <span class="s1">&#39;Random Forest feature importances&#39;</span><span class="p">)</span>
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_14.png" title="Logo Title Text 1" /></p>
<h5>3.5.2.2. AdaBoost Feature Importances</h5>
<div class="highlight"><pre><span class="n">scatter_plot</span><span class="p">(</span><span class="n">picked_feature_name</span> <span class="o">=</span> <span class="s1">&#39;AdaBoost feature importances&#39;</span><span class="p">)</span>
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_15.png" title="Logo Title Text 1" /></p>
<h5>3.5.2.3. Gradient Boost Feature Importances</h5>
<div class="highlight"><pre><span class="n">scatter_plot</span><span class="p">(</span><span class="n">picked_feature_name</span> <span class="o">=</span> <span class="s1">&#39;Gradient Boost feature importances&#39;</span><span class="p">)</span>
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_16.png" title="Logo Title Text 1" /></p>
<h5>3.5.2.4. Extra trees Feature Importances</h5>
<div class="highlight"><pre><span class="n">scatter_plot</span><span class="p">(</span><span class="n">picked_feature_name</span> <span class="o">=</span> <span class="s1">&#39;Extra trees feature importances&#39;</span><span class="p">)</span>
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_17.png" title="Logo Title Text 1" /></p>
<h3>3.6. XGBoost</h3>
<p>Finally we will build another model with inputs from the output of the previous models. (This is a little like multi-layers neural network which use previous layers output as current layer input).</p>
<p>This time we will XGBoost to build the model. XGBoost is known for boosted tree learners. It optimizes large scale boosted tree. </p>
<div class="highlight"><pre><span class="n">base_pred</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;randomforest&#39;</span><span class="p">:</span> <span class="n">rf_oof_train</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                                <span class="s1">&#39;extratree&#39;</span><span class="p">:</span> <span class="n">et_oof_train</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                                <span class="s1">&#39;adaboost&#39;</span><span class="p">:</span> <span class="n">ada_oof_train</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                                <span class="s1">&#39;gradientboost&#39;</span><span class="p">:</span> <span class="n">gb_oof_train</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> 
                                <span class="s1">&#39;linearsvc&#39;</span><span class="p">:</span> <span class="n">svc_oof_train</span><span class="o">.</span><span class="n">ravel</span><span class="p">()})</span>
</pre></div>


<p>The correlation of the output from the previous model output is given below. We can see the correlation is not very high so we can safely use these output as input for XGBoost model.</p>
<div class="highlight"><pre><span class="n">data</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">go</span><span class="o">.</span><span class="n">Heatmap</span><span class="p">(</span><span class="n">z</span> <span class="o">=</span> <span class="n">base_pred</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
               <span class="n">x</span> <span class="o">=</span> <span class="n">base_pred</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
               <span class="n">y</span> <span class="o">=</span> <span class="n">base_pred</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
               <span class="n">colorscale</span> <span class="o">=</span> <span class="s2">&quot;Portland&quot;</span><span class="p">,</span>
               <span class="n">showscale</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span>
               <span class="n">reversescale</span> <span class="o">=</span> <span class="bp">True</span>
              <span class="p">)</span>
<span class="p">]</span>
<span class="n">py</span><span class="o">.</span><span class="n">iplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">filename</span> <span class="o">=</span> <span class="s2">&quot;labelled-Heatmap&quot;</span><span class="p">)</span>
</pre></div>


<p><img alt="jpgpng" src="/figures/20170917_aws_device_failure_18.png" title="Logo Title Text 1" /></p>
<div class="highlight"><pre><span class="n">xgb_x_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">et_oof_train</span><span class="p">,</span> <span class="n">rf_oof_train</span><span class="p">,</span> <span class="n">ada_oof_train</span><span class="p">,</span> <span class="n">gb_oof_train</span><span class="p">,</span> <span class="n">svc_oof_train</span><span class="p">),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">xgb_y_train</span> <span class="o">=</span> <span class="n">fy_train</span>

<span class="kn">import</span> <span class="nn">xgboost</span> <span class="kn">as</span> <span class="nn">xgb</span>

<span class="n">gbm</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span>
    <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
    <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
    <span class="n">min_child_weight</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
    <span class="n">subsample</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="n">colsample_bytree</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="n">objective</span> <span class="o">=</span> <span class="s2">&quot;binary:logistic&quot;</span><span class="p">,</span>
    <span class="n">nthread</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">scale_pos_weight</span> <span class="o">=</span> <span class="mi">1</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xgb_x_train</span><span class="p">,</span> <span class="n">xgb_y_train</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">xgb_y_train</span><span class="p">,</span> <span class="n">gbm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xgb_x_train</span><span class="p">))</span>
</pre></div>


<div class="highlight"><pre>array([[10267,   340],
       [    0, 10600]])
</pre></div>


<h3>GridSearch for All</h3>
<div class="highlight"><pre><span class="k">def</span> <span class="nf">gscv</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">tuned_parameters</span><span class="p">):</span>
    <span class="n">cv_grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">param_grid</span> <span class="o">=</span> <span class="n">tuned_parameters</span><span class="p">,</span> <span class="n">scoring</span> <span class="o">=</span> <span class="n">my_score</span><span class="p">)</span>
    <span class="n">cv_grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xtrain</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">)</span>

    <span class="n">best_parameters</span> <span class="o">=</span> <span class="n">cv_grid</span><span class="o">.</span><span class="n">best_estimator_</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">param_name</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">tuned_parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
        <span class="k">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="si">%s</span><span class="s2">: </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">param_name</span><span class="p">,</span> <span class="n">best_parameters</span><span class="p">[</span><span class="n">param_name</span><span class="p">]))</span>
    <span class="n">pred1</span> <span class="o">=</span> <span class="n">cv_grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xtest</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;confustion matrix on validation data: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">ytest</span><span class="p">,</span> <span class="n">pred1</span><span class="p">)))</span>
    <span class="n">pred_full</span> <span class="o">=</span> <span class="n">cv_grid</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">indata</span><span class="p">[</span><span class="n">cols</span><span class="p">])</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;confustion matrix on validation data: &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">indata</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">pred_full</span><span class="p">)))</span>
    <span class="k">return</span> <span class="n">pred_full</span>
</pre></div>


<div class="highlight"><pre><span class="n">rf_tuned_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> 
                           <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">]}</span>
<span class="n">rf_estimator</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">rf_out</span> <span class="o">=</span> <span class="n">gscv</span><span class="p">(</span><span class="n">rf_estimator</span><span class="p">,</span> <span class="n">rf_tuned_parameters</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="n">max_depth</span><span class="o">:</span> <span class="mi">20</span>
<span class="n">min_samples_leaf</span><span class="o">:</span> <span class="mi">2</span>
<span class="n">n_estimators</span><span class="o">:</span> <span class="mi">100</span>

<span class="n">confustion</span> <span class="n">matrix</span> <span class="n">on</span> <span class="n">validation</span> <span class="n">data</span><span class="o">:</span> <span class="o">[[</span><span class="mi">4259</span>   <span class="mi">56</span><span class="o">]</span> <span class="o">[</span>   <span class="mi">0</span> <span class="mi">4168</span><span class="o">]]</span>
<span class="n">confustion</span> <span class="n">matrix</span> <span class="n">on</span> <span class="n">validation</span> <span class="n">data</span><span class="o">:</span> <span class="o">[[</span><span class="mi">124384</span>      <span class="mi">4</span><span class="o">]</span> <span class="o">[</span>    <span class="mi">88</span>     <span class="mi">18</span><span class="o">]]</span>
</pre></div>


<div class="highlight"><pre><span class="n">et_tuned_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> 
                           <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">]}</span>
<span class="n">et_estimator</span> <span class="o">=</span> <span class="n">ExtraTreesClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">et_out</span> <span class="o">=</span> <span class="n">gscv</span><span class="p">(</span><span class="n">et_estimator</span><span class="p">,</span> <span class="n">et_tuned_parameters</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="n">max_depth</span><span class="o">:</span> <span class="mi">50</span>
<span class="n">min_samples_leaf</span><span class="o">:</span> <span class="mi">2</span>
<span class="n">n_estimators</span><span class="o">:</span> <span class="mi">200</span>

<span class="n">confustion</span> <span class="n">matrix</span> <span class="n">on</span> <span class="n">validation</span> <span class="n">data</span><span class="o">:</span> <span class="o">[[</span><span class="mi">4241</span>   <span class="mi">74</span><span class="o">]</span> <span class="o">[</span>   <span class="mi">0</span> <span class="mi">4168</span><span class="o">]]</span>
<span class="n">confustion</span> <span class="n">matrix</span> <span class="n">on</span> <span class="n">validation</span> <span class="n">data</span><span class="o">:</span> <span class="o">[[</span><span class="mi">124382</span>      <span class="mi">6</span><span class="o">]</span> <span class="o">[</span>    <span class="mi">82</span>     <span class="mi">24</span><span class="o">]]</span>
</pre></div>


<div class="highlight"><pre><span class="n">ada_tuned_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">]}</span>
<span class="n">ada_estimator</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">ada_out</span> <span class="o">=</span> <span class="n">gscv</span><span class="p">(</span><span class="n">ada_estimator</span><span class="p">,</span> <span class="n">ada_tuned_parameters</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="n">learning_rate</span><span class="o">:</span> <span class="mi">1</span>
<span class="n">n_estimators</span><span class="o">:</span> <span class="mi">200</span>

<span class="n">confustion</span> <span class="n">matrix</span> <span class="n">on</span> <span class="n">validation</span> <span class="n">data</span><span class="o">:</span> <span class="o">[[</span><span class="mi">4026</span>  <span class="mi">289</span><span class="o">]</span> <span class="o">[</span> <span class="mi">151</span> <span class="mi">4017</span><span class="o">]]</span>
<span class="n">confustion</span> <span class="n">matrix</span> <span class="n">on</span> <span class="n">validation</span> <span class="n">data</span><span class="o">:</span> <span class="o">[[</span><span class="mi">124388</span>      <span class="mi">0</span><span class="o">]</span> <span class="o">[</span>   <span class="mi">105</span>      <span class="mi">1</span><span class="o">]]</span>
</pre></div>


<div class="highlight"><pre><span class="n">gb_tuned_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;max_depth&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="s1">&#39;n_estimators&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span> 
                           <span class="s1">&#39;min_samples_leaf&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">]}</span>
<span class="n">gb_estimator</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">gb_out</span> <span class="o">=</span> <span class="n">gscv</span><span class="p">(</span><span class="n">gb_estimator</span><span class="p">,</span> <span class="n">gb_tuned_parameters</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="n">max_depth</span><span class="o">:</span> <span class="mi">10</span>
<span class="n">min_samples_leaf</span><span class="o">:</span> <span class="mi">20</span>
<span class="n">n_estimators</span><span class="o">:</span> <span class="mi">200</span>

<span class="n">confustion</span> <span class="n">matrix</span> <span class="n">on</span> <span class="n">validation</span> <span class="n">data</span><span class="o">:</span> <span class="o">[[</span><span class="mi">4287</span>   <span class="mi">28</span><span class="o">]</span> <span class="o">[</span>   <span class="mi">0</span> <span class="mi">4168</span><span class="o">]]</span>
<span class="n">confustion</span> <span class="n">matrix</span> <span class="n">on</span> <span class="n">validation</span> <span class="n">data</span><span class="o">:</span> <span class="o">[[</span><span class="mi">124386</span>      <span class="mi">2</span><span class="o">]</span> <span class="o">[</span>    <span class="mi">77</span>     <span class="mi">29</span><span class="o">]]</span>
</pre></div>


<div class="highlight"><pre><span class="n">svc_tuned_parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;C&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]}</span>
<span class="n">svc_estimator</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">svc_out</span> <span class="o">=</span> <span class="n">gscv</span><span class="p">(</span><span class="n">svc_estimator</span><span class="p">,</span> <span class="n">svc_tuned_parameters</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="n">C</span><span class="o">:</span> <span class="mf">0.2</span>

<span class="n">confustion</span> <span class="n">matrix</span> <span class="n">on</span> <span class="n">validation</span> <span class="n">data</span><span class="o">:</span> <span class="o">[[</span><span class="mi">4315</span>    <span class="mi">0</span><span class="o">]</span> <span class="o">[</span><span class="mi">4168</span>    <span class="mi">0</span><span class="o">]]</span>
<span class="n">confustion</span> <span class="n">matrix</span> <span class="n">on</span> <span class="n">validation</span> <span class="n">data</span><span class="o">:</span> <span class="o">[[</span><span class="mi">124388</span>      <span class="mi">0</span><span class="o">]</span> <span class="o">[</span>   <span class="mi">106</span>      <span class="mi">0</span><span class="o">]]</span>
</pre></div>


<div class="highlight"><pre><span class="n">xgb_x_train_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">rf_out</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">et_out</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
                               <span class="n">ada_out</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">gb_out</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> 
                               <span class="n">svc_out</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">xgb_y_train_</span> <span class="o">=</span> <span class="n">indata</span><span class="o">.</span><span class="n">target</span>

<span class="n">gbm</span> <span class="o">=</span> <span class="n">xgb</span><span class="o">.</span><span class="n">XGBClassifier</span><span class="p">(</span>
    <span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
    <span class="n">max_depth</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
    <span class="n">min_child_weight</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
    <span class="n">gamma</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">,</span>
    <span class="n">subsample</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="n">colsample_bytree</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="n">objective</span> <span class="o">=</span> <span class="s2">&quot;binary:logistic&quot;</span><span class="p">,</span>
    <span class="n">nthread</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">scale_pos_weight</span> <span class="o">=</span> <span class="mi">1</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xgb_x_train_</span><span class="p">,</span> <span class="n">xgb_y_train_</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="k">print</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">indata</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">gbm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xgb_x_train_</span><span class="p">)))</span>
</pre></div>


<div class="highlight"><pre><span class="k">[[124386     2]</span>
 <span class="k">[    60     46]]</span>
</pre></div>


<h3>References</h3>
<ol>
<li><a href="http://scikit-learn.org/stable/modules/model_evaluation.html">sklearn score function</a></li>
<li><a href="https://www.hackerearth.com/zh/practice/machine-learning/machine-learning-algorithms/tutorial-random-forest-parameter-tuning-r/tutorial/">Practical Tutorial on Random Forest and Parameter Tuning in R</a></li>
</ol></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
        <a href="/author/huiming-song.html">Huiming Song</a>
    </span>
  </span>
<time datetime="2017-09-23T18:08:00-05:00" pubdate>Sat 23 September 2017</time>  <span class="categories">
    <a class='category' href='/category/python.html'>Python</a>
  </span>
  <span class="categories">
    <a class="category" href="/tag/python.html">python</a>,    <a class="category" href="/tag/data-mining.html">data mining</a>,    <a class="category" href="/tag/sklearn.html">sklearn</a>,    <a class="category" href="/tag/data-visualization.html">data visualization</a>  </span>
</p><div class="sharing">
</div>    </footer>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="/pages/2022/10/22/zhi-chang-hua-ti-bei-mei-hua-ren-gao-guan-zong-jie-de-zhi-chang-shang-sheng-fang-fa/"></a>
      </li>
      <li class="post">
          <a href="/pages/2019/07/27/2019-07-27-week-30-gong-ju-he-ji/">2019-07-27 Week 30 </a>
      </li>
      <li class="post">
          <a href="/pages/2019/07/20/2019-07-20-week-29-nvidia-smi-error/">2019-07-20 Week 29, nvidia-smi error</a>
      </li>
      <li class="post">
          <a href="/pages/2019/06/22/2019-06-22-week-25-gong-ju-he-ji/">2019-06-22 Week 25 </a>
      </li>
      <li class="post">
          <a href="/pages/2019/06/15/2019-06-15-week-24/">2019-06-15 Week 24</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="/category/career-growth.html">career growth</a></li>
        <li><a href="/category/linux.html">Linux</a></li>
        <li><a href="/category/python.html">python</a></li>
        <li><a href="/category/rthers.html">Rthers</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="/tag/pelican.html">pelican</a>,    <a href="/tag/apply_async.html">apply_async</a>,    <a href="/tag/mysql.html">mysql</a>,    <a href="/tag/deep-learning.html">deep learning</a>,    <a href="/tag/data-visualization.html">data visualization</a>,    <a href="/tag/linux.html">linux</a>,    <a href="/tag/apply.html">apply</a>,    <a href="/tag/git.html">git</a>,    <a href="/tag/re.html">re</a>,    <a href="/tag/flask.html">flask</a>,    <a href="/tag/pyqt.html">PyQt</a>,    <a href="/tag/career-growth.html">career growth</a>,    <a href="/tag/dynamic-programming.html">dynamic programming</a>,    <a href="/tag/bokeh.html">bokeh</a>,    <a href="/tag/quant.html">quant</a>,    <a href="/tag/remote-access.html">remote access</a>,    <a href="/tag/tensorflow.html">tensorflow</a>,    <a href="/tag/webcrawl.html">webCrawl</a>,    <a href="/tag/numpy.html">numpy</a>,    <a href="/tag/pandas.html">pandas</a>,    <a href="/tag/tweepy.html">tweepy</a>,    <a href="/tag/map.html">map</a>,    <a href="/tag/shiny.html">shiny</a>,    <a href="/tag/random-walk.html">random walk</a>,    <a href="/tag/python.html">python</a>,    <a href="/tag/leetcode.html">leetcode</a>,    <a href="/tag/matplotlib.html">matplotlib</a>,    <a href="/tag/pytorch.html">pytorch</a>,    <a href="/tag/base.html">base</a>,    <a href="/tag/sentiment-analysis.html">sentiment analysis</a>,    <a href="/tag/sql.html">sql</a>,    <a href="/tag/data-minging.html">data minging</a>,    <a href="/tag/tkinter.html">tkinter</a>,    <a href="/tag/data-mining.html">data mining</a>,    <a href="/tag/spyre.html">spyre</a>,    <a href="/tag/highcharts.html">highcharts</a>,    <a href="/tag/r.html">R</a>,    <a href="/tag/statsmodels.html">statsmodels</a>,    <a href="/tag/docker.html">docker</a>,    <a href="/tag/cx_freeze.html">cx_freeze</a>,    <a href="/tag/multiprocessing.html">multiprocessing</a>,    <a href="/tag/sklearn.html">sklearn</a>  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://www.linkedin.com/pub/huiming-song/24/735/349" target="_blank">Linkedin</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://easysas.blogspot.com/" target="_blank">my old SAS blog</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2015&ndash;2022  shm &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="/theme/js/modernizr-2.0.js"></script>
  <script src="/theme/js/ender.js"></script>
  <script src="/theme/js/octopress.js" type="text/javascript"></script>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-65938411-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-65938411-1');
    ga('send', 'pageview');
</script>
  <script type="text/javascript">
    var disqus_shortname = 'songhuiming';
    var disqus_identifier = '/pages/2017/09/23/data-engineering-and-modeling-01-predict-defaults-with-imbalanced-data/';
    var disqus_url = '/pages/2017/09/23/data-engineering-and-modeling-01-predict-defaults-with-imbalanced-data/';
    var disqus_title = 'Data Engineering and Modeling 01: predict defaults with imbalanced data';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = "//" + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
  </script>
</body>
</html>