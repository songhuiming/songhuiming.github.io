<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Exploratory analysis of Two Sigma Connect: Rental Listing Inquiries &mdash; pydata: Huiming's learning notes</title>
  <meta name="author" content="shm">






  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="/favicon.png" rel="icon">

  <link href="/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><header>
  <h1><a href="/">pydata: Huiming's learning notes</a></h1>
    <h2>Keep Looking, Don't Settle</h2>
</header>

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],  // 允许 $...$ 和 \( ... \) 作为行内公式
    displayMath: [['$$', '$$'], ['\\[', '\\]']],  // 允许 $$...$$ 和 \[ ... \] 作为块级公式
    processEscapes: true,  // 允许在公式中使用转义符，如 \$ 表示美元符号
    processEnvironments: true  // 允许解析 \begin{equation} ... \end{equation} 等数学环境
  },
  options: {
    skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],  // 跳过某些 HTML 标签，防止错误解析
    renderActions: {
      addMenu: []  // 移除右键菜单
    }
  }
};

window.addEventListener('load', () => {
  document.querySelectorAll("mjx-container").forEach(x => {
    x.parentElement.classList.add('has-jax');  // 使用 classList.add() 避免字符串拼接错误
  });
});
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script></header>
  <nav role="navigation">

<form action="https://www.google.com/search" method="get">
    <fieldset role="search">
       <input type="hidden" name="q" value="site:songhuiming.github.io" />
       <input class="search" type="text" name="q" results="0" placeholder="Search"/>
    </fieldset>
</form>


<ul class="main-navigation">
    <li><a href="/functions/archives.html">Archives</a></li>
      <li >
        <a href="/category/career-growth.html">Career growth</a>
      </li>
      <li >
        <a href="/category/linux.html">Linux</a>
      </li>
      <li class="active">
        <a href="/category/python.html">Python</a>
      </li>
      <li >
        <a href="/category/rthers.html">Rthers</a>
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Exploratory analysis of Two Sigma Connect: Rental Listing Inquiries</h1>
    <p class="meta">
<time datetime="2017-02-18T00:00:00-06:00" pubdate>Sat 18 February 2017</time>    </p>
</header>

  <div class="entry-content"><h2>0. Introduction</h2>
<p>Finding the perfect place to call your new home should be more than browsing through endless listings. RentHop makes apartment search smarter by using data to sort rental listings by quality. But while looking for the perfect apartment is difficult enough, structuring and making sense of all available real estate data programmatically is even harder. Two Sigma and RentHop, a portfolio company of Two Sigma Ventures, invite Kagglers to unleash their creative engines to uncover business value in this unique recruiting competition.</p>
<pre><code class="language-python">import numpy as np 
import pandas as pd 
import matplotlib  
from matplotlib import rcParams 
import matplotlib.pyplot as plt
import seaborn as sns
color = sns.color_palette()

%matplotlib inline
plt.rcParams['figure.figsize'] = (8, 6)

train = pd.read_json(r&quot;../indata/train.json&quot;)


print train.head()
</code></pre>
<pre><code>        bathrooms  bedrooms                       building_id  \
10            1.5         3  53a5b119ba8f7b61d4e010512e0dfc85   
10000         1.0         2  c5c8a357cba207596b04d1afd1e4f130   
100004        1.0         1  c3ba40552e2120b0acfc3cb5730bb2aa   
100007        1.0         1  28d9ad350afeaab8027513a3e52ac8d5   
100013        1.0         4                                 0

                    created  \
10      2016-06-24 07:54:24   
10000   2016-06-12 12:19:27   
100004  2016-04-17 03:26:41   
100007  2016-04-18 02:22:02   
100013  2016-04-28 01:32:41

                                              description  \
10      A Brand New 3 Bedroom 1.5 bath ApartmentEnjoy ...   
10000                                                       
100004  Top Top West Village location, beautiful Pre-w...   
100007  Building Amenities - Garage - Garden - fitness...   
100013  Beautifully renovated 3 bedroom flex 4 bedroom...

            display_address  \
10      Metropolitan Avenue   
10000       Columbus Avenue   
100004          W 13 Street   
100007     East 49th Street   
100013    West 143rd Street

                                                 features interest_level  \
10                                                     []         medium   
10000   [Doorman, Elevator, Fitness Center, Cats Allow...            low   
100004  [Laundry In Building, Dishwasher, Hardwood Flo...           high   
100007                          [Hardwood Floors, No Fee]            low   
100013                                          [Pre-War]            low

        latitude  listing_id  longitude                        manager_id  \
10       40.7145     7211212   -73.9425  5ba989232d0489da1b5f2c45f6688adc   
10000    40.7947     7150865   -73.9667  7533621a882f71e25173b27e3139d83d   
100004   40.7388     6887163   -74.0018  d9039c43983f6e564b1482b273bd7b01   
100007   40.7539     6888711   -73.9677  1067e078446a7897d2da493d2f741316   
100013   40.8241     6934781   -73.9493  98e13ad4b495b9613cef886d79a6291f

                                                   photos  price  \
10      [https://photos.renthop.com/2/7211212_1ed4542e...   3000   
10000   [https://photos.renthop.com/2/7150865_be3306c5...   5465   
100004  [https://photos.renthop.com/2/6887163_de85c427...   2850   
100007  [https://photos.renthop.com/2/6888711_6e660cee...   3275   
100013  [https://photos.renthop.com/2/6934781_1fa4b41a...   3350

                 street_address  
10      792 Metropolitan Avenue  
10000       808 Columbus Avenue  
100004          241 W 13 Street  
100007     333 East 49th Street  
100013    500 West 143rd Street
</code></pre>
<h2>1. data description</h2>
<p>This part we will learn the data to understand the data better.</p>
<p>There are 49352 observations, 15 variables. interest_level is the response variable to predict with 3 values： high, medium and low. bathrooms, bedrooms, latitude, longitude, price are the numeric variables. For apartments, it is likely the cheaper and less bedrooms will be more popular. We can check this later. description and features are the text description or labels about the property. display_address and street_address are the address information.Some apartments may be more popular than the others, we can check if this is true or not later.</p>
<h3>1.1. distribution of interest_level</h3>
<p>The response variable interest_level is character with 3 levels, there is no missing value.</p>
<pre><code class="language-python">train.interest_level.value_counts(dropna = False)
</code></pre>
<pre><code>low       34284
medium    11229
high       3839
Name: interest_level, dtype: int64
</code></pre>
<h3>1.2. check the distribution / missing of numeric variables</h3>
<p>There is no missing value for the numeric variables, but there are some outliers.</p>
<p>There is max of bathrooms is 10 and the max of bedrooms is 8. The min of bathrooms and bedrooms are 0. Are they condo? Min of latitude is 0 and max is 44.88. Latitude is mostly around 40.7. Min of longitude is -118.27 and max is 0. Most of longitude is around -73.9. Min of prince is 43 and max is 4.49MM. It is very likely latitude, longitude and price has ourliers.</p>
<pre><code class="language-python">train.describe()
</code></pre>
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>bathrooms</th>
      <th>bedrooms</th>
      <th>latitude</th>
      <th>listing_id</th>
      <th>longitude</th>
      <th>price</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>49352.00000</td>
      <td>49352.000000</td>
      <td>49352.000000</td>
      <td>4.935200e+04</td>
      <td>49352.000000</td>
      <td>4.935200e+04</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1.21218</td>
      <td>1.541640</td>
      <td>40.741545</td>
      <td>7.024055e+06</td>
      <td>-73.955716</td>
      <td>3.830174e+03</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.50142</td>
      <td>1.115018</td>
      <td>0.638535</td>
      <td>1.262746e+05</td>
      <td>1.177912</td>
      <td>2.206687e+04</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.00000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>6.811957e+06</td>
      <td>-118.271000</td>
      <td>4.300000e+01</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>40.728300</td>
      <td>6.915888e+06</td>
      <td>-73.991700</td>
      <td>2.500000e+03</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.00000</td>
      <td>1.000000</td>
      <td>40.751800</td>
      <td>7.021070e+06</td>
      <td>-73.977900</td>
      <td>3.150000e+03</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.00000</td>
      <td>2.000000</td>
      <td>40.774300</td>
      <td>7.128733e+06</td>
      <td>-73.954800</td>
      <td>4.100000e+03</td>
    </tr>
    <tr>
      <th>max</th>
      <td>10.00000</td>
      <td>8.000000</td>
      <td>44.883500</td>
      <td>7.753784e+06</td>
      <td>0.000000</td>
      <td>4.490000e+06</td>
    </tr>
  </tbody>
</table>
</div>

<h3>1.3. check of latitude</h3>
<p>The 1st and 99th percentile of latitude is 40.6404 and 40.862047. So it is reasonable of thinking 0 and 44.8835 as ourliers. We will floor and cap latitude by its 1st and 99th percentile.</p>
<pre><code class="language-python">lat_pct = np.percentile(train.latitude, [1, 99]).tolist()
print lat_pct

train['latitude'] = np.where(train['latitude'] &lt; lat_pct[0], lat_pct[0], 
                             np.where(train['latitude'] &gt; lat_pct[1], lat_pct[1], train['latitude']))
</code></pre>
<pre><code>[40.6404, 40.862047]
</code></pre>
<pre><code class="language-python">train['latitude'].hist(bins = 50)
</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7fb00ff45610&gt;
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_01.png"></p>
<h3>1.4. check of longitude</h3>
<p>The 1st and 99th percentile of longitude is -74.0162 and -73.852651. So we will also floot and cap at these two numbers.</p>
<pre><code class="language-python">long_pct = np.percentile(train.longitude, [1, 99]).tolist()
print long_pct

train['longitude'] = np.where(train['longitude'] &lt; long_pct[0], long_pct[0], 
                             np.where(train['longitude'] &gt; long_pct[1], long_pct[1], train['longitude']))
</code></pre>
<pre><code>[-74.0162, -73.852651]
</code></pre>
<pre><code class="language-python">train['longitude'].hist(bins = 50)
</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7faff2c0b490&gt;
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_02.png"></p>
<h3>1.5. basemap of latitude and longitude</h3>
<p>Since latitude and longitude indicates the location of the apartment. we can plot them on the basemap to get more intuitive impression about the location.</p>
<p>From the basemap plot, most of the apartments are on the island. It will be better if we can check the y distribution based on the combination of latitude and longitude. But since there are many combinations(more than 10000) of latitude and longitude in the data, it is not good way to do this. But this may indicate that we should re-group latitude and longitude in the model.</p>
<pre><code class="language-python">plt.style.use('ggplot')
new_style = {'grid': False}  
matplotlib.rc('axes', **new_style)  

rcParams['figure.figsize'] = (12, 12) #Size of figure  
rcParams['figure.dpi'] = 10000

P=train.plot(kind='scatter', x='longitude', y='latitude',color='white',xlim=(-74.02, -73.85),ylim=(40.64, 40.86),
             s=.1, alpha=1, title = &quot;basemap location plot based on latitude and longitude&quot;)

P.set_axis_bgcolor('black') #Background Color
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_03.png"></p>
<pre><code class="language-python">train.ix[:, ['latitude', 'longitude']].drop_duplicates().shape
</code></pre>
<pre><code>(10933, 2)
</code></pre>
<p>We can plot the high and medium level location to have a look if there is any special location of these levels. But from the plot it does not show special locations.</p>
<pre><code class="language-python">plt.style.use('ggplot')
new_style = {'grid': False}  
matplotlib.rc('axes', **new_style)  

rcParams['figure.figsize'] = (12, 12) #Size of figure  
rcParams['figure.dpi'] = 10000

P=train.query('interest_level == &quot;high&quot;').plot(kind='scatter', x='longitude', y='latitude',color='white',
                                               xlim=(-74.02, -73.85),ylim=(40.64, 40.86),s=.1, alpha=1, title = &quot;high level plot&quot;)
P.set_axis_bgcolor('black') #Background Color
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_04.png"></p>
<pre><code class="language-python">plt.style.use('ggplot')
new_style = {'grid': False}  
matplotlib.rc('axes', **new_style)  

rcParams['figure.figsize'] = (12, 12) #Size of figure  
rcParams['figure.dpi'] = 10000

P=train.query('interest_level == &quot;medium&quot;').plot(kind='scatter', x='longitude', y='latitude',color='white',
                                                 xlim=(-74.02, -73.85),ylim=(40.64, 40.86),s=.1, alpha=1, title = &quot;medium level plot&quot;)

P.set_axis_bgcolor('black') #Background Color
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_05.png"></p>
<h3>1.5. check of price</h3>
<p>The 1st and 99th percentile of price is 1475 and 13000. To be reasonable, we can floor and cap at 500 to 20000 for price.</p>
<pre><code class="language-python">price_pct = np.percentile(train.price, [1, 5, 95, 99]).tolist()
print price_pct

train['price'] = np.where(train['price'] &lt; 500, 500, 
                             np.where(train['price'] &gt; 20000, 20000, train['price']))
</code></pre>
<pre><code>[1475.0, 1800.0, 6895.0, 13000.0]
</code></pre>
<pre><code class="language-python">train.price.hist(bins = 50)
</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f94bd61f7d0&gt;
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_06.png"></p>
<p>Let's have a look at the price level at each interest_level. To avoid the bias in case of outliers, we will use median to compare. As is shown, the high interest level has the lowest median price, the low interest level has the highest price. That is, the higher the price, the less interest it is.</p>
<p>The same conclusion is there for price per bedroom. We can also find the median bedrooms for hign and medium are 2 while the bedrooms for low level is 1.</p>
<pre><code class="language-python">train.groupby('interest_level').price.median()
</code></pre>
<pre><code>interest_level
high      2400
low       3300
medium    2895
Name: price, dtype: int64
</code></pre>
<pre><code class="language-python">train['pricetobedroom'] = train.price / train.bedrooms
train['pricetobathroom'] = train.price / train.bathrooms

print train.ix[:, ['interest_level', 'price', 'bedrooms', 'bathrooms', 'pricetobedroom', 'pricetobathroom']]\
.groupby('interest_level').agg('median')
</code></pre>
<pre><code>                price  bedrooms  bathrooms  pricetobedroom  pricetobathroom
interest_level                                                             
high             2400         2        1.0          1625.0           2300.0
low              3300         1        1.0          2700.0           2995.0
medium           2895         2        1.0          1887.5           2650.0
</code></pre>
<h3>1.6. locations having only one rating</h3>
<p>For hign interest ratings, there are about 20% locations only have high rating. For medium ratings, it is also about 20% of the locations only have medium ratings. For low ratings, there are about 33% of the locations only have low ratings. For the other locations, they have more than 1 ratings. For these locations only have one rating, shall we only predict one rating for them? Or at least we should take them out from modeling. </p>
<pre><code class="language-python">grp = train.groupby(['latitude', 'longitude'])
cnt1 = grp.interest_level.apply(lambda x: x.value_counts()).reset_index(name=&quot;interest_level_cnts&quot;)
cnt2 = grp.size().reset_index(name = 'size')
cnt = pd.merge(cnt1, cnt2, how = 'inner', on = [&quot;latitude&quot;, &quot;longitude&quot;])
cnt['pct'] = cnt.interest_level_cnts / cnt.ix[:, 'size']
</code></pre>
<pre><code class="language-python">cnt.query('level_2 == &quot;high&quot;').sort_values('pct').pct.hist(bins = 50, normed=True)
plt.plot()
</code></pre>
<pre><code>[]
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_07.png"></p>
<pre><code class="language-python">cnt.query('level_2 == &quot;medium&quot;').sort_values('pct').pct.hist(bins = 50, normed=True)
plt.plot()
</code></pre>
<pre><code>[]
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_08.png"></p>
<pre><code class="language-python">cnt.query('level_2 == &quot;low&quot;').sort_values('pct').pct.hist(bins = 50, normed=True)
plt.plot()
</code></pre>
<pre><code>[]
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_09.png"></p>
<pre><code class="language-python">cnt.query('level_2 == &quot;high&quot; &amp; pct &lt; 1').sort_values('pct').pct.hist(bins = 50, normed=True)
</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f94b74a1e50&gt;
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_10.png"></p>
<pre><code class="language-python">cnt.query('level_2 == &quot;medium&quot; &amp; pct &lt; 1').sort_values('pct').pct.hist(bins = 50, normed=True)
</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f94bdd6e350&gt;
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_11.png"></p>
<pre><code class="language-python">cnt.query('level_2 == &quot;low&quot; &amp; pct &lt; 1').sort_values('pct').pct.hist(bins = 50, normed=True)
</code></pre>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f94b75d3910&gt;
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_12.png"></p>
<pre><code class="language-python">cnt_mix = cnt.ix[:, ['latitude', 'longitude', 'pct']].query('pct &lt; 1').drop_duplicates(['latitude', 'longitude'])
train_mix = pd.merge(train, cnt_mix, how = 'inner', on = ['latitude', 'longitude'])

print train_mix.ix[:, ['interest_level', 'price', 'bedrooms', 'bathrooms', 'pricetobedroom', 'pricetobathroom']]\
.groupby('interest_level').agg('median')
</code></pre>
<pre><code>                price  bedrooms  bathrooms  pricetobedroom  pricetobathroom
interest_level                                                             
high             2600         2        1.0     1683.333333           2450.0
low              3345         1        1.0     2800.000000           3000.0
medium           2950         2        1.0     1950.000000           2700.0
</code></pre>
<h3>1.7. character variables</h3>
<p>displary_adress, description, features and street_address are the character variables. display_adress is not normalized characters, which have special characters like ' ,.$# ' and so on. We will first remove these special characters and then strip to remove leading and tailing blanks, and then compress to remove the multiple blanks in the middle. </p>
<p>After cleaning display_adress, wall st, broadway, e 34th st, second ave and w 37th st are the location with most listings.There are about 4k locations with only one listing.So either we don't include it in the model or we have to combine the address since it has too many levels.</p>
<p>A good way to display these characters is <a href="https://en.wikipedia.org/wiki/Tag_cloud">word cloud</a>. It shows the size of the character in accordance with its frequency: the higher the frequency of the character, the bigger the size is. The following will show how to draw the wordcloud.</p>
<pre><code class="language-python">train['display_address2'] = train.display_address.map(lambda x: &quot; &quot;.join(x.strip(&quot;-,.$*!#&amp;\'\t&quot;).replace(&quot;'&quot;,'').lower()\
                                                                         .replace('street', 'st').replace('avenue', 'ave')\
                                                                         .replace('east', 'e').replace('west', 'w').split()))
train['display_address2'].value_counts(dropna = False)[:20]
</code></pre>
<pre><code>wall st          451
broadway         443
e 34th st        441
w st             412
second ave       370
w 37th st        370
john st          346
gold st          345
york ave         316
washington st    304
w 42nd st        295
columbus ave     292
lexington ave    283
e 39th st        281
water st         280
first ave        268
e 79th st        253
e 35th st        251
w 54th st        240
e 89th st        238
Name: display_address2, dtype: int64
</code></pre>
<pre><code class="language-python">from wordcloud import WordCloud
display_address_word = ' '.join(train['display_address2'].values.tolist())

plt.figure(figsize=(12, 9))
wordcloud = WordCloud(background_color='white', width=600, height=300, max_font_size=50, max_words=40).generate(display_address_word)
wordcloud.recolor(random_state=0)
plt.imshow(wordcloud)
plt.title(&quot;Wordcloud for display address&quot;, fontsize=30)
plt.axis(&quot;off&quot;)
plt.show()
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_13.png"></p>
<pre><code class="language-python">display_address_word2 = ' '.join(train.display_address.map(lambda x: '_'.join(x.strip().split(&quot; &quot;))))

plt.figure(figsize=(12, 9))
wordcloud = WordCloud(background_color='white', width=600, height=300, max_font_size=50, max_words=40).generate(display_address_word2)
wordcloud.recolor(random_state=0)
plt.imshow(wordcloud)
plt.title(&quot;Wordcloud for display address&quot;, fontsize=30)
plt.axis(&quot;off&quot;)
plt.show()
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_14.png"></p>
<pre><code class="language-python">feature_list = train.features.values.tolist()
feature_list_all = [item for sublist in feature_list for item in sublist]
feature_list_all_norm = map(lambda x: &quot;_&quot;.join(x.strip().split(&quot; &quot;)), feature_list_all)
feature_list_all_norm_ = &quot; &quot;.join(feature_list_all_norm)

plt.figure(figsize=(12, 9))
wordcloud = WordCloud(background_color='white', width=600, height=300, max_font_size=50, max_words=40).generate(feature_list_all_norm_)
wordcloud.recolor(random_state=0)
plt.imshow(wordcloud)
plt.title(&quot;Wordcloud for features&quot;, fontsize=30)
plt.axis(&quot;off&quot;)
plt.show()
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_15.png"></p>
<h2>2. Distribution of y on x</h2>
<p>From above analysis we got the clue that number of bedrooms and price are the two very important variables. Here we will show a little more relation between y and x.</p>
<h3>2.1. high/low/medium counts on number of bedrooms</h3>
<p>For each number of bedrooms(0, 1, 2...) we can count how many times high/low/medium occurs. From the graph below, the 1 bedroom occurs most, next by two bedrooms, and then 0 bedrooms. For each of these, low appers most, then medium. hign appears least.</p>
<pre><code class="language-python">plt.figure(figsize=(12, 9))
ax = sns.countplot(x='bedrooms', hue='interest_level', data=train)
plt.ylabel('Interest_level frequency', fontsize=12)
plt.xlabel('bedrooms', fontsize=12)
plt.show()
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_16.png"></p>
<p>But this only tell us the counts. It does not tell us the distribution of interest_level on different bedrooms. Next we will calculate the percentage.</p>
<p>From the analysis, we can find low rate is a little high on bedroom=1 than the others from 0 to 4. On 5, 6, 7 and 8, the low rate is very high which is almost 1. So we can have the rough conclusion that if bedrooms is more than or equal to 5, it is very likely it will be low interest.</p>
<pre><code class="language-python">f = lambda x: x.value_counts()/x.shape[0]
s = train.groupby('bedrooms').interest_level.apply(f)
s = s.unstack(level = -1)

fig, ax = plt.subplots()
s.plot.bar(width = .9, ax = ax)
for p in ax.patches: 
    ax.annotate(int(np.round(p.get_height()*100)), (p.get_x()+p.get_width()/2., p.get_height()), \
                ha='center', va='center', xytext=(0, 3), size = 8, textcoords='offset points') 

plt.legend(loc = 0)
plt.ylabel(&quot;percentage*100&quot;)
</code></pre>
<pre><code>&lt;matplotlib.text.Text at 0x7f94bddf2750&gt;
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_17.png"></p>
<h3>2.2. counts of features v.s. y</h3>
<p>Features is a list with different kind of keywords. We can apply text mining on it. But the easiest way if to check the feqture keyword counts v.s. y.</p>
<p>From the feature_cnt histogram, there is only few with more than 15 features. so we will cap at 15. </p>
<p>From the percentage plot, we can find features count from 0 to 3, low interest is increasing, medium interest is decreasing. After 4, low interest is decreasing and medium interest is increasing. For high interest, it is high on two tails(start and end), and it is low in the center.</p>
<pre><code class="language-python">train['feature_cnt'] = train.features.map(lambda x: len(x))

train['feature_cnt'].hist(bins = 20)
train['feature_cnt'] = np.where(train['feature_cnt']&lt;=15, train['feature_cnt'], 15)

f = lambda x: x.value_counts()/x.shape[0]
s = train.groupby('feature_cnt').interest_level.apply(f)
s = s.unstack(level = -1)

fig, ax = plt.subplots()
s.plot.bar(width = .9, ax = ax)
for p in ax.patches: 
    ax.annotate(int(np.round(p.get_height()*100)), (p.get_x()+p.get_width()/2., p.get_height()), \
                ha='center', va='center', xytext=(0, 3), size = 8, textcoords='offset points') 

plt.legend(loc = 0)
plt.ylabel(&quot;percentage*100&quot;)
</code></pre>
<pre><code>&lt;matplotlib.text.Text at 0x7f94bdb6ddd0&gt;
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_18.png"></p>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_19.png"></p>
<p>Another popular plot to show the realtion at different level is <a href="https://en.wikipedia.org/wiki/Violin_plot">violin plot</a>. </p>
<pre><code class="language-python">plt.figure(figsize=(12, 10))
sns.violinplot(y=&quot;feature_cnt&quot;, x=&quot;interest_level&quot;, data=train, order =['low','medium','high'])
plt.xlabel('interest_level', fontsize=12)
plt.ylabel('Number of features', fontsize=12)
plt.show()
</code></pre>
<p><img alt="png" src="/figures/20170218_twosigma_renthop_20.png"></p>
<p>Next we will begin to build models based on the analysis above.</p></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
        <a href="/author/huiming-song.html">Huiming Song</a>
    </span>
  </span>
<time datetime="2017-02-18T00:00:00-06:00" pubdate>Sat 18 February 2017</time>  <span class="categories">
    <a class='category' href='/category/python.html'>Python</a>
  </span>
  <span class="categories">
    <a class="category" href="/tag/python.html">python</a>,    <a class="category" href="/tag/data-visualization.html">data visualization</a>,    <a class="category" href="/tag/matplotlib.html">matplotlib</a>,    <a class="category" href="/tag/data-minging.html">data minging</a>  </span>
</p><div class="sharing">
</div>    </footer>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="/pages/2025/02/23/deepseek-v3-learning-notes/">DeepSeek V3 learning notes</a>
      </li>
      <li class="post">
          <a href="/pages/2025/02/16/deepseek-v3/">DeepSeek V3</a>
      </li>
      <li class="post">
          <a href="/pages/2024/04/21/prediction-in-decoder-and-kv-cache/">Prediction in decoder and KV-Cache</a>
      </li>
      <li class="post">
          <a href="/pages/2023/10/01/image-generation-2-latent-diffusion-model-stable-diffusion/">Image Generation 2: Latent Diffusion model / Stable Diffusion</a>
      </li>
      <li class="post">
          <a href="/pages/2023/07/04/image-generation-1-diffusion-model/">Image Generation 1: Diffusion model</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="/category/career-growth.html">career growth</a></li>
        <li><a href="/category/linux.html">Linux</a></li>
        <li><a href="/category/python.html">python</a></li>
        <li><a href="/category/rthers.html">Rthers</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="/tag/python.html">python</a>,    <a href="/tag/ai.html">AI</a>,    <a href="/tag/llm.html">LLM</a>,    <a href="/tag/aig.html">AIG</a>,    <a href="/tag/agi.html">AGI</a>,    <a href="/tag/gpt.html">GPT</a>,    <a href="/tag/data-mining.html">data mining</a>,    <a href="/tag/sklearn.html">sklearn</a>,    <a href="/tag/pytorch.html">pytorch</a>,    <a href="/tag/career-growth.html">career growth</a>,    <a href="/tag/linux.html">linux</a>,    <a href="/tag/deep-learning.html">deep learning</a>,    <a href="/tag/leetcode.html">leetcode</a>,    <a href="/tag/dynamic-programming.html">dynamic programming</a>,    <a href="/tag/flask.html">flask</a>,    <a href="/tag/highcharts.html">highcharts</a>,    <a href="/tag/sql.html">sql</a>,    <a href="/tag/webcrawl.html">webCrawl</a>,    <a href="/tag/random-walk.html">random walk</a>,    <a href="/tag/multiprocessing.html">multiprocessing</a>,    <a href="/tag/data-visualization.html">data visualization</a>,    <a href="/tag/numpy.html">numpy</a>,    <a href="/tag/tensorflow.html">tensorflow</a>,    <a href="/tag/quant.html">quant</a>,    <a href="/tag/statsmodels.html">statsmodels</a>,    <a href="/tag/pandas.html">pandas</a>,    <a href="/tag/docker.html">docker</a>,    <a href="/tag/matplotlib.html">matplotlib</a>,    <a href="/tag/data-minging.html">data minging</a>,    <a href="/tag/remote-access.html">remote access</a>,    <a href="/tag/mysql.html">mysql</a>,    <a href="/tag/base.html">base</a>,    <a href="/tag/tweepy.html">tweepy</a>,    <a href="/tag/bokeh.html">bokeh</a>,    <a href="/tag/sentiment-analysis.html">sentiment analysis</a>,    <a href="/tag/map.html">map</a>,    <a href="/tag/apply.html">apply</a>,    <a href="/tag/apply_async.html">apply_async</a>,    <a href="/tag/git.html">git</a>,    <a href="/tag/pyqt.html">PyQt</a>,    <a href="/tag/cx_freeze.html">cx_freeze</a>,    <a href="/tag/tkinter.html">tkinter</a>,    <a href="/tag/pelican.html">pelican</a>,    <a href="/tag/spyre.html">spyre</a>,    <a href="/tag/shiny.html">shiny</a>,    <a href="/tag/r.html">R</a>,    <a href="/tag/re.html">re</a>  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://www.linkedin.com/pub/huiming-song/24/735/349" target="_blank">Linkedin</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://easysas.blogspot.com/" target="_blank">my old SAS blog</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2015&ndash;2025  shm &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="/theme/js/modernizr-2.0.js"></script>
  <script src="/theme/js/ender.js"></script>
  <script src="/theme/js/octopress.js" type="text/javascript"></script>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-65938411-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-65938411-1');
    ga('send', 'pageview');
</script>
  <script type="text/javascript">
    var disqus_shortname = 'songhuiming';
    var disqus_identifier = '/pages/2017/02/18/exploratory-analysis-of-two-sigma-connect-rental-listing-inquiries/';
    var disqus_url = '/pages/2017/02/18/exploratory-analysis-of-two-sigma-connect-rental-listing-inquiries/';
    var disqus_title = 'Exploratory analysis of Two Sigma Connect: Rental Listing Inquiries';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = "//" + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
  </script>
</body>
</html>