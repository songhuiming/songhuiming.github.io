<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Build Neural Network from Scratch &mdash; pydata</title>
  <meta name="author" content="shm">






  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">


    <link href="/favicon.png" rel="icon">

  <link href="/theme/css/main.css" media="screen, projection"
        rel="stylesheet" type="text/css">

  <link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
  <link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic"
        rel="stylesheet" type="text/css">
</head>

<body>
  <header role="banner"><hgroup>
  <h1><a href="/">pydata</a></h1>
    <h2>Keep Looking, Don't Settle</h2>
</hgroup>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
        MathJax.Hub.Config({
            config: ["MMLorHTML.js"],
            extensions: ["tex2jax.js","TeX/AMSmath.js","TeX/AMSsymbols.js"],
            jax: ["input/TeX"],
            tex2jax: {
                inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                processEscapes: false
            },
            TeX: {
                TagSide: "right",
                TagIndent: ".8em",
                MultLineWidth: "85%",
                equationNumbers: {
                   autoNumber: "AMS",
                },
                unicode: {
                   fonts: "STIXGeneral,'Arial Unicode MS'"
                }
            },
            showProcessingMessages: false
        });
</script></header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
</ul>

<form class="search" action="/search.html">
    <input type="text" class="search-query" placeholder="Search" name="q" id="s">
</form>

<form action="https://www.google.com/search" method="get">
    <fieldset role="search">
       <input type="hidden" name="q" value="site:songhuiming.github.io" />
       <input class="search" type="text" name="q" results="0" placeholder="Search"/>
    </fieldset>
</form>


<ul class="main-navigation">
    <li><a href="/functions/archives.html">Archives</a></li>
      <li >
        <a href="/category/career-growth.html">Career growth</a>
      </li>
      <li >
        <a href="/category/linux.html">Linux</a>
      </li>
      <li class="active">
        <a href="/category/python.html">Python</a>
      </li>
      <li >
        <a href="/category/rthers.html">Rthers</a>
      </li>
</ul></nav>
  <div id="main">
    <div id="content">
<div>
  <article class="hentry" role="article">
<header>
      <h1 class="entry-title">Build Neural Network from Scratch</h1>
    <p class="meta">
<time datetime="2017-08-12T15:08:00-05:00" pubdate>Sat 12 August 2017</time>    </p>
</header>

  <div class="entry-content"><h2>How to build Neural Network from scratch</h2>
<p>This post will introduce how to build a neural network from stratch: </p>
<ol>
<li>the forward-propagation: from input data to activations on each layer</li>
<li>the backpropagation: using chain rules to calculate the deravatives of cost function to weights(parameters) on each layer</li>
<li>minimize the cost function by SGD with the derivatives from step 2.</li>
</ol>
<h3>Example 1.</h3>
<p>First I will introduce a very simple example. Suppose we have data like the following. <span class="math">\(X\)</span> is a 4x3 array. <span class="math">\(Y\)</span> is a 4x1 vector. The task is to predict the output <span class="math">\(Y\)</span> based on the input <span class="math">\(X\)</span>. We will show how to build a neural network to do this job.</p>
<table cellspacing="10" width="400">
  <tr>
    <td colspan="3"  align="center" valign="middle">Inputs: X</td>
    <td  align="center" valign="middle">Output: Y</td>
  </tr>

  <tr>
    <td align="center" valign="middle">0 </td>
    <td align="center" valign="middle">0 </td>
    <td align="center" valign="middle">1 </td>
    <td align="center" valign="middle">0 </td>
  </tr>
  <tr>
    <td align="center" valign="middle">0</td>
    <td align="center" valign="middle">1</td>
    <td align="center" valign="middle">1</td>
    <td align="center" valign="middle">1</td>
  </tr>
  <tr>
    <td align="center" valign="middle">1</td>
    <td align="center" valign="middle">0</td>
    <td align="center" valign="middle">1</td>
    <td align="center" valign="middle">1</td>
  </tr> 
  <tr>
    <td align="center" valign="middle">1</td>
    <td align="center" valign="middle">1</td>
    <td align="center" valign="middle">1</td>
    <td align="center" valign="middle">0</td>
  </tr> 
</table>

<p>Our NN will have 2 layers. The first layer is from input <span class="math">\(X\)</span> (we will call it <span class="math">\(a_1\)</span>) to activations <span class="math">\(a_2\)</span> with the sigmoid activation function. The shape of the weights for the first layer (<span class="math">\(\Theta_1^{T}\)</span>) is 4x3. So the shape of layer 1 is 4x4.</p>
<p>The layer 1 (<span class="math">\(a_2\)</span>) will be the input for the second layer(<span class="math">\(a_3\)</span>) with weights parameter <span class="math">\(\Theta_2^{T}\)</span> and sigmoid activation function. The shape of <span class="math">\(\Theta_2^{T}\)</span> is 4x1 (the shape of input data to layer 2 is 4x4 and the shape of <span class="math">\(Y\)</span> is 4x1, these two will determine the shape of <span class="math">\(\Theta_2\)</span> because layer 2 is the output layer here).</p>
<h2>Preparation</h2>
<h3>1.1. Model Structure</h3>
<p>Our prediction Neural Network will have two layers: the first layer a linear combination between input <span class="math">\(X\)</span> and parameter <span class="math">\(\theta_1\)</span>. Then this will be the input to the <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid</a> function, which is the second layer. </p>
<div class="math">\begin{aligned}
    a_1 &amp;= X \\
    z_1 &amp;= a_1 \cdot \Theta_1^{T}  \\
    a_2 &amp;= \mbox{sigmoid}(z_1) = \frac{1}{1 + e^{- z_1}}  \qquad \mbox{the first activation layer} \\
    z_2 &amp;= a_2 \cdot \Theta_2^{T} \\
    a_3 &amp;= \mbox{sigmoid}(z_2) = \frac{1}{1 + e^{- z_2}}  \qquad \mbox{the second activation layer}
\end{aligned}</div>
<p>The symbal <span class="math">\(\cdot\)</span> above means <a href="https://en.wikipedia.org/wiki/Dot_product">dot product</a> of the vector or the matrix. We also need the [elementwise product](https://en.wikipedia.org/wiki/Hadamard_product_(matrices) denoted as <span class="math">\(\odot\)</span>.</p>
<h3>1.2. Cost Function</h3>
<p>Cost function generally measures the distance between the predictions and the true value. </p>
<ol>
<li>
<p><strong><a href="https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_error_function_and_logistic_regression">Cross Entropy</a> Loss function</strong>:
<div class="math">\begin{aligned}
     C = -\frac{1}{n}\sum_{x}\left[y \log(a_3) + (1 - y)\log(1 - a_3) \right]  
\end{aligned}</div>
</p>
</li>
<li>
<p><strong>L2 cost function</strong>:</p>
</li>
</ol>
<div class="math">\begin{aligned}
    C = \frac{1}{2}||y - a_3||^2  
\end{aligned}</div>
<h3>1.3. Derivatives / Gradient</h3>
<p>Suppose the Lost function is
</p>
<div class="math">\begin{aligned}
    C = \frac{1}{2} ||y - a_3||^2   
\end{aligned}</div>
<p>First, let's denote
</p>
<div class="math">\begin{aligned}
    d_3 &amp;= (a_3 - y) \odot (a_3 \odot (1 - a_3))  ,\; \; \mbox{ or call it } a_3\_delta \\
    d_2 &amp;= d_3 \cdot \Theta_2 \odot (a_2 \odot (1 - a_2)) 
\end{aligned}</div>
<p>The partival derivative of Loss function to parameter <span class="math">\(\Theta_2\)</span> using chain rule is:
</p>
<div class="math">\begin{aligned}
    \frac{\partial {C}}{\partial {\Theta_2}} &amp; = \frac{\partial{C}}{\partial{a_3}} \frac{\partial{a_3}}{\partial{z_2}} \frac{\partial{z_2}}{\partial{\Theta_2}} \\
    &amp; = (a_3 - y) \left(a_3 (1 - a_3)\right) a_2  \; \; (\mbox{if all are scalers}) \\
    &amp; =  \left[(a_3 - y) \odot \left(a_3 \odot (1 - a_3)\right)\right]^{T} \cdot a_2 \\
    &amp;  \triangleq   d_3^{T} \cdot a_2  
\end{aligned}</div>
<p>where  <span class="math">\(d_3 \triangleq (a_3 - y) \odot \left(a_3 \odot (1 - a_3)\right)\)</span> . <span class="math">\(\odot\)</span>  maens element-wise product, <span class="math">\(\cdot\)</span> means dot product.</p>
<p>The partival derivative of Loss function to parameter <span class="math">\(\Theta_1\)</span> using chain rule is:
</p>
<div class="math">\begin{aligned}
    \frac{\partial {C}}{\partial {\Theta_1}} &amp; = \frac{\partial{C}}{\partial{a_3}} \frac{\partial{a_3}}{\partial{z_2}} \frac{\partial{z_2}}{\partial{a_2}} \frac{\partial{a_2}}{\partial{z_1}} \frac{\partial{z_1}}{\partial{\Theta_1}}  \\
    &amp; \propto (a_3 - y) \left(a_3 (1 - a_3)\right) \Theta_2 (a_2 (1 - a_2)) a_1 \\
    &amp; \propto \left[(a_3 - y) \odot \left(a_3 (1 - a_3)\right) \cdot \Theta_2 \odot (a_2 \odot (1 - a_2))\right]^{T} a_1 \\
    &amp;  = d_2^{T} \cdot a_1
\end{aligned}</div>
<p>
where <span class="math">\(d_2 \triangleq d_3 \cdot \Theta_2 \odot \left(a_2 \odot (1 - a_2) \right)\)</span> .</p>
<p>To find the value of <span class="math">\(\Theta_1\)</span> and <span class="math">\(\Theta_2\)</span>, we need to iteratively adjust their value until their gradient is close to 0. That is, to iterate:</p>
<div class="math">\begin{aligned}
    \Theta_2^{i + 1} &amp;= \Theta_2^{i} + \lambda  \frac{\partial {C}}{\partial {\Theta_2^{i}}}  \\
    \Theta_1^{i + 1} &amp;= \Theta_1^{i} + \lambda  \frac{\partial {C}}{\partial {\Theta_1^{i}}} 
\end{aligned}</div>
<h3>4. Code</h3>
<div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="n">a1</span> <span class="o">=</span> <span class="n">x</span>
<span class="n">theta1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">theta2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>

<span class="n">learning_rate</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100000</span><span class="p">):</span>
    <span class="c1"># forward propagation: including the first layer and the second layer</span>
    <span class="n">z1</span> <span class="o">=</span> <span class="n">a1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta1</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">a2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z1</span><span class="p">)</span> 
    <span class="n">z2</span> <span class="o">=</span> <span class="n">a2</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">a3</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span> 

    <span class="c1"># backpropagation: chain rules of the partial derivatives</span>
    <span class="n">a3_error</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">a3</span>
    <span class="n">theta2_grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">a3_error</span> <span class="o">*</span> <span class="p">(</span><span class="n">a3</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">a3</span><span class="p">))),</span> <span class="n">a2</span><span class="p">)</span> 
    <span class="n">theta1_grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a3_error</span> <span class="o">*</span> <span class="p">(</span><span class="n">a3</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">a3</span><span class="p">)),</span>  <span class="n">theta2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">a2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">a2</span><span class="p">))),</span> <span class="n">a1</span><span class="p">)</span>

    <span class="c1"># update the parameters until the gradient converges to 0</span>
    <span class="n">theta2</span> <span class="o">+=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">theta2_grad</span>
    <span class="n">theta1</span> <span class="o">+=</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">theta1_grad</span>
</pre></div>


<div class="highlight"><pre><span class="n">theta2</span>
</pre></div>


<div class="highlight"><pre>array([[ -3.16174322,  10.29352444,  11.40818558,  -4.45945196]])
</pre></div>


<div class="highlight"><pre><span class="n">theta1</span>
</pre></div>


<div class="highlight"><pre>array([[ 3.35916278, -3.32786847,  1.87094082],
       [ 5.84130712, -5.98365309, -3.07635286],
       [-6.45870855,  6.34717945, -3.30437575],
       [-3.91182875,  3.95761648,  2.17740367]])
</pre></div>


<div class="highlight"><pre><span class="n">a3</span>
</pre></div>


<div class="highlight"><pre>array([[ 0.00276657],
       [ 0.99710763],
       [ 0.99718615],
       [ 0.00243296]])
</pre></div>


<div class="highlight"><pre><span class="c1"># The prediction is</span>
<span class="n">a3</span> <span class="o">&gt;</span> <span class="mf">0.5</span>
</pre></div>


<div class="highlight"><pre>array([[False],
       [ True],
       [ True],
       [False]], dtype=bool)
</pre></div>


<p>The above is a simple example to introduce the insides of a neural network: how to calculate the forward propagation from input data to the prediction output and the cost function, how to calcualte the back propagatin of the partial derivatives with chain rules, and how to update the parameters until the gradients converging to zero, although in fact neural network is not necessary for this simple example since there are only 4 data points but we have introduced 16 parameters(parameters in <span class="math">\(\Theta_1\)</span> and <span class="math">\(\Theta_2\)</span>).</p>
<h2>Example 2</h2>
<p>The following example is a more real data question: I collect 60 verifacation code graphs. Each graph has 4 characters. The user needs to recognize these 4 characters correctly to get correct input verification.</p>
<p>Each graph has 4 characters. An example of the picture is like</p>
<p><img alt="alt text" src="/figures/20170812_nn_from_scratch_01.png" title="Logo Title Text 1" /></p>
<p>The corresponding characters are: 'k' 'n' 'n' 'p'. </p>
<h3>2.1. Model</h3>
<p>We will build a three layers neural network. </p>
<div class="math">\begin{aligned}
    a_1 &amp;= X \\
    z_1 &amp;= a_1 \cdot \Theta_1^{T}  \\
    a_2 &amp;= \mbox{sigmoid}(z_1) = \frac{1}{1 + e^{- z_1}}  \qquad \mbox{the first activation layer} \\
    z_2 &amp;= a_2 \cdot \Theta_2^{T} \\
    a_3 &amp;= \mbox{sigmoid}(z_2) = \frac{1}{1 + e^{- z_2}}  \qquad \mbox{the second activation layer} \\
    z_3 &amp;= a_3 \cdot \Theta_3^{T}  \\
    a_4 &amp;= \mbox{sigmoid}(z_3) = \frac{1}{1 + e^{- z_3}}  \qquad \mbox{the third activation layer} 
\end{aligned}</div>
<h3>2.2. Derivatives</h3>
<p>Suppose the Lost function is
</p>
<div class="math">\begin{aligned}
    C = -\frac{1}{n}\sum_{x}\left[y \log(a_3) + (1 - y)\log(1 - a_3) \right] 
\end{aligned}</div>
<p>First, let's denote
</p>
<div class="math">\begin{aligned}
    d_4 &amp;= a_4 - y   ,\; \; \mbox{ or call it } a_4\_delta \\
    d_3 &amp;= d_4 \cdot \Theta_3 \odot (a_3 \odot (1 - a_3))  ,\; \; \mbox{ or call it } a_3\_delta \\
    d_2 &amp;= d_3 \cdot \Theta_2 \odot (a_2 \odot (1 - a_2)) 
\end{aligned}</div>
<p>The partival derivative of Loss function to parameter <span class="math">\(\Theta_3\)</span> using chain rule is:</p>
<div class="math">\begin{aligned}
    \frac{\partial {C}}{\partial {\Theta_3}} &amp; = \frac{\partial{C}}{\partial{a_4}} \frac{\partial{a_4}}{\partial{z_4}} \frac{\partial{z_4}}{\partial{\Theta_3}} \\
    &amp; = - \left[ \frac{y}{a_4} - \frac{1 - y}{1 - a_4}  \right] \left(a_4 (1 - a_4)\right) a_3 = ( a_4 - y) a_3  \; \; (\mbox{if all are scalers}) \\
    &amp; =  \left[(a_4 - y)\right]^{T} \cdot a_3 \\
    &amp;  \triangleq   d_4^{T} \cdot a_3  
\end{aligned}</div>
<p>The partival derivative of Loss function to parameter <span class="math">\(\Theta_2\)</span> using chain rule is:</p>
<div class="math">\begin{aligned}
    \frac{\partial {C}}{\partial {\Theta_2}} &amp; =\frac{\partial{C}}{\partial{a_4}} \frac{\partial{a_4}}{\partial{z_4}} \frac{\partial{z_4}}{\partial{a_3}} \frac{\partial a_3}{\partial z_3} \frac{\partial z_3}{\partial \Theta_2} \\
    &amp; \propto - \left[ \frac{y}{a_4} - \frac{1 - y}{1 - a_4}  \right] \left(a_4 (1 - a_4)\right) \Theta_3 (a_3(1-a_3)) a_2  \; \; (\mbox{if all are scalers})  \\
    &amp; =  \left[d_4 \cdot \Theta_3 \odot \left(a_3 \odot (1 - a_3)\right)\right]^{T} \cdot a_2 \\
    &amp;  \triangleq   d_3^{T} \cdot a_2  
\end{aligned}</div>
<p>The partival derivative of Loss function to parameter <span class="math">\(\Theta_1\)</span> using chain rule is:
</p>
<div class="math">\begin{aligned}
    \frac{\partial {C}}{\partial {\Theta_1}} &amp; = \frac{\partial{C}}{\partial{a_4}} \frac{\partial{a_4}}{\partial{z_4}} \frac{\partial{z_4}}{\partial{a_3}} \frac{\partial a_3}{\partial z_3} \frac{\partial z_3}{\partial a_2} \frac{\partial{a_2}}{\partial{z_2}} \frac{\partial{z_2}}{\partial{\Theta_1}}  \\
    &amp; \propto - \left[ \frac{y}{a_4} - \frac{1 - y}{1 - a_4}  \right] \left(a_4 (1 - a_4)\right) \Theta_3 (a_3(1-a_3)) \Theta_2 (a_2(1-a_2)) \cdot a_1 \; \; (\mbox{if all are scalers}) \\
    &amp; = \left[(a_3 - y) \odot \left(a_3 (1 - a_3)\right) \cdot \Theta_2 \odot (a_2 \odot (1 - a_2))\right]^{T} a_1 \\
    &amp;  = d_2^{T} \cdot a_1
\end{aligned}</div>
<h3>2.3. Details</h3>
<p>The overall steps will include these:</p>
<ol>
<li>from pic to data</li>
<li>set up activation function / sigmoid</li>
<li>calc gradient descent function</li>
<li>loss function</li>
<li>predict</li>
<li>put all together</li>
</ol>
<h4>Shape of the data</h4>
<div class="highlight"><pre>Theta1.T: 261 x 200
Theta2.T: 201 x 200
Theta3.T: 201 x 36

X: 240 * 260
a1: 240 * 261
z2: 240 * 200
a2: 240 * 200 -&gt; 240 * 201
z3: 240 * 201
a3: 240 * 200 -&gt; 240 * 201
z4: 240 * 36
a4: 240 * 36

y_matirx: 240 * 36
</pre></div>


<div class="highlight"><pre><span class="kn">import</span> <span class="nn">scipy.io</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">scipy.signal</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">scipy.optimize</span> <span class="kn">as</span> <span class="nn">opt</span>
</pre></div>


<div class="highlight"><pre><span class="n">word</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;0&#39;</span><span class="p">,</span> <span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="s1">&#39;2&#39;</span><span class="p">,</span> <span class="s1">&#39;3&#39;</span><span class="p">,</span> <span class="s1">&#39;4&#39;</span><span class="p">,</span> <span class="s1">&#39;5&#39;</span><span class="p">,</span> <span class="s1">&#39;6&#39;</span><span class="p">,</span> <span class="s1">&#39;7&#39;</span><span class="p">,</span> <span class="s1">&#39;8&#39;</span><span class="p">,</span> <span class="s1">&#39;9&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="s1">&#39;d&#39;</span><span class="p">,</span> <span class="s1">&#39;e&#39;</span><span class="p">,</span> <span class="s1">&#39;f&#39;</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="s1">&#39;h&#39;</span><span class="p">,</span> <span class="s1">&#39;i&#39;</span><span class="p">,</span> <span class="s1">&#39;j&#39;</span><span class="p">,</span> <span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="s1">&#39;l&#39;</span><span class="p">,</span>\
        <span class="s1">&#39;m&#39;</span><span class="p">,</span> <span class="s1">&#39;n&#39;</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="s1">&#39;q&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="s1">&#39;t&#39;</span><span class="p">,</span> <span class="s1">&#39;u&#39;</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">,</span> <span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="s1">&#39;z&#39;</span><span class="p">]</span>

<span class="n">mypath</span> <span class="o">=</span> <span class="s1">r&#39;data/yanzhengma/&#39;</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_pickle</span><span class="p">(</span><span class="n">mypath</span> <span class="o">+</span> <span class="s1">&#39;train_data.pkl&#39;</span><span class="p">)</span>
</pre></div>


<div class="highlight"><pre><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">derivative</span> <span class="o">=</span> <span class="bp">False</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">derivative</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">rand_init_weights</span><span class="p">(</span><span class="n">layer_in</span><span class="p">,</span> <span class="n">layer_out</span><span class="p">):</span>
    <span class="n">epsilon_init</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">layer_out</span><span class="p">,</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">layer_in</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">epsilon_init</span> <span class="o">-</span> <span class="n">epsilon_init</span>

<span class="k">def</span> <span class="nf">nn_gradient</span><span class="p">(</span><span class="n">nn_params</span><span class="p">,</span> <span class="n">input_layer_size</span><span class="p">,</span> <span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambda_param</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    theta1: 200x261</span>
<span class="sd">    theta2: 200x201</span>
<span class="sd">    theta3: 36x201</span>
<span class="sd">    a1: 240x261</span>
<span class="sd">    z2: 240x200</span>
<span class="sd">    a2: 240x200 -&gt; 240x201</span>
<span class="sd">    z3: 240x200</span>
<span class="sd">    a3: 240x2-- -&gt; 240x201</span>
<span class="sd">    z4: 240x36</span>
<span class="sd">    a4: 240x36</span>
<span class="sd">    d4: 240x36</span>
<span class="sd">    d3: 240x201 -&gt; 240x200</span>
<span class="sd">    d2: 240x201 -&gt; 240x200</span>
<span class="sd">    theta1_grad: 200x261</span>
<span class="sd">    theta2_grad: 200x201</span>
<span class="sd">    theta3_grad: 36x201</span>
<span class="sd">    final output: 200x261 + 200x201 + 36x201 = 99636</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">theta1</span> <span class="o">=</span> <span class="n">nn_params</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">theta2</span> <span class="o">=</span> <span class="n">nn_params</span><span class="p">[(</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="p">:</span> \
                       <span class="p">(</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> \
                        <span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">theta3</span> <span class="o">=</span> <span class="n">nn_params</span><span class="p">[(</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> \
                        <span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)):]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">X</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">a1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">X</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">z2</span> <span class="o">=</span> <span class="n">a1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta1</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">a2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>
    <span class="n">a2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">a2</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">z3</span> <span class="o">=</span> <span class="n">a2</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">a3</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z3</span><span class="p">)</span>
    <span class="n">a3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">a3</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">z4</span> <span class="o">=</span> <span class="n">a3</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta3</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">a4</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z4</span><span class="p">)</span>

    <span class="n">y_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_labels</span><span class="p">):</span>
        <span class="n">y_matrix</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">d4</span> <span class="o">=</span> <span class="n">a4</span> <span class="o">-</span> <span class="n">y_matrix</span>
    <span class="n">d3</span> <span class="o">=</span> <span class="n">d4</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta3</span><span class="p">)</span> <span class="o">*</span> <span class="n">a3</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">a3</span><span class="p">)</span>   
    <span class="n">d3</span> <span class="o">=</span> <span class="n">d3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
    <span class="n">d2</span> <span class="o">=</span> <span class="n">d3</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta2</span><span class="p">)</span> <span class="o">*</span> <span class="n">a2</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">a2</span><span class="p">)</span>  
    <span class="n">d2</span> <span class="o">=</span> <span class="n">d2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
    <span class="n">theta1_grad</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">d2</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a1</span><span class="p">))</span>
    <span class="n">theta2_grad</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">d3</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a2</span><span class="p">))</span> 
    <span class="n">theta3_grad</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">d4</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a3</span><span class="p">))</span>  
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">theta1_grad</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">theta2_grad</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">),</span> <span class="n">theta3_grad</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">nn_cost</span><span class="p">(</span><span class="n">nn_params</span><span class="p">,</span> <span class="n">input_layer_size</span><span class="p">,</span> <span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambda_param</span><span class="p">):</span>
    <span class="n">theta1</span> <span class="o">=</span> <span class="n">nn_params</span><span class="p">[</span><span class="mi">0</span><span class="p">:(</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">theta2</span> <span class="o">=</span> <span class="n">nn_params</span><span class="p">[(</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span> <span class="p">:</span> \
                       <span class="p">(</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> \
                        <span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">theta3</span> <span class="o">=</span> <span class="n">nn_params</span><span class="p">[(</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> \
                        <span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)):]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">X</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">a1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">X</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">z2</span> <span class="o">=</span> <span class="n">a1</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta1</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">a2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>
    <span class="n">a2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">a2</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">z3</span> <span class="o">=</span> <span class="n">a2</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">a3</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z3</span><span class="p">)</span>
    <span class="n">a3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">a3</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">z4</span> <span class="o">=</span> <span class="n">a3</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta3</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">a4</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">z4</span><span class="p">)</span>

    <span class="n">y_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_labels</span><span class="p">):</span>
        <span class="n">y_matrix</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">==</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y_matrix</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">a4</span><span class="p">)))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">y_matrix</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">a4</span><span class="p">))))</span> <span class="o">+</span> \
        <span class="n">lambda_param</span> <span class="o">/</span> <span class="p">((</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">theta1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">theta2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">+</span> \
                        <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">theta3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span><span class="o">**</span><span class="mi">2</span><span class="p">)))</span>

<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">theta1</span><span class="p">,</span> <span class="n">theta2</span><span class="p">,</span> <span class="n">theta3</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">X</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">h1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">X</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta1</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
    <span class="n">h2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">h1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta2</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
    <span class="n">h3</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">h2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">theta3</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">h3</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">p</span> <span class="o">+</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">train_data</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="s1">&#39;y&#39;</span><span class="p">]</span>
    <span class="n">input_layer_size</span> <span class="o">=</span> <span class="mi">260</span>
    <span class="n">hidden_layer_size</span> <span class="o">=</span> <span class="mi">200</span>
    <span class="n">num_labels</span> <span class="o">=</span> <span class="mi">36</span>

    <span class="n">initial_theta1</span> <span class="o">=</span> <span class="n">rand_init_weights</span><span class="p">(</span><span class="n">input_layer_size</span><span class="p">,</span> <span class="n">hidden_layer_size</span><span class="p">)</span>
    <span class="n">initial_theta2</span> <span class="o">=</span> <span class="n">rand_init_weights</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">hidden_layer_size</span><span class="p">)</span>
    <span class="n">initial_theta3</span> <span class="o">=</span> <span class="n">rand_init_weights</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>

    <span class="n">initial_nn_params</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">initial_theta1</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">initial_theta2</span><span class="o">.</span><span class="n">flatten</span><span class="p">()),</span> <span class="n">initial_theta3</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
    <span class="n">lambda_param</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">opt</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">fun</span> <span class="o">=</span> <span class="n">nn_cost</span><span class="p">,</span> <span class="n">x0</span> <span class="o">=</span> <span class="n">initial_nn_params</span><span class="p">,</span> \
                          <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">input_layer_size</span><span class="p">,</span> <span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambda_param</span><span class="p">),</span> \
                          <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;CG&quot;</span><span class="p">,</span> <span class="n">jac</span> <span class="o">=</span> <span class="n">nn_gradient</span><span class="p">,</span> <span class="n">options</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;maxiter&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">})</span>
    <span class="n">nn_params</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span>
    <span class="n">theta1</span> <span class="o">=</span> <span class="n">nn_params</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">hidden_layer_size</span><span class="o">*</span><span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">theta2</span> <span class="o">=</span> <span class="n">nn_params</span><span class="p">[</span><span class="n">hidden_layer_size</span><span class="o">*</span><span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="p">:</span> \
                       <span class="p">(</span><span class="n">hidden_layer_size</span><span class="o">*</span><span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> \
                        <span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">theta3</span> <span class="o">=</span> <span class="n">nn_params</span><span class="p">[(</span><span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">input_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> \
                        <span class="n">hidden_layer_size</span> <span class="o">*</span> <span class="p">(</span><span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)):]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="n">hidden_layer_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">theta1</span><span class="p">,</span> <span class="n">theta2</span><span class="p">,</span> <span class="n">theta3</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">&quot;Training Accuracy: &quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="s2">&quot;%&quot;</span><span class="p">)</span>
    <span class="k">return</span>

<span class="n">test</span><span class="p">()</span>
</pre></div>


<div class="highlight"><pre>(&#39;Training Accuracy: &#39;, 100.0000000, &#39;%&#39;)
</pre></div>


<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }
    
    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript'; 
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js','color.js','mhchem.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script></div>
    <footer>
<p class="meta">
  <span class="byline author vcard">
    Posted by <span class="fn">
        <a href="/author/huiming-song.html">Huiming Song</a>
    </span>
  </span>
<time datetime="2017-08-12T15:08:00-05:00" pubdate>Sat 12 August 2017</time>  <span class="categories">
    <a class='category' href='/category/python.html'>Python</a>
  </span>
  <span class="categories">
    <a class="category" href="/tag/python.html">python</a>,    <a class="category" href="/tag/deep-learning.html">deep learning</a>  </span>
</p><div class="sharing">
</div>    </footer>
  </article>

</div>
<aside class="sidebar">
  <section>
    <h1>Recent Posts</h1>
    <ul id="recent_posts">
      <li class="post">
          <a href="/pages/2021/12/31/recommendation-system-05-bayesian-optimization/">Recommendation System 05 - Bayesian Optimization</a>
      </li>
      <li class="post">
          <a href="/pages/2021/12/26/recommendation-system-04-gaussian-process-regression/">Recommendation System 04 - Gaussian process regression</a>
      </li>
      <li class="post">
          <a href="/pages/2021/12/22/zhi-chang-hua-ti-guan-yu-zhi-chang-communications-skillde-yi-dian-gan-xiang-zhuan-zai/">communications skill ()</a>
      </li>
      <li class="post">
          <a href="/pages/2021/12/22/zhi-chang-hua-ti-zhi-chang-chang-jian-8da-chang-jing-gou-tong-zhuan-zai/">8()</a>
      </li>
      <li class="post">
          <a href="/pages/2021/11/06/recommendation-system-03/">Recommendation System 03</a>
      </li>
    </ul>
  </section>
  <section>
      
    <h1>Categories</h1>
    <ul id="recent_posts">
        <li><a href="/category/career-growth.html">career growth</a></li>
        <li><a href="/category/linux.html">Linux</a></li>
        <li><a href="/category/python.html">Python</a></li>
        <li><a href="/category/rthers.html">Rthers</a></li>
    </ul>
  </section>
 

  <section>
  <h1>Tags</h1>
    <a href="/tag/pelican.html">pelican</a>,    <a href="/tag/apply_async.html">apply_async</a>,    <a href="/tag/mysql.html">mysql</a>,    <a href="/tag/deep-learning.html">deep learning</a>,    <a href="/tag/data-visualization.html">data visualization</a>,    <a href="/tag/linux.html">linux</a>,    <a href="/tag/apply.html">apply</a>,    <a href="/tag/git.html">git</a>,    <a href="/tag/re.html">re</a>,    <a href="/tag/flask.html">flask</a>,    <a href="/tag/pyqt.html">PyQt</a>,    <a href="/tag/career-growth.html">career growth</a>,    <a href="/tag/dynamic-programming.html">dynamic programming</a>,    <a href="/tag/bokeh.html">bokeh</a>,    <a href="/tag/quant.html">quant</a>,    <a href="/tag/remote-access.html">remote access</a>,    <a href="/tag/tensorflow.html">tensorflow</a>,    <a href="/tag/webcrawl.html">webCrawl</a>,    <a href="/tag/numpy.html">numpy</a>,    <a href="/tag/pandas.html">pandas</a>,    <a href="/tag/tweepy.html">tweepy</a>,    <a href="/tag/map.html">map</a>,    <a href="/tag/shiny.html">shiny</a>,    <a href="/tag/random-walk.html">random walk</a>,    <a href="/tag/python.html">python</a>,    <a href="/tag/leetcode.html">leetcode</a>,    <a href="/tag/matplotlib.html">matplotlib</a>,    <a href="/tag/pytorch.html">pytorch</a>,    <a href="/tag/base.html">base</a>,    <a href="/tag/sentiment-analysis.html">sentiment analysis</a>,    <a href="/tag/sql.html">sql</a>,    <a href="/tag/data-minging.html">data minging</a>,    <a href="/tag/tkinter.html">tkinter</a>,    <a href="/tag/data-mining.html">data mining</a>,    <a href="/tag/spyre.html">spyre</a>,    <a href="/tag/highcharts.html">highcharts</a>,    <a href="/tag/r.html">R</a>,    <a href="/tag/statsmodels.html">statsmodels</a>,    <a href="/tag/docker.html">docker</a>,    <a href="/tag/cx_freeze.html">cx_freeze</a>,    <a href="/tag/multiprocessing.html">multiprocessing</a>,    <a href="/tag/sklearn.html">sklearn</a>  </section>


    <section>
        <h1>Social</h1>
        <ul>
            <li><a href="https://www.linkedin.com/pub/huiming-song/24/735/349" target="_blank">Linkedin</a></li>
        </ul>
    </section>
    <section>
        <h1>Blogroll</h1>
        <ul>
            <li><a href="http://easysas.blogspot.com/" target="_blank">my old SAS blog</a></li>
        </ul>
    </section>

</aside>    </div>
  </div>
  <footer role="contentinfo"><p>
    Copyright &copy;  2015&ndash;2021  shm &mdash;
  <span class="credit">Powered by <a href="http://getpelican.com">Pelican</a></span>
</p></footer>
  <script src="/theme/js/modernizr-2.0.js"></script>
  <script src="/theme/js/ender.js"></script>
  <script src="/theme/js/octopress.js" type="text/javascript"></script>
    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-65938411-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();

    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-65938411-1');
    ga('send', 'pageview');
</script>
  <script type="text/javascript">
    var disqus_shortname = 'songhuiming';
    var disqus_identifier = '/pages/2017/08/12/build-neural-network-from-scratch/';
    var disqus_url = '/pages/2017/08/12/build-neural-network-from-scratch/';
    var disqus_title = 'Build Neural Network from Scratch';
    (function() {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = "//" + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
     })();
  </script>
</body>
</html>